{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff61f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "\n",
    "# standard lib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# external imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dotted_dict import DottedDict\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "# local imports\n",
    "from datasets import AffNIST\n",
    "from effcn.models import AffnistEffCapsNet\n",
    "from effcn.layers import PrimaryCaps, FCCaps\n",
    "from effcn.functions import margin_loss, max_norm_masking\n",
    "from effcn.utils import count_parameters\n",
    "from misc.optimizer import get_optimizer, get_scheduler\n",
    "from misc.utils import get_sting_timestamp, mkdir_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a229aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': 'cuda:1',\n",
    "    'debug': True,\n",
    "    'train': {\n",
    "        'batch_size': 512,\n",
    "        'num_epochs': 150,\n",
    "        'num_workers': 12,\n",
    "        'num_vis': 8,\n",
    "    },\n",
    "    'valid': {\n",
    "        'num_workers': 12,\n",
    "        'batch_size': 512,\n",
    "        'num_vis': 8,\n",
    "    },\n",
    "    'optimizer': 'adam',\n",
    "    'optimizer_args': {\n",
    "        'lr': 0.001\n",
    "    },\n",
    "    'scheduler': 'exponential_decay',\n",
    "    'scheduler_burnin': 10, # [epochs]\n",
    "    'scheduler_args':{\n",
    "        'gamma':0.96\n",
    "    },\n",
    "    'freqs': {\n",
    "        'valid': 1,  # [epochs]\n",
    "        'rec': 1,    # [epochs] show reconstructions\n",
    "        'ckpt': 1,   # [epochs]\n",
    "    },\n",
    "    'paths': {\n",
    "        'data': '/home/matthias/projects/EfficientCN/data',\n",
    "        'experiments': '/mnt/experiments/effcn/affnist/tmp',\n",
    "    },\n",
    "    'names': {\n",
    "        'model_dir': 'effcn_affnist_{}'.format(get_sting_timestamp()),\n",
    "        'ckpt_dir': 'ckpts',\n",
    "        'img_dir': 'imgs',\n",
    "        'log_dir': 'logs',\n",
    "        'model_file': 'model_{}.ckpt',\n",
    "        'stats_file': 'stats.pkl',\n",
    "        'config_file': 'config.pkl',\n",
    "        'acc_plot': 'acc.png',\n",
    "        'loss_plot': 'loss.png',\n",
    "    },\n",
    "    'loss': {\n",
    "        'margin': {\n",
    "            'lbd': 0.5,\n",
    "            'm_plus': 0.9,\n",
    "            'm_minus': 0.1,\n",
    "            'weight': 1.0\n",
    "        },\n",
    "        'rec': {\n",
    "            'weight': 0.3\n",
    "        }\n",
    "    },\n",
    "    'stop_acc': 0.9922\n",
    "}\n",
    "config = DottedDict(config)\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87031088",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = config.paths.data\n",
    "p_experiment = Path(config.paths.experiments) / config.names.model_dir\n",
    "p_ckpts = p_experiment / config.names.ckpt_dir\n",
    "p_logs = p_experiment / config.names.log_dir\n",
    "p_config = p_experiment / config.names.config_file\n",
    "p_stats = p_experiment / config.names.stats_file\n",
    "p_imgs = p_experiment / config.names.img_dir\n",
    "p_acc_plot = p_experiment / config.names.acc_plot\n",
    "p_loss_plot = p_experiment / config.names.loss_plot\n",
    "#\n",
    "device = torch.device(config.device)\n",
    "batch_size_train = config.train.batch_size\n",
    "batch_size_valid = config.valid.batch_size\n",
    "num_workers_train = config.train.num_workers\n",
    "num_workers_valid = config.valid.num_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b757b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_data)\n",
    "print(p_experiment)\n",
    "print(p_ckpts)\n",
    "print(p_logs)\n",
    "print(p_config)\n",
    "print(p_stats)\n",
    "print(p_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = None\n",
    "transform_valid = None # converts [0,255] to [0,1] by dividing through 255\n",
    "\n",
    "ds_mnist_train = AffNIST(p_root=p_data, split=\"mnist_train\", download=True, transform=transform_train, target_transform=None)\n",
    "ds_mnist_valid = AffNIST(p_root=p_data, split=\"mnist_valid\", download=True, transform=transform_valid, target_transform=None)\n",
    "ds_affnist_valid = AffNIST(p_root=p_data, split=\"affnist_valid\", download=True, transform=transform_valid, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist_train = torch.utils.data.DataLoader(\n",
    "    ds_mnist_train, \n",
    "    batch_size=batch_size_train, \n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.train.num_workers)\n",
    "dl_mnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_mnist_valid, \n",
    "    batch_size=batch_size_valid, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers_valid)\n",
    "dl_affnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_affnist_valid, \n",
    "    batch_size=batch_size_valid, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(dl_mnist_train))\n",
    "x_vis_train = x[:config.train.num_vis]\n",
    "\n",
    "x, _ = next(iter(dl_mnist_valid))\n",
    "x_vis_mnist_valid = x[:config.valid.num_vis]\n",
    "\n",
    "x, _ = next(iter(dl_affnist_valid))\n",
    "x_vis_affnist_valid = x[:config.valid.num_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41411439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torchvision.utils.make_grid(x_vis_train).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_mnist_valid).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_affnist_valid).permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AffnistEffCapsNet()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f8292",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(config.optimizer, model.parameters(), config.optimizer_args)\n",
    "if config.scheduler is not None:\n",
    "    scheduler = get_scheduler(config.scheduler, optimizer, config.scheduler_args)\n",
    "else:\n",
    "    scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18537093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_experiment)\n",
    "print(p_ckpts)\n",
    "print(p_logs)\n",
    "print(p_config)\n",
    "print(p_stats)\n",
    "print(p_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5324a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348513cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, device, data_loader):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    \n",
    "    for x,y_true in data_loader:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            u_h, x_rec = model.forward(x)\n",
    "\n",
    "            # LOSS\n",
    "            y_one_hot = F.one_hot(y_true, num_classes=10)\n",
    "            loss_margin = margin_loss(\n",
    "                    u_h, y_one_hot,\n",
    "                    lbd=config.loss.margin.lbd,\n",
    "                    m_plus=config.loss.margin.m_plus,\n",
    "                    m_minus=config.loss.margin.m_minus\n",
    "            )\n",
    "            loss_rec = torch.nn.functional.mse_loss(x, x_rec)\n",
    "\n",
    "            # total loss\n",
    "            loss = (loss_margin * config.loss.margin.weight) + (loss_rec * config.loss.rec.weight)\n",
    "\n",
    "            # validate batch \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_correct += (y_true == y_pred).sum().item()\n",
    "            epoch_total += x.shape[0]\n",
    "    epoch_acc = epoch_correct / epoch_total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def create_reconstruction_grid_img(model, device, x, permute=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _, x_rec = model.forward(x.to(device))\n",
    "        x_rec = x_rec.cpu()\n",
    "    img = torchvision.utils.make_grid(torch.cat([x, x_rec], dim=0), nrow=x.shape[0])\n",
    "    if permute:\n",
    "        img = img.permute(1,2,0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a75a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directories\n",
    "if config.debug:\n",
    "    # remove dir and recreate it if in debug mode\n",
    "    if p_experiment.exists():\n",
    "        shutil.rmtree(p_experiment)\n",
    "    mkdir_directories([p_experiment, p_ckpts, p_logs, p_imgs], parents=True, exist_ok=True)\n",
    "else:\n",
    "    mkdir_directories([p_experiment, p_ckpts, p_logs, p_imgs], parents=True, exist_ok=False)\n",
    "\n",
    "# summary writer\n",
    "sw = SummaryWriter(p_logs)\n",
    "print(\"tensorboard loss_marginloss_margin--logdir={}\".format(str(p_logs)))\n",
    "\n",
    "# save configs\n",
    "with open(p_config, \"wb\") as file:\n",
    "    pickle.dump(config, file)\n",
    "\n",
    "# custom training stats\n",
    "stats = {\n",
    "    \"train\": {\n",
    "        'acc': [],\n",
    "        'loss': [],\n",
    "        'epoch': [],\n",
    "    },\n",
    "    \"valid\": {\n",
    "        'mnist': {\n",
    "            'acc': [],\n",
    "            'loss': [],\n",
    "            'epoch': [],\n",
    "        },\n",
    "        'affnist': {\n",
    "            'acc': [],\n",
    "            'loss': [],\n",
    "            'epoch': [],            \n",
    "        }\n",
    "    },\n",
    "    \"notes\": []\n",
    "}\n",
    "\n",
    "stop_run = False # set if some event occurs\n",
    "for epoch_idx in range(1, config.train.num_epochs + 1, 1):\n",
    "    ###################\n",
    "    # TRAIN\n",
    "    ###################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, config.train.num_epochs)\n",
    "    pbar = tqdm(dl_mnist_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_correct = 0\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # way faster than optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "            \n",
    "        u_h, x_rec = model.forward(x)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=10)\n",
    "        loss_margin = margin_loss(\n",
    "            u_h, y_one_hot,\n",
    "            lbd=config.loss.margin.lbd,\n",
    "            m_plus=config.loss.margin.m_plus,\n",
    "            m_minus=config.loss.margin.m_minus\n",
    "        )\n",
    "        loss_margin = loss_margin * config.loss.margin.weight\n",
    "        loss_rec = torch.nn.functional.mse_loss(x, x_rec)\n",
    "        loss_rec = loss_rec * config.loss.rec.weight\n",
    "        \n",
    "        # total loss\n",
    "        loss = loss_margin + loss_rec\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # validate batch \n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "\n",
    "        correct = (y_true == y_pred).sum()\n",
    "        acc = correct / x.shape[0]\n",
    "\n",
    "        epoch_correct += correct.item()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'mar': loss_margin.item(),\n",
    "                 'rec': loss_rec.item(),\n",
    "                 'acc': acc.item()\n",
    "                }\n",
    "            )\n",
    "    # TRAIN STAS\n",
    "    sw.add_scalar(\"train/loss\", epoch_loss, epoch_idx)\n",
    "    sw.add_scalar(\"train/acc\", epoch_correct / len(ds_mnist_train), epoch_idx)\n",
    "    \n",
    "    stats[\"train\"][\"epoch\"].append(epoch_idx)\n",
    "    stats[\"train\"][\"acc\"].append(epoch_correct / len(ds_mnist_train))\n",
    "    stats[\"train\"][\"loss\"].append(epoch_loss)\n",
    "    \n",
    "    if scheduler is not None and (epoch_idx > config.scheduler_burnin):\n",
    "        scheduler.step()\n",
    "        \n",
    "    if epoch_loss == torch.nan:\n",
    "        print_str = \"Stopping epoch {}: epoch_loss={}\".format(epoch_idx, epoch_loss)\n",
    "        print(print_str)\n",
    "        stats[\"notes\"].append(print_str)\n",
    "        stop_run = True\n",
    "    \n",
    "    ###################\n",
    "    # EVAL\n",
    "    ###################\n",
    "    model.eval()\n",
    "    if (epoch_idx % config.freqs.ckpt == 0) or (config.train.num_epochs == epoch_idx):\n",
    "        p_ckpt = p_ckpts / config.names.model_file.format(epoch_idx)\n",
    "        torch.save(model.state_dict(), p_ckpt)\n",
    "\n",
    "    if (epoch_idx % config.freqs.rec == 0) or (config.train.num_epochs == epoch_idx):\n",
    "        \n",
    "        img_train = create_reconstruction_grid_img(model, device, x_vis_train)\n",
    "        img_mnist_valid = create_reconstruction_grid_img(model, device, x_vis_mnist_valid)\n",
    "        img_affnist_valid = create_reconstruction_grid_img(model, device, x_vis_affnist_valid)\n",
    "        \n",
    "        plt.imshow(img_train.permute(1,2,0))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "        sw.add_image(\"train/rec\", img_train, epoch_idx)\n",
    "        sw.add_image(\"valid/mnist\", img_mnist_valid, epoch_idx)\n",
    "        sw.add_image(\"valid/affnist\", img_affnist_valid, epoch_idx)\n",
    "\n",
    "    if (epoch_idx % config.freqs.valid == 0) or (config.train.num_epochs == epoch_idx):\n",
    "        loss_mnist_valid, acc_mnist_valid = eval_model(model, device, dl_mnist_valid)\n",
    "        \n",
    "        sw.add_scalar(\"valid/mnist/loss\", loss_mnist_valid, epoch_idx)\n",
    "        sw.add_scalar(\"valid/mnist/acc\", acc_mnist_valid, epoch_idx)\n",
    "        \n",
    "        stats[\"valid\"][\"mnist\"][\"epoch\"].append(epoch_idx)\n",
    "        stats[\"valid\"][\"mnist\"][\"acc\"].append(acc_mnist_valid)\n",
    "        stats[\"valid\"][\"mnist\"][\"loss\"].append(loss_mnist_valid)\n",
    "        \n",
    "        \n",
    "        loss_affnist_valid, acc_affnist_valid = eval_model(model, device, dl_affnist_valid)\n",
    "        sw.add_scalar(\"valid/affnist/loss\", loss_affnist_valid, epoch_idx)\n",
    "        sw.add_scalar(\"valid/affnist/acc\", acc_affnist_valid, epoch_idx)\n",
    "\n",
    "        stats[\"valid\"][\"affnist\"][\"epoch\"].append(epoch_idx)\n",
    "        stats[\"valid\"][\"affnist\"][\"acc\"].append(acc_affnist_valid)\n",
    "        stats[\"valid\"][\"affnist\"][\"loss\"].append(loss_affnist_valid)\n",
    "        \n",
    "        print_str = \"Valid: mnist_loss: {:.5f}, affnist_loss: {:.5f}, mnist_acc: {:.5f} affnist_acc: {:.5f}\"\n",
    "        print(print_str.format(loss_mnist_valid, loss_affnist_valid, acc_mnist_valid, acc_affnist_valid))\n",
    "        \n",
    "        if acc_mnist_valid >= config.stop_acc:\n",
    "            print_str = \"Stopping epoch {}: acc_valid {:.5f} > {:.5f}\".format(epoch_idx, acc_mnist_valid, config.stop_acc)\n",
    "            print(print_str)\n",
    "            stats[\"notes\"].append(print_str)\n",
    "            stop_run = True\n",
    "    \n",
    "    with open(p_stats, \"wb\") as file:\n",
    "        pickle.dump(p_stats, file)\n",
    "\n",
    "    if stop_run:\n",
    "        break\n",
    "\n",
    "sw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max = max(stats[\"train\"][\"acc\"])\n",
    "valid_mnist_max = max(stats[\"valid\"][\"mnist\"][\"acc\"])\n",
    "valid_affnist_max = max(stats[\"valid\"][\"affnist\"][\"acc\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(stats[\"train\"][\"epoch\"], stats[\"train\"][\"acc\"], label=\"train {:.5f}\".format(train_max), color='b')\n",
    "plt.plot(stats[\"valid\"][\"mnist\"][\"epoch\"], stats[\"valid\"][\"mnist\"][\"acc\"], label=\"valid mnist {:.5f}\".format(valid_mnist_max), color='red')\n",
    "plt.plot(stats[\"valid\"][\"affnist\"][\"epoch\"], stats[\"valid\"][\"affnist\"][\"acc\"], label=\"valid affnist {:.5f}\".format(valid_affnist_max), color='orange')\n",
    "#\n",
    "plt.axhline(y=train_max, color='b', linestyle='dotted')\n",
    "plt.axhline(y=valid_mnist_max, color='red', linestyle='dotted')\n",
    "plt.axhline(y=valid_affnist_max, color='orange', linestyle='dotted')\n",
    "plt.title(\"ACC\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(p_acc_plot)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7463de1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(stats[\"train\"][\"epoch\"], stats[\"train\"][\"loss\"], label=\"train\", color='b')\n",
    "plt.plot(stats[\"valid\"][\"mnist\"][\"epoch\"], stats[\"valid\"][\"mnist\"][\"loss\"], label=\"valid mnist\", color='red')\n",
    "plt.plot(stats[\"valid\"][\"affnist\"][\"epoch\"], stats[\"valid\"][\"affnist\"][\"loss\"], label=\"valid affnist\", color='orange')\n",
    "#\n",
    "plt.title(\"LOSS\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(p_loss_plot)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
