{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a27a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")\n",
    "\n",
    "# standard lib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# external imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "# local imports\n",
    "from effcn.functions import masking\n",
    "from datasets.csprites import ClassificationDataset\n",
    "from effcn.layers import Squash\n",
    "from effcn.functions import margin_loss, max_norm_masking\n",
    "from misc.utils import count_parameters\n",
    "from misc.plot_utils import plot_couplings, plot_capsules, plot_mat, plot_mat2\n",
    "from misc.metrics import *\n",
    "from misc.utils import normalize_transform, inverse_normalize_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8a87f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171841a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# black background\n",
    "p_data = '/mnt/data/csprites/single_csprites_32x32_n7_c24_a12_p6_s2_bg_1_constant_color_145152'\n",
    "\n",
    "# structured background\n",
    "# p_data = '/mnt/data/csprites/single_csprites_32x32_n7_c24_a12_p6_s2_bg_inf_random_function_145152'\n",
    "\n",
    "\n",
    "p_ds_config = Path(p_data) / \"config.pkl\"\n",
    "with open(p_ds_config, \"rb\") as file:\n",
    "    ds_config = pickle.load(file)\n",
    "target_variable = \"shape\"\n",
    "target_idx = [idx for idx, target in enumerate(ds_config[\"classes\"]) if target == target_variable][0]\n",
    "n_classes = ds_config[\"n_classes\"][target_variable]\n",
    "#\n",
    "norm_transform = normalize_transform(ds_config[\"means\"],\n",
    "                               ds_config[\"stds\"])\n",
    "#\n",
    "target_transform = lambda x: x[target_idx]\n",
    "transform = T.Compose(\n",
    "    [T.ToTensor(),\n",
    "     norm_transform,\n",
    "    ])\n",
    "inverse_norm_transform = inverse_normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0703022f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "batch_size = 512\n",
    "num_workers = 4\n",
    "#\n",
    "ds_train = ClassificationDataset(\n",
    "    p_data = p_data,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=False\n",
    ")\n",
    "# VALID\n",
    "ds_valid = ClassificationDataset(\n",
    "    p_data = p_data,\n",
    "    transform=transform,\n",
    "    target_transform=target_transform,\n",
    "    split=\"valid\"\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = num_workers,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb430ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 64\n",
    "x,y = next(iter(dl_train))\n",
    "x = x[:n_vis]\n",
    "y = y[:n_vis]\n",
    "#\n",
    "x = inverse_norm_transform(x)\n",
    "#\n",
    "grid_img = torchvision.utils.make_grid(x, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a665b026",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f166c4f",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14090b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_classes, d_out):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(n_classes * d_out, 10*10)\n",
    "        )\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(1, 32, kernel_size=(3, 3), padding=\"valid\"),\n",
    "            nn.LeakyReLU(0.3,inplace=True),\n",
    "            nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=(3, 3), padding=\"valid\"),\n",
    "            nn.LeakyReLU(0.3,inplace=True),\n",
    "            #nn.UpsamplingBilinear2d(scale_factor=2),\n",
    "            nn.Conv2d(64, 3, kernel_size=(3, 3), padding=\"valid\"),\n",
    "            #nn.LeakyReLU(0.3,inplace=True),\n",
    "            #nn.Conv2d(128, 3, kernel_size=(3, 3), padding=\"same\"),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = x.view(-1, 1, 10, 10)\n",
    "        x = self.layer2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Decoder(7, 16)\n",
    "y = model(torch.rand(1, 7 * 16))\n",
    "print(y.shape)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce22576",
   "metadata": {},
   "source": [
    "### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca15992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBB(nn.Module):\n",
    "    \"\"\"\n",
    "        Custom backbone\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.n_classes=n_classes\n",
    "    \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=32, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=256, groups=32, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=7, groups=32, stride=1, padding=\"valid\"),\n",
    "        )\n",
    "        self.fc = nn.Linear(512 , n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)     # -> (b, 256), remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CustomBB(nn.Module):\n",
    "    \"\"\"\n",
    "        Custom backbone\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.n_classes=n_classes\n",
    "    \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, groups=1, stride=2, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, groups=32, stride=2, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=7, groups=32, stride=1, padding=\"valid\", bias=False),\n",
    "        )\n",
    "        self.fc = nn.Linear(512 , n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)     # -> (b, 256), remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CustomBB(nn.Module):\n",
    "    \"\"\"\n",
    "        Custom backbone\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.n_classes=n_classes\n",
    "    \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, groups=1, stride=2, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 256, kernel_size=3, groups=32, stride=2, padding=0, bias=False),\n",
    "            #nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 512, kernel_size=7, groups=32, stride=1, padding=\"valid\", bias=False),\n",
    "        )\n",
    "        self.fc = nn.Linear(512 , n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)     # -> (b, 256), remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class CustomBB(nn.Module):\n",
    "    \"\"\"\n",
    "        Custom backbone\n",
    "    \"\"\"\n",
    "    def __init__(self, ch_in=3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.n_classes=n_classes\n",
    "    \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, groups=1, stride=1, padding=\"same\", bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 256, kernel_size=3, groups=32, stride=1, padding=\"same\", bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, groups=32, stride=1, padding=0, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(512, 512, kernel_size=3, groups=32, stride=1, padding=0, bias=False),\n",
    "\n",
    ")\n",
    "        self.fc = nn.Linear(512 , n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)     # -> (b, 256), remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if it works\n",
    "model = CustomBB(ch_in=3)\n",
    "y = model(torch.rand(128, 3, 32, 32))\n",
    "print(count_parameters(model))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3cd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, n_z, d_z, d_x, d_i, scale=0.01, dim=1):\n",
    "        super().__init__()\n",
    "        self.z = torch.nn.Parameter(torch.rand(n_z, d_z), requires_grad=True)\n",
    "        self.to_q = nn.Linear(d_z, d_i, bias=False)\n",
    "        self.to_kv = nn.Linear(d_x, d_i * 2, bias=False)\n",
    "        self.scale = scale\n",
    "        self.dim = dim\n",
    "        #\n",
    "        self.squash = Squash(eps=1e-20)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.forward_debug(x)\n",
    "        return out\n",
    "    \n",
    "    def forward_debug(self, x):\n",
    "        q = self.to_q(self.z)\n",
    "        k, v = self.to_kv(x).chunk(2, dim=-1)\n",
    "        #\n",
    "        S = torch.einsum(\"id, ...jd -> ...ij\", q, k)\n",
    "        \n",
    "        C = torch.softmax(S / self.scale, dim=self.dim)\n",
    "        \n",
    "        # (b,n_h,n_l) (b,n_l,d_i)\n",
    "        out = torch.einsum(\"...ij, ...jk -> ...ik\", C, v)\n",
    "        #\n",
    "        return self.squash(out), C.permute(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b81c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_l = 4\n",
    "n_h = 3\n",
    "d_l = 5\n",
    "d_h = 2\n",
    "#\n",
    "model = CrossAttention(n_z=n_h, d_z=d_h, d_x=d_l, d_i=d_h)\n",
    "x = torch.rand(1, n_l, d_l)\n",
    "y, C = model.forward_debug(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3557b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCCaps(nn.Module):\n",
    "    \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        n_l ... number of lower layer capsules\n",
    "        d_l ... dimension of lower layer capsules\n",
    "        n_h ... number of higher layer capsules\n",
    "        d_h ... dimension of higher layer capsules\n",
    "\n",
    "        W   (n_l, n_h, d_l, d_h) ... weight tensor\n",
    "        B   (n_l, n_h)           ... bias tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_l, n_h, d_l, d_h):\n",
    "        super().__init__()\n",
    "        self.n_l = n_l\n",
    "        self.d_l = d_l\n",
    "        self.n_h = n_h\n",
    "        self.d_h = d_h\n",
    "        \n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.rand(\n",
    "            n_l, n_h, d_l, d_h), requires_grad=True)\n",
    "        self.B = torch.nn.Parameter(torch.rand(n_l, n_h), requires_grad=True)\n",
    "        self.squash = Squash(eps=1e-20)\n",
    "\n",
    "        # init custom weights\n",
    "        # i'm relly unsure about this initialization scheme\n",
    "        # i don't think it makes sense in our case, but the paper says so ...\n",
    "        torch.nn.init.kaiming_normal_(\n",
    "            self.W, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        torch.nn.init.kaiming_normal_(\n",
    "            self.B, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n",
    "\n",
    "        self.attention_scaling = np.sqrt(self.d_l)\n",
    "        self.scaling = 0.01\n",
    "\n",
    "    def forward(self, U_l):\n",
    "        U_h, _ = self.forward_debug(U_l)\n",
    "        return U_h\n",
    "\n",
    "    def forward_debug(self, U_l):\n",
    "        \"\"\"\n",
    "        einsum convenventions:\n",
    "          n_l = i | h\n",
    "          d_l = j\n",
    "          n_h = k\n",
    "          d_h = l\n",
    "\n",
    "        Data tensors:\n",
    "            IN:  U_l ... lower layer capsules\n",
    "            OUT: U_h ... higher layer capsules\n",
    "            DIMS:\n",
    "                U_l (n_l, d_l)\n",
    "                U_h (n_h, d_h)\n",
    "                W   (n_l, n_h, d_l, d_h)\n",
    "                B   (n_l, n_h)\n",
    "                A   (n_l, n_l, n_h)\n",
    "                C   (n_l, n_h)\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "            Same as forward() but returns more stuff to analyze routing\n",
    "        \"\"\"\n",
    "        U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, self.W)\n",
    "        A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "        \n",
    "        # I removed the scaling, to create stronger couplings\n",
    "        #A = A / self.attention_scaling)\n",
    "        \n",
    "        \n",
    "        A_sum = torch.einsum(\"...hij->...hj\", A)\n",
    "        C = torch.softmax(A_sum / self.scaling, dim=-1)\n",
    "        \n",
    "        # I removed the Bias term\n",
    "        #CB = C + B\n",
    "        \n",
    "        U_h = torch.einsum('...ikl,...ik->...kl', U_hat, C)\n",
    "        return self.squash(U_h), C\n",
    "\n",
    "class DeepCapsNet(nn.Module):\n",
    "    \"\"\"\n",
    "        A Deeper CN that allows\n",
    "    \"\"\"\n",
    "    def __init__(self, ns, ds):\n",
    "        super().__init__()\n",
    "        self.ns = ns\n",
    "        self.ds = ds\n",
    "        \n",
    "        self.backbone = CustomBB(ch_in=3)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.decoder = Decoder(ns[-1], ds[-1])\n",
    "        \n",
    "        self.squash = Squash(eps=1e-20)\n",
    "        layers = []\n",
    "        for idx in range(1, len(ns), 1):\n",
    "            dim = 1\n",
    "            scale = 0.001\n",
    "            if idx == 1:\n",
    "                dim = dim\n",
    "                scale = scale\n",
    "            n_l = ns[idx - 1]\n",
    "            n_h = ns[idx]\n",
    "            d_l = ds[idx - 1]\n",
    "            d_h = ds[idx]\n",
    "            layers.append(CrossAttention(n_z=n_h, d_z=d_h, d_x=d_l, d_i=d_h, dim=dim, scale=scale))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        \n",
    "        #self.PW = nn.Parameter(torch.rand(ns[0], ds[0], ds[0]))\n",
    "\n",
    "\n",
    "    def forward(self, x, y_true=None):\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # primecaps\n",
    "        x = x.view(-1, self.ns[0], self.ds[0])\n",
    "        #x = torch.einsum(\"...nd,nkd->...nk\", x, self.PW)\n",
    "        x = self.squash(x)\n",
    "        \n",
    "        # fccaps\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # decoder\n",
    "        u_h_masked = masking(x, y_true)\n",
    "        x_rec = self.decoder(u_h_masked)\n",
    "        return x, x_rec\n",
    "\n",
    "    def forward_debug(self, x, y_true=None):\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # primecaps\n",
    "        x = x.view(-1, self.ns[0], self.ds[0])\n",
    "        #x = torch.einsum(\"...nd,nkd->...nk\", x, self.PW)\n",
    "        x = self.squash(x)\n",
    "        \n",
    "        us = [torch.clone(x)]\n",
    "        cc = []\n",
    "        # fccaps\n",
    "        for layer in self.layers:\n",
    "            x, c = layer.forward_debug(x)\n",
    "            cc.append(c.detach())\n",
    "            us.append(torch.clone(x).detach())\n",
    "        \n",
    "        u_h_masked = masking(x, y_true)\n",
    "        x_rec = self.decoder(u_h_masked)\n",
    "        \n",
    "        return x, cc, us, x_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01791255",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [32, 26, 20, 14, n_classes]\n",
    "ds = [16, 16, 16, 16, 16]\n",
    "#\n",
    "ns = [32, 32, 32, n_classes]\n",
    "ds = [8, 8, 8, 8]\n",
    "#\n",
    "ns = [32, n_classes]\n",
    "ds = [16, 16]\n",
    "\n",
    "model = DeepCapsNet(ns=ns, ds=ds)\n",
    "#\n",
    "print(\"tot Model \", count_parameters(model))\n",
    "print(\"Backbone  \", count_parameters(model.backbone))\n",
    "print(\"Decoder  \", count_parameters(model.decoder))\n",
    "print(\"Routing  \", count_parameters(model.layers))\n",
    "#\n",
    "model = model.to(device)\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.98)\n",
    "#\n",
    "func_rec_loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba65fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 8\n",
    "x_vis, y_vis = next(iter(dl_valid))\n",
    "x_vis = x_vis[:n_vis].to(device)\n",
    "y_vis = y_vis[:n_vis].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf55e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 51\n",
    "do_overfit = False\n",
    "if do_overfit:\n",
    "    x_of, y_of = next(iter(dl_train))\n",
    "    x_of = x_of[:10]\n",
    "    y_of = y_of[:10]\n",
    "    n_vis = 10\n",
    "    x_vis = x_of.to(device)\n",
    "    y_vis = y_of.to(device)\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        if do_overfit:\n",
    "            x = x_of\n",
    "            y_true = y_of\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        #\n",
    "        #\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        u_h, x_rec = model.forward(x, y_true)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=n_classes)\n",
    "        loss_mar = margin_loss(u_h, y_one_hot)\n",
    "        \n",
    "        loss_rec = func_rec_loss(inverse_norm_transform(x), x_rec) * 10\n",
    "        \n",
    "        loss = loss_rec + loss_mar\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'rec': loss_rec.item(),\n",
    "                 'mar': loss_mar.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            u_h, x_rec = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   mnist acc_valid: {:.3f}\".format(total_correct / total))\n",
    "    #\n",
    "    with torch.no_grad():\n",
    "        _, x_rec_vis = model(x_vis.to(device))\n",
    "        _, x_rec_vis_mask = model(x_vis.to(device), y_vis.to(device))\n",
    "    #\n",
    "    grid_img = torch.cat([inverse_norm_transform(x_vis), x_rec_vis, x_rec_vis_mask], dim=0)\n",
    "    grid_img = torchvision.utils.make_grid(grid_img, nrow=n_vis)\n",
    "    plt.imshow(grid_img.permute(1, 2, 0).cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6823efc",
   "metadata": {},
   "source": [
    "### results\n",
    "epoch = 50 0.994 0.883, groups=256\n",
    "epoch = 50 0.992 0.923, groups=32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f8a12",
   "metadata": {},
   "source": [
    "# Visualize and Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f7ae3",
   "metadata": {},
   "source": [
    "### Show parse tree and activations for individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl_valid))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_h, CC, US, x_rec = model.forward_debug(x.to(device))\n",
    "y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "#\n",
    "US = [u.cpu().numpy() for u in US]\n",
    "CS = [c.cpu().numpy() for c in CC]\n",
    "#\n",
    "Y_true = y.cpu().numpy()\n",
    "Y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102f1ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vis_class = None\n",
    "vis_max = 4\n",
    "for idx in range(vis_max):\n",
    "    if vis_class is not None and Y_true[idx] != vis_class:\n",
    "        continue\n",
    "    cs = [c[idx] for c in CS]\n",
    "    us = [u[idx] for u in US]\n",
    "    u_norms = [np.linalg.norm(u, axis=1) for u in us]\n",
    "    \n",
    "    # plot stuff\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    title = \"exp={} a={}\".format(y[idx], y_pred[idx])\n",
    "    #\n",
    "    plot_couplings(cs, title=title, ax=axes[0], show=False)\n",
    "    plot_capsules(u_norms, title=title , ax=axes[1], show=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb9b79",
   "metadata": {},
   "source": [
    "# Statistics For Further Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "YY = []\n",
    "CC = [[] for _ in range(len(ns) - 1)]\n",
    "US = [[] for _ in range(len(ns))]\n",
    "\n",
    "\n",
    "# use whole dataset\n",
    "for x,y_true in dl_valid:\n",
    "    x = x.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        _, cc, us, _ = model.forward_debug(x.to(device))\n",
    "        for idx in range(len(cc)):\n",
    "            CC[idx].append(cc[idx].detach().cpu().numpy())\n",
    "        for idx in range(len(us)):\n",
    "            US[idx].append(us[idx].detach().cpu().numpy())\n",
    "        YY.append(y_true.numpy())\n",
    "        \n",
    "# Dataset Labels\n",
    "YY = np.concatenate(YY)\n",
    "\n",
    "# Dataset Coupling Coefficient Matrices\n",
    "CC = [np.concatenate(c) for c in CC]\n",
    "\n",
    "# Dataset Capsules\n",
    "US = [np.concatenate(u) for u in US]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a733919",
   "metadata": {},
   "source": [
    "### Mean parse tree and mean activation for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    \n",
    "# Mean parse tree\n",
    "cc_mean = [np.mean(c, axis=0) for c in CC]\n",
    "cc_std = [np.std(c, axis=0) for c in CC]\n",
    "plot_couplings(cc_mean, ax=axes[0], show=False, title=\"mean couplings\")\n",
    "plot_couplings(cc_std, ax=axes[1], show=False, title=\"std couplings\")\n",
    "    \n",
    "# mean and std capsule activation\n",
    "us_mean = [np.linalg.norm(u, axis=-1).mean(axis=0) for u in US]\n",
    "us_std = [np.linalg.norm(u, axis=-1).std(axis=0) for u in US]\n",
    "us_max = [np.linalg.norm(u, axis=-1).max(axis=0) for u in US]\n",
    "plot_capsules(us_mean, scale_factor=1, ax=axes[2], show=False, title=\"mean activation\")\n",
    "plot_capsules(us_std, scale_factor=1, ax=axes[3], show=False, title=\"std activation\")\n",
    "plot_capsules(us_max, scale_factor=1, ax=axes[4], show=False, title=\"max activation\")\n",
    "plt.suptitle(\"dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e6d556",
   "metadata": {},
   "source": [
    "### Parse tree from normalized Couplings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77845a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(4 * len(CC), 4))\n",
    "\n",
    "CNS = [normalize_couplings(C) for C in CC]\n",
    "\n",
    "CNS_MAN = [ma_couplings(C, pr) for C, pr in CNS]\n",
    "CNS_MAX = [C.max(axis=0) for C, pr in CNS]\n",
    "CNS_STD = [stda_couplings(C, pr) for C, pr in CNS]\n",
    "\n",
    "plot_couplings(CNS_MAN, ax=axes[0], show=False, title=\"mean\")\n",
    "plot_couplings(CNS_STD, ax=axes[1], show=False, title=\"std\")\n",
    "plot_couplings(CNS_MAX, ax=axes[2], show=False, title=\"max\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f4597",
   "metadata": {},
   "source": [
    "### Classwise mean parse tree and mean activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084dbf6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mean and variance activation\n",
    "for cls in range(n_classes):\n",
    "    idcs = np.where(YY == cls)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 6, figsize=(24, 4))\n",
    "    \n",
    "    cc = [C[idcs] for C in CC]\n",
    "    CNS = [normalize_couplings(C, eps_rate=0.5) for C in cc]\n",
    "    \n",
    "    CNS_MAN = [ma_couplings(C, pr) for C, pr in CNS]\n",
    "    CNS_MAX = [C.max(axis=0) for C, pr in CNS]\n",
    "    CNS_STD = [stda_couplings(C, pr) for C, pr in CNS]\n",
    "\n",
    "    plot_couplings(CNS_MAN, ax=axes[0], show=False, title=\"mean\")\n",
    "    plot_couplings(CNS_STD, ax=axes[1], show=False, title=\"std\")\n",
    "    plot_couplings(CNS_MAX, ax=axes[2], show=False, title=\"max\")\n",
    "    \n",
    "    # mean and std capsule activation\n",
    "    us = [u[idcs] for u in US]\n",
    "    us_mean = [np.linalg.norm(u, axis=-1).mean(axis=0) for u in us]\n",
    "    us_std = [np.linalg.norm(u, axis=-1).std(axis=0) for u in us]\n",
    "    us_max = [np.linalg.norm(u, axis=-1).max(axis=0) for u in us]\n",
    "    \n",
    "    plot_capsules(us_mean, scale_factor=1, ax=axes[3], show=False, title=\"mean activation\")\n",
    "    plot_capsules(us_std, scale_factor=1, ax=axes[4], show=False, title=\"std activation\")\n",
    "    plot_capsules(us_max, scale_factor=1, ax=axes[5], show=False, title=\"max activation\")\n",
    "    plt.suptitle(\"class {}\".format(cls))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb15cf",
   "metadata": {},
   "source": [
    "# Coupling Death vs Alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26c1f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_th_mu = 1e-2\n",
    "c_th_sd = 1e-2\n",
    "\n",
    "fig, axes = plt.subplots(len(US), 2, figsize=(6, 3 * len(US)))\n",
    "#\n",
    "US_alive = []\n",
    "for idx in range(len(US)):\n",
    "    U = US[idx]\n",
    "    U_norm = np.linalg.norm(U, axis=2)\n",
    "    U_norm_mu = U_norm.mean(axis=0)\n",
    "    U_norm_sd = U_norm.std(axis=0)\n",
    "    #\n",
    "    U_dead = (U_norm_sd < 1e-2) * (U_norm_mu < 1e-2)\n",
    "    #\n",
    "    xx = range(len(U_norm_mu))\n",
    "    axes[idx][0].set_title(\"mu(norm(U))\")\n",
    "    axes[idx][0].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][0].bar(xx, U_norm_mu)\n",
    "    axes[idx][0].set_ylim(0, 1)\n",
    "    axes[idx][1].set_title(\"sd(norm(U))\")\n",
    "    axes[idx][1].bar(xx, U_norm_sd)\n",
    "    axes[idx][1].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][1].set_ylim(0, 1)\n",
    "    U_alive = 1 - U_dead\n",
    "    US_alive.append(U_alive)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d94325",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d9f498",
   "metadata": {},
   "source": [
    "### Vibrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "for U in US:\n",
    "    pr = rate_dead_capsules_norm(U)\n",
    "    print(\"#Permanently Dead: {:.3f}\".format(pr.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe74560",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in CC:\n",
    "    pr = rate_inactive_capsules(C)\n",
    "    print(\"Rate inactive capsules {:.3f}\".format(pr.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99acf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    U = US[idx]\n",
    "    #\n",
    "    rnd, rac, racnd =  get_vibrance(U, C)\n",
    "    #\n",
    "    print(\"rate alive: {:.3f} rate active {:.3f} rate active of alive {:.3f}\".format(\n",
    "        rnd, rac, racnd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915638f4",
   "metadata": {},
   "source": [
    "### Bonding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeda11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    b = get_bonding(C)\n",
    "    print_str = \"bonding strength: {:.3f}\"\n",
    "    print(print_str.format(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2f84b1",
   "metadata": {},
   "source": [
    "### Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953925f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    dyc = get_dynamics(C)\n",
    "    #\n",
    "    print(\"dynamics: {:.3f}\".format(\n",
    "          dyc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59444de",
   "metadata": {},
   "source": [
    "### Correlation Capsule Activation and Max Coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaad1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    U = US[idx]\n",
    "    C = CC[idx]\n",
    "    print(\"corr: {:.3f}\".format(activation_coupling_corr(C, U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae7505",
   "metadata": {},
   "source": [
    "### metrics for whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cf573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    U = US[idx]\n",
    "    #\n",
    "    rnd, rac, racnd = get_vibrance(U, C)\n",
    "    b = get_bonding(C)\n",
    "    dyc = get_dynamics(C)\n",
    "    cor = activation_coupling_corr(C, U)\n",
    "    vals.append((idx,\n",
    "                 rnd, rac, racnd,\n",
    "                 b, dyc, cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32da7964",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"layer\",\n",
    "        \"alive rate\", \"active rate\", \"active of alive rate\",\n",
    "        \"bonding str.\", \"dynamics\", \"cor\"]\n",
    "df = pd.DataFrame(data=vals, columns=cols)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d755f",
   "metadata": {},
   "source": [
    "### metrics for whole dataset, but classwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de94e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vals = []\n",
    "\n",
    "#\n",
    "for cls in range(10):\n",
    "    idcs = np.where(YY == cls)[0]\n",
    "    for idx in range(len(CC)):\n",
    "        C = CC[idx][idcs]\n",
    "        U = US[idx][idcs]\n",
    "        #\n",
    "        rnd, rac, racnd = get_vibrance(U, C)\n",
    "        b = get_bonding(C)\n",
    "        dyc = get_dynamics(C)\n",
    "        cor = activation_coupling_corr(C, U)\n",
    "        vals.append((cls, idx,\n",
    "                     rnd, rac, racnd,\n",
    "                     b, dyc, cor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf815a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"class\", \"layer\",\n",
    "        \"alive rate\", \"active rate\", \"active of alive rate\",\n",
    "        \"bonding str.\", \"dynamics\", \"cor\"]\n",
    "df = pd.DataFrame(data=vals, columns=cols)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8748c773",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    sdf = df[df[\"layer\"] == idx].drop(columns=[\"layer\"])\n",
    "    print(sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c00fb3",
   "metadata": {},
   "source": [
    "# Couplings Viszalizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0ec07",
   "metadata": {},
   "source": [
    "#### Couplings FROM DEAD Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    C = C[:,np.where(Ul_alive == False)[0],:]\n",
    "    \n",
    "    if len(C.flatten()) < 1:\n",
    "        print(\"No dead capsules for layer {}\".format(idx))\n",
    "        continue\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(33, 11))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ce33",
   "metadata": {},
   "source": [
    "#### Couplings FROM Alive Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    C = C[:,np.where(Ul_alive == True)[0],:]\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(42, 14))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750004af",
   "metadata": {},
   "source": [
    "per sample count max coupling and use max to find out if coupling in general gets lower or just the average as they are loosly connected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b5d3f",
   "metadata": {},
   "source": [
    "### Couplings FROM ALIVE to DEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4889ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    Uh_alive = US_alive[idx + 1]\n",
    "    if (1 - Uh_alive).sum() < 1:\n",
    "        print(\"{} No dead capsules for upper layer {}\".format(idx ,idx + 1))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    C = C[:,np.where(Ul_alive == True)[0],:][:,:,np.where(Uh_alive == False)[0]]\n",
    "    \n",
    "    if len(C.flatten()) < 1:\n",
    "        print(\"No dead capsules for layer {}\".format(idx))\n",
    "        continue\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(33, 11))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52314d8",
   "metadata": {},
   "source": [
    "### Couplings FROM ALIVE TO ALIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3e7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    Uh_alive = US_alive[idx + 1]\n",
    "    if (Uh_alive).sum() < 1:\n",
    "        print(\"No dead capsules for upper layer {}\".format(idx + 1))\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    C = C[:,np.where(Ul_alive == True)[0],:][:,:,np.where(Uh_alive == True)[0]]\n",
    "    \n",
    "    if len(C.flatten()) < 1:\n",
    "        print(\"No dead capsules for layer {}\".format(idx))\n",
    "        continue\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(33, 11))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6f272",
   "metadata": {},
   "source": [
    "# CNN Only Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "epoch acc\n",
    "010   96.0 85.5\n",
    "020   99.6 87.0\n",
    "050   1.00 88.4\n",
    "100   1.09 88.6\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomBB(ch_in=3, n_classes=n_classes)\n",
    "#\n",
    "model = model.to(device)\n",
    "#backbone\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay=2e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)\n",
    "#\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609b403",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    ", acc = num_epochs = 51\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model.forward(x)\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   mnist acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4f8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
