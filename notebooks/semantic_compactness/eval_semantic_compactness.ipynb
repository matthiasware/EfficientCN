{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "#\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from dotted_dict import DottedDict\n",
    "#\n",
    "from misc.plot_utils import plot_mat, imshow\n",
    "from effcn.functions import max_norm_masking\n",
    "from effcn.models_mnist import Backbone, Decoder, EffCapsNet, CNN_CR_SF, CNN_CR, CNN_R\n",
    "from misc.utils import mkdir_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[4.,2.,6.],[1., 3.,2.],[2., 3.,2.]])\n",
    "print(a.shape)\n",
    "dim = 1\n",
    "print(torch.var(a, dim=dim))\n",
    "print(torch.cov(a))\n",
    "\n",
    "\n",
    "#a = np.array([[1, 2], [3, 4]])\n",
    "print(np.var(a.numpy(), axis=0))\n",
    "print(np.cov(a.numpy()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_experiment = \"/mnt/data/experiments/EfficientCN/mnist/effcn_mnist_MnistEffCapsNet_2022_02_03_00_32_47\"\n",
    "#p_experiment = \"/mnt/data/experiments/EfficientCN/mnist/effcn_mnist_MnistCNN_R_2022_02_04_01_02_39\"\n",
    "p_experiment = Path(p_experiment)\n",
    "p_ckpts = p_experiment / \"ckpts\"\n",
    "p_data = Path(\"/mnt/data/datasets\")\n",
    "p_model = p_ckpts / \"model_150.ckpt\"\n",
    "p_model.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EffCapsNet()\n",
    "#model = MnistCNN_R()\n",
    "model.load_state_dict(torch.load(p_model))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kullbach-Leiber Divergence and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "ds_train = datasets.MNIST(root=p_data, train=train, download=True, transform=T.ToTensor())\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        #batch_size=len(ds_train), \n",
    "                                        batch_size=8, \n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(dl_train))\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affine_xtrans(img, target, range=[-5.,5.,1]):\n",
    "    arange = np.arange(range[0],(range[1]+range[2]),range[2])\n",
    "    x_trans = torch.zeros([len(arange),img.shape[-3],img.shape[-2],img.shape[-1]])\n",
    "    l_target = torch.zeros(len(arange))\n",
    "\n",
    "    for i, l in enumerate(arange):\n",
    "        x_trans[i] = T.functional.affine(img=img, angle=0, translate=[l,0], scale=1.,shear=0)\n",
    "        l_target[i] = target\n",
    "    \n",
    "    return x_trans, l_target\n",
    "\n",
    "def affine_ytrans(img, target, range=[-5.,5.,1]):\n",
    "    arange = np.arange(range[0],(range[1]+range[2]),range[2])\n",
    "    y_trans = torch.zeros([len(arange),img.shape[-3],img.shape[-2],img.shape[-1]])\n",
    "    l_target = torch.zeros(len(arange))\n",
    "\n",
    "    for i, l in enumerate(arange):\n",
    "        y_trans[i] = T.functional.affine(img=img, angle=0, translate=[0,l], scale=1.,shear=0)\n",
    "        l_target[i] = target\n",
    "    \n",
    "    return y_trans, l_target\n",
    "\n",
    "def affine_rot(img, target, range=[-25.,25.,1]):\n",
    "    arange = np.arange(range[0],(range[1]+range[2]),range[2])\n",
    "    rot = torch.zeros([len(arange),img.shape[-3],img.shape[-2],img.shape[-1]])\n",
    "    l_target = torch.zeros(len(arange))\n",
    "\n",
    "    for i, l in enumerate(arange):\n",
    "        rot[i] = T.functional.affine(img=img, angle=l, translate=[0,0], scale=1.,shear=0)\n",
    "        l_target[i] = target\n",
    "    \n",
    "    return rot, l_target\n",
    "\n",
    "def affine_scale(img, target, range=[0.75,1.25,0.05]):\n",
    "    arange = np.arange(range[0],(range[1]+range[2]),range[2])\n",
    "    scale = torch.zeros([len(arange),img.shape[-3],img.shape[-2],img.shape[-1]])\n",
    "    l_target = torch.zeros(len(arange))\n",
    "\n",
    "    for i, l in enumerate(arange):\n",
    "        scale[i] = T.functional.affine(img=img, angle=0, translate=[0,0], scale=l,shear=0)\n",
    "        l_target[i] = target\n",
    "    \n",
    "    return scale, l_target\n",
    "\n",
    "def affine_shear(img, target, range=[-10.,10.,2]):\n",
    "    arange = np.arange(range[0],(range[1]+range[2]),range[2])\n",
    "    shear = torch.zeros([len(arange),img.shape[-3],img.shape[-2],img.shape[-1]])\n",
    "    l_target = torch.zeros(len(arange))\n",
    "\n",
    "    for i, l in enumerate(arange):\n",
    "        shear[i] = T.functional.affine(img=img, angle=0, translate=[0,0], scale=1,shear=l)\n",
    "        l_target[i] = target\n",
    "    \n",
    "    return shear, l_target    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_aff, y_aff = affine_xtrans(x[0],y[0], range=[-2.,2.,0.5])\n",
    "\n",
    "x_aff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_uh_trans(uh):\n",
    "    \"\"\"\n",
    "    uh in [k,n,m]\n",
    "    k -> number of transformed images\n",
    "    n -> number of output classes\n",
    "    m -> number of capsul values\n",
    "    \"\"\"\n",
    "\n",
    "    uh_mean = uh.mean(dim=0)\n",
    "    z = uh - uh_mean\n",
    "    c_k = torch.einsum('...ij, ...ik -> ...jk', z,z)\n",
    "    c = torch.einsum('ijk -> jk', c_k) / c_k.shape[0]\n",
    "\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Test for model = MnistCNN_R()\n",
    "\n",
    "affine = affine_xtrans\n",
    "\n",
    "#generate aff transforms\n",
    "x_aff, y_aff = affine(x[0],y[0])\n",
    "\n",
    "#Generate Caps from affine Transform\n",
    "x_aff = x_aff.to(device)\n",
    "uh_aff, _ = model.forward(x_aff)\n",
    "\n",
    "\n",
    "print(uh_aff.shape)\n",
    "print(uh_aff)\n",
    "print(y_aff)\n",
    "\n",
    "\n",
    "\n",
    "#KL-Divergence\n",
    "uh_aff_th = uh_aff[:,y[0]]\n",
    "#Variance over each dimension\n",
    "var_uh_aff = torch.var(uh_aff_th, dim=EcnDecoder0)\n",
    "#Kullback-Leibler-Divergenz\n",
    "kl = (var_uh_aff * torch.log((var_uh_aff/0.1)))\n",
    "#kl_div.append(kl.tolist())\n",
    "\n",
    "\n",
    "print(uh_aff_th)\n",
    "print(uh_aff_th.shape)\n",
    "print(var_uh_aff)\n",
    "print(var_uh_aff.sum())\n",
    "print(torch.log((var_uh_aff/1)))\n",
    "print(kl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = affine_rot\n",
    "kl_div = []\n",
    "\n",
    "pbar = tqdm(dl_train, bar_format='{bar:10}{r_bar}{bar:-10b}')\n",
    "\n",
    "#load batchwise\n",
    "for x, y in pbar:\n",
    "    #calculate staistical vals\n",
    "    for i, img in enumerate(x):\n",
    "        #generate aff transforms\n",
    "        x_aff, y_aff = affine(x[i],y[i])\n",
    "        \n",
    "        #Generate Caps from affine Transform\n",
    "        x_aff = x_aff.to(device)\n",
    "        uh_aff, _ = model.forward(x_aff)\n",
    "\n",
    "        #KL-Divergence\n",
    "        uh_aff_th = uh_aff[:,y[i]]\n",
    "        #Variance over each dimension\n",
    "        var_uh_aff = torch.var(uh_aff_th, dim=0)\n",
    "        #Kullback-Leibler-Divergenz\n",
    "        kl = (var_uh_aff * torch.log((var_uh_aff)))\n",
    "        kl_div.append(kl.tolist())\n",
    "\n",
    "\n",
    "kld_mean = torch.tensor(kl_div).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kld_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = affine_rot\n",
    "pca_eig = []\n",
    "kl_div = []\n",
    "\n",
    "pbar = tqdm(dl_train, bar_format='{bar:10}{r_bar}{bar:-10b}')\n",
    "\n",
    "#load batchwise\n",
    "for x, y in pbar:\n",
    "    #calculate staistical vals\n",
    "    for i, img in enumerate(x):\n",
    "        #generate aff transforms\n",
    "        x_aff, y_aff = affine(x[i],y[i])\n",
    "        \n",
    "        #Generate Caps from affine Transform\n",
    "        x_aff = x_aff.to(device)\n",
    "        uh_aff, _ = model.forward(x_aff)\n",
    "\n",
    "        #PCA\n",
    "        #Covariance from Caps\n",
    "        cov_uh = cov_uh_trans(uh_aff)\n",
    "        #Eigenvals\n",
    "        eig, v_eig = torch.linalg.eig(cov_uh)\n",
    "        sig = eig.float() / eig.float().sum()\n",
    "        #PCA eigenvalues\n",
    "        pca_eig.append(sig.tolist())\n",
    "\n",
    "\n",
    "        #KL-Divergence\n",
    "        #Caps from valid\n",
    "        uh_aff_th = uh_aff[:,y[i],:]\n",
    "        #Variance over each dimension\n",
    "        var_uh_aff = torch.var(uh_aff_th, dim=0)\n",
    "        #Variance normalized\n",
    "        nor_uh_aff = var_uh_aff / var_uh_aff.sum()\n",
    "        #uniform prior\n",
    "        uni_p = 1/nor_uh_aff.shape[0]\n",
    "        #Kullback-Leibler-Divergenz\n",
    "        kl = (nor_uh_aff * torch.log((nor_uh_aff/uni_p))).sum()\n",
    "        kl_div.append(kl.tolist())\n",
    "\n",
    "\n",
    "pca_mean = torch.tensor(pca_eig).mean(dim=0)\n",
    "kld_mean = torch.tensor(kl_div).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(kl_div))\n",
    "print(kld_mean)\n",
    "print(len(pca_eig))\n",
    "print(pca_mean)\n",
    "\n",
    "kl_div[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    \"model\": [str(p_model)],\n",
    "    \"dataset\": [str(p_data)],\n",
    "    \"train\": [train],\n",
    "    \"affine\": [affine.__name__],\n",
    "    \"pca\": {\n",
    "        'pca_eig': pca_eig,\n",
    "        'pca_mean': pca_mean,\n",
    "    },\n",
    "    \"kld\": {\n",
    "        'kld_val': kl_div,\n",
    "        'kld_mean': kld_mean,\n",
    "    }\n",
    "}\n",
    "s =  DottedDict(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =  DottedDict(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pprint.pp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_semcomp = Path(\"/mnt/data/experiments/EfficientCN/sem_comp\")\n",
    "p_stats = p_semcomp / 'semcomp_mnist_{tr}_{da}'.format(tr=affine.__name__, da=datetime.datetime.fromtimestamp(time.time()).strftime('%Y_%m_%d_%H_%M_%S'))\n",
    "\n",
    "mkdir_directories([p_stats], parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(p_stats /'stats.pkl', 'wb')\n",
    "pickle.dump(stats, file1)\n",
    "file1.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca_mean.detach().numpy(),\".\")\n",
    "plt.tick_params(colors=\"w\")\n",
    "plt.title(str(affine.__name__) + \", kld_mean: \" + str(kld_mean.item()),color=\"w\")\n",
    "\n",
    "plt.savefig(p_stats /'eigenvals_mean.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
