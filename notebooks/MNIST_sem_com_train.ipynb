{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint\n",
    "import hashlib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotted_dict import DottedDict\n",
    "from tqdm import tqdm\n",
    "#\n",
    "from effcn.layers import View#, Squash\n",
    "from effcn.functions import margin_loss, masking, margin_loss_cnn_r\n",
    "from effcn.models import MnistEffCapsNet, MnistEcnDecoder, MnistCNN_CR_SF, MnistCNN_CR, MnistCNN_R\n",
    "from effcn.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomAffine(\n",
    "        degrees=(-30, 30),\n",
    "        shear=(-30, 30),\n",
    "        # translate=(0.9, 0.9),\n",
    "    ),\n",
    "    T.RandomResizedCrop(\n",
    "        28,\n",
    "        scale=(0.8, 1.2),\n",
    "        ratio=(1, 1),\n",
    "    ),\n",
    "    T.ToTensor()\n",
    "])\n",
    "transform_valid = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds_train.data[0], cmap='gray')\n",
    "plt.title('%i' % ds_train.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                          batch_size=16, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=0):#1e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         IN:  (b, n, d)\n",
    "         OUT: squash(x(b,n,d))\n",
    "        \"\"\"\n",
    "        x_norm = torch.norm(x, dim=2, keepdim=True)\n",
    "        return (1 - 1 / (torch.exp(x_norm) + self.eps)) * (x / (x_norm + self.eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_CR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CR_Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=256,            \n",
    "                kernel_size=9,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(256, 256, 9, 2),     \n",
    "            nn.ReLU(),                                 \n",
    "        )\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 10 * 16)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)        \n",
    "        x = x.view(-1,10,16)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = CNN_CR_Backbone()\n",
    "        self.decoder = MnistEcnDecoder()\n",
    "\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def forward(self, x, y_true=None):\n",
    "        \"\"\"\n",
    "            IN:\n",
    "                x (b, 1, 28, 28)\n",
    "            OUT:\n",
    "                u_h\n",
    "                    (b, n_h, d_h)\n",
    "                    output caps\n",
    "                x_rec\n",
    "                    (b, 1, 28, 28)\n",
    "                    reconstruction of x\n",
    "        \"\"\"\n",
    "\n",
    "        u_h = self.backbone(x)\n",
    "\n",
    "        u_h_masked = masking(u_h, y_true)\n",
    "        x_rec = self.decoder(u_h_masked)\n",
    "\n",
    "        return u_h, x_rec      \n",
    "\n",
    "    def initialize_weights(self):\n",
    "        print('hi {}'.format(self.backbone.conv2[0].weight.std()))\n",
    "        nn.init.kaiming_uniform_(self.backbone.conv2[0].weight)\n",
    "        print('hi {}'.format(self.backbone.conv2[0].weight.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_CR_SF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CR_SF_Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=256,            \n",
    "                kernel_size=9,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(256, 256, 9, 2),     \n",
    "            nn.ReLU(),                                 \n",
    "        )\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 16 * 8)\n",
    "        self.sq = Squash(eps=1e-20)\n",
    "        self.fc2 =  nn.Linear(16 * 8, 16 * 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = x.view(-1,16,8)\n",
    "        x = self.sq(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc2(x)\n",
    "        x = x.view(-1,10,16)\n",
    "        x = self.sq(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_CR_SF(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = CNN_CR_SF_Backbone()\n",
    "        self.decoder = MnistEcnDecoder()\n",
    "\n",
    "    def forward(self, x, y_true=None):\n",
    "        \"\"\"\n",
    "            IN:\n",
    "                x (b, 1, 28, 28)\n",
    "            OUT:\n",
    "                u_h\n",
    "                    (b, n_h, d_h)\n",
    "                    output caps\n",
    "                x_rec\n",
    "                    (b, 1, 28, 28)\n",
    "                    reconstruction of x\n",
    "        \"\"\"\n",
    "\n",
    "        u_h = self.backbone(x)\n",
    "\n",
    "        u_h_masked = masking(u_h, y_true)\n",
    "        x_rec = self.decoder(u_h_masked)\n",
    "\n",
    "        return u_h, x_rec "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_R_Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=256,            \n",
    "                kernel_size=9,              \n",
    "                stride=1,                   \n",
    "                padding=0,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(256, 256, 9, 2),     \n",
    "            nn.ReLU(),                                 \n",
    "        )\n",
    "        self.fc1 = nn.Linear(256 * 6 * 6, 10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)        \n",
    "        x = x.view(-1,10)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_R_Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "        Decoder model from Efficient-CapsNet for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(10, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, 28 * 28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            IN:\n",
    "                x (b, n, d) with n=10 and d=16\n",
    "            OUT:\n",
    "                x_rec (b, 1, 28, 28)\n",
    "            Notes:\n",
    "                input must be masked!\n",
    "        \"\"\"\n",
    "        x = self.layers(x)\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_R(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = CNN_R_Backbone()\n",
    "        self.decoder = CNN_R_Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            IN:\n",
    "                x (b, 1, 28, 28)\n",
    "            OUT:\n",
    "                u_h\n",
    "                    (b, n_h, d_h)\n",
    "                    output caps\n",
    "                x_rec\n",
    "                    (b, 1, 28, 28)\n",
    "                    reconstruction of x\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred = self.backbone(x)\n",
    "        x_rec = self.decoder(y_pred)\n",
    "\n",
    "        return y_pred, x_rec        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss_cnn_r(u, y_true, lbd=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "        u      (b,n,d)  ... capsules with n equals the numbe of classes\n",
    "        y_true (b,n)    .... labels vector, categorical representation\n",
    "    OUT:\n",
    "        loss, scalar\n",
    "    \"\"\"\n",
    "\n",
    "    #u_norm = torch.norm(u, dim=2)\n",
    "    term_left = torch.square(F.relu(m_plus - u))\n",
    "    term_right = torch.square(F.relu(u - m_minus))\n",
    "    #\n",
    "    loss = y_true * term_left + lbd * (1.0 - y_true) * term_right\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_CR()\n",
    "a = model.backbone.conv1[0].weight\n",
    "print(a.std())\n",
    "print(a.mean())\n",
    "print(a.max())\n",
    "print(a.min())\n",
    "print((a.max()-a.min())/a.std())\n",
    "nn.init.kaiming_uniform_(a)\n",
    "print(a.std())\n",
    "print(a.mean())\n",
    "print(a.max())\n",
    "print(a.min())\n",
    "print((a.max()-a.min())/a.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MnistCNN_CR_SF()\n",
    "model = MnistCNN_CR()\n",
    "img, y = next(iter(dl_train))\n",
    "\n",
    "u, rec = model(img)\n",
    "\n",
    "print(img.shape)\n",
    "print(u.shape)\n",
    "print(y.shape)\n",
    "\n",
    "y_one_hot = F.one_hot(y, num_classes=10)\n",
    "print(y_one_hot.shape)\n",
    "print(margin_loss(u, y_one_hot))\n",
    "print(rec.shape)\n",
    "\n",
    "print(u.max())\n",
    "print(u.min())\n",
    "print(u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MnistCNN_R()\n",
    "img, y = next(iter(dl_train))\n",
    "u, rec = model(img)\n",
    "\n",
    "print(img.shape)\n",
    "print(u.shape)\n",
    "print(y.shape)\n",
    "\n",
    "y_one_hot = F.one_hot(y, num_classes=10)\n",
    "print(y_one_hot)\n",
    "print(margin_loss_cnn_r(u, y_one_hot))\n",
    "print(rec.shape)\n",
    "\n",
    "print(u.max())\n",
    "print(u.min())\n",
    "print(u.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#ccn shape tp caps shape\n",
    "z = torch.zeros([1, 256, 6, 6])\n",
    "z.fill_(1)\n",
    "z = torch.flatten(z, start_dim=1)\n",
    "z = nn.Linear(256 * 6 * 6, 16 * 8)(z)\n",
    "z = z.view(-1,16,8)\n",
    "z.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = MnistCNN_R()\n",
    "model = MnistCNN_CR()\n",
    "#model = MnistCNN_CR_SF()\n",
    "#model = MnistEffCapsNet()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "if model.__class__.__name__ == \"CNN_R\":\n",
    "    print('fine')\n",
    "else:\n",
    "    print('bla')\n",
    "model.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"#params: {}\".format(count_parameters(model)))\n",
    "optimizer = optim.Adam(model.parameters(), lr = 5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch_idx in range(1, num_epochs+1):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "\n",
    "        # clear gradients for this training step   \n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        \n",
    "        u_h, x_rec = model.forward(x)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=10)\n",
    "        if model.__class__.__name__ == \"MnistCNN_R\":\n",
    "            loss_margin = margin_loss_cnn_r(u_h, y_one_hot)\n",
    "        else:\n",
    "            loss_margin = margin_loss(u_h, y_one_hot)\n",
    "        loss_rec = torch.nn.functional.mse_loss(x, x_rec)\n",
    "        \n",
    "        # param from paper\n",
    "        loss = loss_margin + 0.392 * loss_rec\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if model.__class__.__name__ == \"MnistCNN_R\":\n",
    "            y_pred = torch.argmax(u_h, dim=1)\n",
    "        else:        \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "\n",
    "        batch_correct = (y_true == y_pred).sum()\n",
    "        batch_total = y_true.shape[0]\n",
    "        acc = batch_correct / batch_total\n",
    "\n",
    "        epoch_correct += batch_correct\n",
    "        epoch_total += batch_total\n",
    "\n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                    'mar': loss_margin.item(),\n",
    "                    'rec': loss_rec.item(),\n",
    "                    'acc': acc.item()\n",
    "                }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "    \n",
    "epoch_correct = 0\n",
    "epoch_total = 0\n",
    "\n",
    "for x,y_true in dl_valid:\n",
    "    x = x.to(device)\n",
    "    y_true = y_true.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        u_h, x_rec = model.forward(x)\n",
    "        if model.__class__.__name__ == \"MnistCNN_R\":\n",
    "            y_pred = torch.argmax(u_h, dim=1)\n",
    "        else:        \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "\n",
    "        epoch_correct += (y_true == y_pred).sum()\n",
    "        epoch_total += y_true.shape[0]\n",
    "\n",
    "print(\"   acc_valid: {:.5f}\".format(epoch_correct / epoch_total))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vis, y_vis = next(iter(dl_valid))\n",
    "with torch.no_grad():\n",
    "    _, x_rec = model.forward(x_vis.to(device))\n",
    "x_rec = x_rec.cpu()\n",
    "img = torchvision.utils.make_grid(torch.cat([x_vis[:16], x_rec[:16]], dim=0), nrow=16)\n",
    "img = img.permute(1,2,0)\n",
    "plt.figure(figsize=(16, 2))\n",
    "plt.tight_layout()\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
