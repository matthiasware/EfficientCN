{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07aa17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05ac9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9449851a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ds_train.data[0], cmap='gray')\n",
    "plt.title('%i' % ds_train.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50988be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                          batch_size=16, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a9dfd",
   "metadata": {},
   "source": [
    "# Baseline CNN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c90ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5277cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cdf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e005f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkoch\\anaconda3\\envs\\EfficientCN\\lib\\site-packages\\torch\\autograd\\__init__.py:154: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 8000). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  ..\\c10\\cuda\\CUDAFunctions.cpp:112.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[0/10] - step 0 loss: 2.3075\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (x, y_true) in enumerate(dl_train):\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y_true)\n",
    "\n",
    "        # clear gradients for this training step   \n",
    "        optimizer.zero_grad()           \n",
    "            \n",
    "        # backpropagation, compute gradients \n",
    "        loss.backward()    \n",
    "        # apply gradients             \n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(\"Epoch[{}/{}] - step {} loss: {:.4f}\".format(epoch, num_epochs, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y_true in dl_valid:\n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.max(y_pred, 1)[1]\n",
    "        correct += (y_pred == y_true).sum().item()\n",
    "        total += y_true.shape[0]\n",
    "    acc = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(total - correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c175ff9",
   "metadata": {},
   "source": [
    "# Eff-Caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb078de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "        Create a primary capsule layer with the methodology described in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'. \n",
    "        Properties of each capsule s_n are exatracted using a 2D depthwise convolution.\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        F: int depthwise conv number of features\n",
    "        K: int depthwise conv kernel dimension \n",
    "        N: int number of primary capsules\n",
    "        D: int primary capsules dimension (number of properties)\n",
    "        s: int depthwise conv strides\n",
    "    \"\"\"\n",
    "    def __init__(self, F, K, N, D, s=1):\n",
    "        super().__init__()\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.s = s\n",
    "        #\n",
    "        self.dw_conv2d = nn.Conv2d(F, F, kernel_size=K, stride=s, groups=F, padding=\"valid\")\n",
    "        #\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         X in (B,C,H,W) = (B,F,K,K)\n",
    "         -> (B, N, D)\n",
    "        \"\"\"\n",
    "        # (B,C,H,W) -> (B,C,H,W)\n",
    "        x = self.dw_conv2d(x)\n",
    "\n",
    "        # (B,C,H,W) -> (B, N, D)\n",
    "        x = x.view((-1, self.N, self.D))\n",
    "        \n",
    "        #\n",
    "        return x\n",
    "\n",
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=10e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class FCCaps(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forware(self, x):\n",
    "        raise NoteImplementedError()\n",
    "\n",
    "class EfficientCapsNets(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d90430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Part\n",
    "# add he normal initializer\n",
    "cn = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=(5, 5), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Conv2d(32, 64, kernel_size=(3, 3), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 64, kernel_size=(3, 3), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 128, kernel_size=(3, 3), stride=2, padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(128),\n",
    ")\n",
    "x_h = cn(x)\n",
    "print(x_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18307385",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PrimaryCaps(F=128, K=9, N=16, D=8)\n",
    "#\n",
    "z = pc(x_h)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63828ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view((-1, 16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b02479",
   "metadata": {},
   "outputs": [],
   "source": [
    "z.view((-1, 16, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8af806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n, d = 4, 3\n",
    "eps = 10e-21\n",
    "s = torch.rand((n, d))\n",
    "s_norm = torch.linalg.vector_norm(s, dim=1)\n",
    "#\n",
    "print(s.shape)\n",
    "print(s_norm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a926a8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TensorFlow Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a148f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Squash activation used in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    eps: int\n",
    "        fuzz factor used in numeric expression\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    call(s)\n",
    "        compute the activation from input capsules\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps=10e-21, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def call(self, s):\n",
    "        n = tf.norm(s,axis=-1,keepdims=True)\n",
    "        return (1 - 1/(tf.math.exp(n)+self.eps))*(s/(n+self.eps))\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config}\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Create a primary capsule layer with the methodology described in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'. \n",
    "    Properties of each capsule s_n are exatracted using a 2D depthwise convolution.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    F: int\n",
    "        depthwise conv number of features\n",
    "    K: int\n",
    "        depthwise conv kernel dimension\n",
    "    N: int\n",
    "        number of primary capsules\n",
    "    D: int\n",
    "        primary capsules dimension (number of properties)\n",
    "    s: int\n",
    "        depthwise conv strides\n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs)\n",
    "        compute the primary capsule layer\n",
    "    \"\"\"\n",
    "    def __init__(self, F, K, N, D, s=1, **kwargs):\n",
    "        super(PrimaryCaps, self).__init__(**kwargs)\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.s = s\n",
    "        \n",
    "    def build(self, input_shape):    \n",
    "        self.DW_Conv2D = tf.keras.layers.Conv2D(self.F, self.K, self.s,\n",
    "                                             activation='linear', groups=self.F, padding='valid')\n",
    "\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs):      \n",
    "        x = self.DW_Conv2D(inputs)      \n",
    "        x = tf.keras.layers.Reshape((self.N, self.D))(x)\n",
    "        x = Squash()(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4274cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCCaps(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Fully-connected caps layer. It exploites the routing mechanism, explained in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing', \n",
    "    to create a parent layer of capsules. \n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    N: int\n",
    "        number of primary capsules\n",
    "    D: int\n",
    "        primary capsules dimension (number of properties)\n",
    "    kernel_initilizer: str\n",
    "        matrix W initialization strategy\n",
    " \n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs)\n",
    "        compute the primary capsule layer\n",
    "    \"\"\"\n",
    "    def __init__(self, N, D, kernel_initializer='he_normal', **kwargs):\n",
    "        super(FCCaps, self).__init__(**kwargs)\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initializer)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        input_N = input_shape[-2]\n",
    "        input_D = input_shape[-1]\n",
    "\n",
    "        self.W = self.add_weight(shape=[self.N, input_N, input_D, self.D],initializer=self.kernel_initializer,name='W')\n",
    "        self.b = self.add_weight(shape=[self.N, input_N,1], initializer=tf.zeros_initializer(), name='b')\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        \n",
    "        # j=n\n",
    "        # i=d\n",
    "        # k=n\n",
    "        # z=d\n",
    "        # inputs(n, d)\n",
    "        # W(n,n,d,d)\n",
    "        # u(n,n,d)\n",
    "        u = tf.einsum('...ji,kjiz->...kjz',inputs,self.W)         # u shape=(None,N,H*W*input_N,D)\n",
    "             \n",
    "        c = tf.einsum('...ij,...kj->...i', u, u)[...,None]        # b shape=(None,N,H*W*input_N,1) -> (None,j,i,1)\n",
    "        c = c/tf.sqrt(tf.cast(self.D, tf.float32))\n",
    "        c = tf.nn.softmax(c, axis=1)                              # c shape=(None,N,H*W*input_N,1) -> (None,j,i,1)\n",
    "        c = c + self.b\n",
    "        s = tf.reduce_sum(tf.multiply(u, c),axis=-2)             # s shape=(None,N,D)\n",
    "        v = Squash()(s)       # v shape=(None,N,D)\n",
    "        \n",
    "        return v\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.C, self.L)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'N': self.N,\n",
    "            'D': self.D\n",
    "        }\n",
    "        base_config = super(FCCaps, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "\n",
    "class Length(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of each capsule n of a layer l.\n",
    "    ...\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs)\n",
    "        compute the length of each capsule\n",
    "    \"\"\"\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Compute the length of each capsule\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        inputs: tensor\n",
    "           tensor with shape [None, num_capsules (N), dim_capsules (D)]\n",
    "        \"\"\"\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(inputs), - 1) + tf.keras.backend.epsilon())\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config\n",
    "\n",
    "class Mask(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask operation described in 'Dynamic routinig between capsules'.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs, double_mask)\n",
    "        mask a capsule layer\n",
    "        set double_mask for multimnist dataset\n",
    "    \"\"\"\n",
    "    def call(self, inputs, double_mask=None, **kwargs):\n",
    "        if type(inputs) is list:\n",
    "            if double_mask:\n",
    "                inputs, mask1, mask2 = inputs\n",
    "            else:\n",
    "                inputs, mask = inputs\n",
    "        else:  \n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))\n",
    "            if double_mask:\n",
    "                mask1 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,0],num_classes=x.get_shape().as_list()[1])\n",
    "                mask2 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,1],num_classes=x.get_shape().as_list()[1])\n",
    "            else:\n",
    "                mask = tf.keras.backend.one_hot(indices=tf.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        if double_mask:\n",
    "            masked1 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask1, -1))\n",
    "            masked2 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask2, -1))\n",
    "            return masked1, masked2\n",
    "        else:\n",
    "            masked = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "            return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  \n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # generation step\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a7fc63-7c51-422b-8e38-91b4b2463c4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pytorch implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbe646e-6852-4fa8-8b6e-18f791739ba9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Squashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "24216ee1-379a-433e-9c5a-9a069ccef30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_fun(x,eps=10e-21):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        x(b,n,d)\n",
    "    Output:\n",
    "        y = squash(x(b,n,d))\n",
    "    \"\"\"\n",
    "    \n",
    "    x_norm = torch.norm(x, dim=-1, keepdim=True)\n",
    "    y = (1 - 1/torch.exp(x_norm) + eps) * (x/x_norm + eps)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30255cd4-5eee-4c18-a73b-5c094685c340",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'U_h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-4bb482387912>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msquash_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msquash_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m3.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'U_h' is not defined"
     ]
    }
   ],
   "source": [
    "print(squash_fun(U_h))\n",
    "print(squash_fun(torch.tensor([[1., 2., 1.], [-1., 2., -3.], [0.,1.,-2.]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9336d744-a8fc-4b12-be06-855d038adc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self,eps=10e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Input:  x(b,n,d)\n",
    "        Output: squash(x(b,n,d))\n",
    "        \"\"\"        \n",
    "        return squash_fun(x,self.eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a10f7f9c-10f6-43b5-9329-ebcd52698033",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'U_h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ebeedb8d93bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSquash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mU_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'U_h' is not defined"
     ]
    }
   ],
   "source": [
    "A = Squash()\n",
    "\n",
    "print(A.forward(U_h))\n",
    "print(A(U_h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466fb93-41f0-4b75-90f9-cb0abd0dfa48",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FC Caps + Self Attention Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "48020284-d1eb-4302-8155-3229f0aedeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully-connected caps layer. It exploites the routing mechanism, explained in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing', \n",
    "    to create a parent layer of capsules. \n",
    "    \n",
    "    nl: number of input capsuls          (nl...i)(nl...h)\n",
    "    dl: dimension of input capsuls       (dl...j)\n",
    "    nh: number of output capsuls         (nh...k)\n",
    "    dh: dimension of output capsuls      (dh...l)\n",
    "    b: batch size                        (...)\n",
    "\n",
    "    W: weigth tensor                     (W->ikjl)\n",
    "    B: bias matrix                       (B->ik1)\n",
    "    U_l: input capsuls matrix            (U->...ij)    \n",
    "    U_hat: weigthed input capsuls matrix (U_hat->...ikl)\n",
    "    A: covariance tensor                 (A->...hik)\n",
    "    C: couplimg coefficients             (C->...ik)\n",
    "    \n",
    "    input: nl, dl, nh, dh\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, nl, dl, nh, dh):\n",
    "        super().__init__()\n",
    "        self.nl = nl\n",
    "        self.dl = dl\n",
    "        self.nh = nh\n",
    "        self.dh = dh\n",
    "\n",
    "        self.W = torch.rand([self.nl,self.nh,self.dl,self.dh])\n",
    "        self.B = torch.rand([1,self.nl,self.nh])\n",
    "        \n",
    "        self.squash = Squash()\n",
    "                \n",
    "        \n",
    "    def forward(self, U_l):\n",
    "        U_hat = torch.einsum(\"...ij,ikjl->...ikl\",U_l,self.W)\n",
    "        A = torch.einsum(\"...hkl,...ikl->...hik\",U_hat, U_hat)\n",
    "        A = A / torch.sqrt(torch.Tensor([self.dl]))\n",
    "        A_hat = torch.einsum(\"...hik->...ik\",A)\n",
    "        C = torch.softmax(A_hat,dim=-1)\n",
    "        CB = C+self.B\n",
    "        U_h = torch.einsum(\"...ikl,...ik->...kl\",U_hat,CB)\n",
    "        U_h = self.squash(U_h)\n",
    "        return U_h\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e2284ced-b636-40af-b4c9-d7ed265deeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "         [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "         [0.4556, 0.6323, 0.3489, 0.4017]],\n",
      "\n",
      "        [[0.0223, 0.1689, 0.2939, 0.5185],\n",
      "         [0.6977, 0.8000, 0.1610, 0.2823],\n",
      "         [0.6816, 0.9152, 0.3971, 0.8742]]])\n",
      "tensor([[[0.5000, 0.2828, 0.5209, 0.4214, 0.4531],\n",
      "         [0.2448, 0.4859, 0.6130, 0.4353, 0.3700]],\n",
      "\n",
      "        [[0.5355, 0.2815, 0.4004, 0.3977, 0.5589],\n",
      "         [0.3317, 0.4814, 0.5511, 0.3910, 0.4369]]])\n",
      "torch.Size([2, 2, 5])\n",
      "3 2 4 5\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "input_dim = (2,3,4)\n",
    "U_l = torch.rand(size=input_dim)\n",
    "A = FCCaps(3,4,2,5)\n",
    "U_h = A.forward(U_l)\n",
    "\n",
    "print(U_l)\n",
    "print(U_h)\n",
    "print(U_h.size())\n",
    "print(A.nl,A.nh,A.dl, A.dh)\n",
    "\n",
    "#print(A.U_hat.size())\n",
    "#print(A.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563337ab-8525-43e0-83b5-2fe8b67732dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 4==4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67194b63-6149-4c15-a3f1-da2e5ba5fe61",
   "metadata": {},
   "source": [
    "# PrimaryCaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ece001-52d2-41e6-bf76-cac469037b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "        Create a primary capsule layer with the methodology described in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'. \n",
    "        Properties of each capsule s_n are exatracted using a 2D depthwise convolution.\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        F: int depthwise conv number of features\n",
    "        K: int depthwise conv kernel dimension \n",
    "        N: int number of primary capsules\n",
    "        D: int primary capsules dimension (number of properties)\n",
    "        s: int depthwise conv strides\n",
    "    \"\"\"\n",
    "    def __init__(self, F, K, N, D, s=1):\n",
    "        super().__init__()\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.s = s\n",
    "        #\n",
    "        self.dw_conv2d = nn.Conv2d(F, F, kernel_size=K, stride=s, groups=F, padding=\"valid\")\n",
    "        self.squash = Squash()\n",
    "        #\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         X in (B,C,H,W) = (B,F,K,K)\n",
    "         -> (B, N, D)\n",
    "        \"\"\"\n",
    "        # (B,C,H,W) -> (B,C,H,W)\n",
    "        x = self.dw_conv2d(x)\n",
    "        # (B,C,H,W) -> (B, N, D)\n",
    "        x = x.view((-1, self.N, self.D))\n",
    "        x = self.squash(x)\n",
    "        #\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1567ac0b-f0df-4dfe-98fa-857d2f15b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = PrimaryCaps(10,3,4,5)\n",
    "x = torch.rand((8,10,8,8))\n",
    "B(x).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaabd973-20c1-4fb6-8bd4-b624eba16e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(10*8*6*6)\n",
    "print(144*4*5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31745624-b730-4232-9e32-dbf68c35168d",
   "metadata": {},
   "source": [
    "# Margin Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab60580-50a2-4a2c-86c8-26649d716004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0724023e-5d36-49ec-8449-868a020bc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marginLoss(y_true, y_pred):\n",
    "    lbd = 0.5\n",
    "    m_plus = 0.9\n",
    "    m_minus = 0.1\n",
    "    \n",
    "    L = y_true * tf.square(tf.maximum(0., m_plus - y_pred)) +  lbd * (1 - y_true) * tf.square(tf.maximum(0., y_pred - m_minus))\n",
    "\n",
    "    return tf.reduce_mean(tf.reduce_sum(L, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47242160-138e-417f-9d82-17cb54fefc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[0.4963 0.7682 0.0885 0.132  0.3074]\n",
      "  [0.6341 0.4901 0.8964 0.4556 0.6323]]\n",
      "\n",
      " [[0.3489 0.4017 0.0223 0.1689 0.2939]\n",
      "  [0.5185 0.6977 0.8    0.161  0.2823]]], shape=(2, 2, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1.1304001  1.2583     0.9849     0.5876     0.9397    ]\n",
      " [0.86739993 1.0994     0.8223     0.3299     0.5762    ]], shape=(2, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_true = tf.constant([1,1])\n",
    "\n",
    "u = tf.constant(([[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
    "                   [0.6341, 0.4901, 0.8964, 0.4556, 0.6323]],\n",
    "                  [[0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
    "                   [0.5185, 0.6977, 0.8000, 0.1610, 0.2823]]]))\n",
    "print(u)\n",
    "u = tf.reduce_sum(u, axis=1)\n",
    "\n",
    "\n",
    "print(u)\n",
    "#marginLoss(y_true,u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42eaaffe-9a56-4a47-91ab-ca88a62b4da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(u, y_true, lbd=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    \"\"\"\n",
    "    Input:  u      (b,n,d)  ... capsules with n equals the numbe of classes\n",
    "            y_true (b,n)    ... labels vector, categorical representation\n",
    "    Output:\n",
    "        loss, scalar  \n",
    "    \"\"\"\n",
    "    \n",
    "    u_norm = torch.norm(u, dim=-1)\n",
    "    p_true = torch.square(F.relu(m_plus - u_norm))\n",
    "    p_false = torch.square(F.relu(u_norm - m_minus))\n",
    "\n",
    "    loss = y_true * p_true + lbd * (1-y_true) * p_false\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5965d837-3df0-446d-9653-bbed34a5392a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "         [0.6341, 0.4901, 0.8964, 0.4556, 0.6323]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.3853)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "y_true = torch.tensor([0,1])\n",
    "u = torch.rand((1,2,5))\n",
    "print(u)\n",
    "margin_loss(u, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f63f1ce-669f-4a64-8a44-5dfa603b76f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_lossM(u, y_true, lbd=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "        u      (b,n,d)  ... capsules with n equals the numbe of classes\n",
    "        y_true (b,n)    .... labels vector, categorical representation\n",
    "    OUT:\n",
    "        loss, scalar  \n",
    "    \"\"\"\n",
    "    u_norm = torch.norm(u, dim=2)\n",
    "    \n",
    "    print(u_norm)\n",
    "    term_left  = F.relu(m_plus - u_norm)\n",
    "    print(term_left)\n",
    "    term_right = F.relu(u_norm - m_minus)\n",
    "    #\n",
    "    loss = y_true * term_left + lbd * (1.0 - y_true) * term_right\n",
    "    print(loss)\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "    print(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a17e8a7-6810-499d-9693-ad20c1298680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "         [0.6341, 0.4901, 0.8964, 0.4556, 0.6323]]])\n",
      "tensor([[0.9779, 1.4329]])\n",
      "tensor([[0., 0.]])\n",
      "tensor([[0.4389, 0.0000]])\n",
      "tensor(0.4389)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4389)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "y_true = torch.tensor([0,1])\n",
    "u = torch.rand((1,2,5))\n",
    "print(u)\n",
    "margin_lossM(u, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e988e9-91f1-401a-b288-0c4f20a1e653",
   "metadata": {},
   "source": [
    "# masked reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "070fbf63-cfec-40fe-8233-de1bf7c113c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_masking(u):\n",
    "    \"\"\"\n",
    "     Input: u (b, n, d)\n",
    "     normalise over dimension d\n",
    "     keep largest vector in dimension n\n",
    "     mask out everything else\n",
    "     Output: u_mask (b, n, d)\n",
    "    \"\"\"\n",
    "    _, n_classes, _ = u.shape\n",
    "    u_norm = torch.norm(u,dim=2)\n",
    "    mask = F.one_hot(torch.argmax(u_norm,1), num_classes=n_classes)\n",
    "    u_mask = torch.einsum('bnd,bn->bnd',u, mask)\n",
    "    return u_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fbdc2ec-7b23-4525-a30d-cdd02e243a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4963, 0.7682, 0.0885, 0.1320, 0.3074],\n",
      "         [0.6341, 0.4901, 0.8964, 0.4556, 0.6323],\n",
      "         [0.3489, 0.4017, 0.0223, 0.1689, 0.2939],\n",
      "         [0.5185, 0.6977, 0.8000, 0.1610, 0.2823],\n",
      "         [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]],\n",
      "\n",
      "        [[0.5529, 0.9527, 0.0362, 0.1852, 0.3734],\n",
      "         [0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "         [0.0317, 0.2081, 0.9298, 0.7231, 0.7423],\n",
      "         [0.5263, 0.2437, 0.5846, 0.0332, 0.1387],\n",
      "         [0.2422, 0.8155, 0.7932, 0.2783, 0.4820]],\n",
      "\n",
      "        [[0.8198, 0.9971, 0.6984, 0.5675, 0.8352],\n",
      "         [0.2056, 0.5932, 0.1123, 0.1535, 0.2417],\n",
      "         [0.7262, 0.7011, 0.2038, 0.6511, 0.7745],\n",
      "         [0.4369, 0.5191, 0.6159, 0.8102, 0.9801],\n",
      "         [0.1147, 0.3168, 0.6965, 0.9143, 0.9351]]])\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.6816, 0.9152, 0.3971, 0.8742, 0.4194]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0317, 0.2081, 0.9298, 0.7231, 0.7423],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.8198, 0.9971, 0.6984, 0.5675, 0.8352],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "u = torch.rand((3,5,5))\n",
    "print(u)\n",
    "a = max_norm_masking(u)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ab228-adcb-440e-b7d8-3eef328aa1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
