{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "'''\n",
    "The Capsules layer.\n",
    "@author: Yuxian Meng\n",
    "'''\n",
    "#TODO: use less permute() and contiguous()\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from math import floor, pi\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "#from time import time\n",
    "\n",
    "import argparse\n",
    "from torchvision import datasets, transforms\n",
    "from dotted_dict import DottedDict\n",
    "\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Primary Capsule layer is nothing more than concatenate several convolutional\n",
    "    layer together.\n",
    "    Args:\n",
    "        A:input channel\n",
    "        B:number of types of capsules.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self,A=32, B=32):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.B = B\n",
    "        self.capsules_pose = nn.ModuleList([nn.Conv2d(in_channels=A,out_channels=4*4,\n",
    "                                                 kernel_size=1,stride=1) \n",
    "                                                 for i in range(self.B)])\n",
    "        self.capsules_activation = nn.ModuleList([nn.Conv2d(in_channels=A,out_channels=1,\n",
    "                                                 kernel_size=1,stride=1) for i \n",
    "                                                 in range(self.B)])\n",
    "\n",
    "    def forward(self, x): #b,14,14,32\n",
    "        poses = [self.capsules_pose[i](x) for i in range(self.B)]#(b,16,12,12) *32\n",
    "        poses = torch.cat(poses, dim=1) #b,16*32,12,12\n",
    "        activations = [self.capsules_activation[i](x) for i in range(self.B)] #(b,1,12,12)*32\n",
    "        activations = F.sigmoid(torch.cat(activations, dim=1)) #b,32,12,12\n",
    "        output = torch.cat([poses, activations], dim=1)\n",
    "        return output\n",
    "\n",
    "class ConvCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Capsule Layer.\n",
    "    Args:\n",
    "        B:input number of types of capsules.\n",
    "        C:output number of types of capsules.\n",
    "        kernel: kernel of convolution. kernel=0 means the capsules in layer L+1's\n",
    "        receptive field contain all capsules in layer L. Kernel=0 is used in the \n",
    "        final ClassCaps layer.\n",
    "        stride:stride of convolution\n",
    "        iteration: number of EM iterations\n",
    "        coordinate_add: whether to use Coordinate Addition\n",
    "        transform_share: whether to share transformation matrix.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, B=32, C=32, kernel = 3, stride=2,iteration=3,\n",
    "                 coordinate_add=False, transform_share = False):\n",
    "        super(ConvCaps, self).__init__()\n",
    "        self.B =B\n",
    "        self.C=C\n",
    "        self.K=kernel # kernel = 0 means full receptive field like class capsules\n",
    "        self.stride = stride\n",
    "        self.coordinate_add=coordinate_add\n",
    "        self.transform_share = transform_share\n",
    "        self.beta_v = nn.Parameter(torch.randn(1))\n",
    "        self.beta_a = nn.Parameter(torch.randn(C)) #TODO: make sure whether beta_a depend on c \n",
    "        if not transform_share:\n",
    "            self.W = nn.Parameter(torch.randn(self.B, kernel,kernel,self.C, \n",
    "                                              4, 4)) #B,K,K,C,4,4\n",
    "        else:\n",
    "            self.W = nn.Parameter(torch.randn(self.B, self.C, 4, 4)) #B,C,4,4\n",
    "        self.iteration=iteration\n",
    "\n",
    "    def forward(self, x, lambda_,):\n",
    "#        t = time()\n",
    "        b = x.size(0) #batchsize\n",
    "        width_in = x.size(2)  #12\n",
    "        use_cuda = next(self.parameters()).is_cuda\n",
    "        pose = x[:,:-self.B,:,:].contiguous() #b,16*32,12,12\n",
    "        pose = pose.view(b,16,self.B,width_in,width_in).permute(0,2,3,4,1).contiguous() #b,B,12,12,16\n",
    "        activation = x[:,-self.B:,:,:] #b,B,12,12                    \n",
    "        w = width_out = int((width_in-self.K)/self.stride+1) if self.K else 1 #5\n",
    "        if self.transform_share:\n",
    "            if self.K == 0:\n",
    "                self.K = width_in # class Capsules' kernel = width_in\n",
    "            W = self.W.view(self.B,1,1,self.C,4,4).expand(self.B,self.K,self.K,self.C,4,4).contiguous()\n",
    "        else:\n",
    "            W = self.W #B,K,K,C,4,4\n",
    "            \n",
    "        #used to store every capsule i's poses in each capsule c's receptive field\n",
    "        poses = torch.stack([pose[:,:,self.stride*i:self.stride*i+self.K,\n",
    "                       self.stride*j:self.stride*j+self.K,:] for i in range(w) for j in range(w)], dim=-1) #b,B,K,K,w*w,16\n",
    "        poses = poses.view(b,self.B,self.K,self.K,1,w,w,4,4) #b,B,K,K,1,w,w,4,4\n",
    "        W_hat = W[None,:,:,:,:,None,None,:,:]                #1,B,K,K,C,1,1,4,4\n",
    "        votes = torch.matmul(W_hat, poses) #b,B,K,K,C,w,w,4,4\n",
    "        \n",
    "        #Coordinate Addition\n",
    "        add = [] #K,K,w,w\n",
    "        if self.coordinate_add:\n",
    "            for i in range(self.K):\n",
    "                for j in range(self.K):\n",
    "                    for x in range(w):\n",
    "                        for y in range(w):\n",
    "                            #compute where is the V_ic\n",
    "                            pos_x = self.stride*x + i\n",
    "                            pos_y = self.stride*y + j\n",
    "                            add.append([pos_x/width_in, pos_y/width_in])\n",
    "            add = Variable(torch.Tensor(add)).view(1,1,self.K,self.K,1,w,w,2)\n",
    "            add = add.expand(b,self.B,self.K,self.K,self.C,w,w,2).contiguous()\n",
    "            if use_cuda:\n",
    "                add = add.cuda()\n",
    "            votes[:,:,:,:,:,:,:,0,:2] = votes[:,:,:,:,:,:,:,0,:2] + add\n",
    "\n",
    "#        print(time()-t)\n",
    "        #Start EM   \n",
    "        Cww = w*w*self.C\n",
    "        Bkk = self.K*self.K*self.B\n",
    "        R = np.ones([b,self.B,width_in,width_in,self.C,w,w])/Cww\n",
    "        V_s = votes.view(b,Bkk,Cww,16) #b,Bkk,Cww,16\n",
    "        for iterate in range(self.iteration):\n",
    "#            t = time()\n",
    "            #M-step\n",
    "            r_s,a_s = [],[]\n",
    "            for typ in range(self.C):            \n",
    "                for i in range(width_out):\n",
    "                    for j in range(width_out):\n",
    "                        r = R[:,:,self.stride*i:self.stride*i+self.K,  #b,B,K,K\n",
    "                                self.stride*j:self.stride*j+self.K,typ,i,j]\n",
    "                        r = Variable(torch.from_numpy(r).float())\n",
    "                        if use_cuda:\n",
    "                            r = r.cuda()\n",
    "                        r_s.append(r)\n",
    "                        a = activation[:,:,self.stride*i:self.stride*i+self.K,\n",
    "                                self.stride*j:self.stride*j+self.K] #b,B,K,K\n",
    "                        a_s.append(a)\n",
    "\n",
    "            \n",
    "            r_s = torch.stack(r_s,-1).view(b, Bkk, Cww) #b,Bkk,Cww\n",
    "            a_s = torch.stack(a_s,-1).view(b, Bkk, Cww) #b,Bkk,Cww\n",
    "            r_hat = r_s*a_s #b,Bkk,Cww\n",
    "            r_hat = r_hat.clamp(0.01) #prevent nan since we'll devide sth. by r_hat\n",
    "            sum_r_hat = r_hat.sum(1).view(b,1,Cww,1).expand(b,1,Cww,16) #b,Cww,16\n",
    "            r_hat_stack = r_hat.view(b,Bkk,Cww,1).expand(b, Bkk, Cww,16) #b,Bkk,Cww,16\n",
    "            mu = torch.sum(r_hat_stack*V_s, 1, True)/sum_r_hat #b,1,Cww,16\n",
    "            mu_stack = mu.expand(b,Bkk,Cww,16) #b,Bkk,Cww,16\n",
    "            sigma = torch.sum(r_hat_stack*(V_s-mu_stack)**2,1,True)/sum_r_hat #b,1,Cww,16           \n",
    "            sigma = sigma.clamp(0.01) #prevent nan since the following is a log(sigma)\n",
    "            cost = (self.beta_v + torch.log(sigma)) * sum_r_hat #b,1,Cww,16\n",
    "            beta_a_stack = self.beta_a.view(1,self.C,1).expand(b,self.C,w*w).contiguous().view(b,1,Cww)#b,Cww\n",
    "            a_c = torch.sigmoid(lambda_*(beta_a_stack-torch.sum(cost,3))) #b,1,Cww \n",
    "            mus = mu.view(b,self.C,w,w,16) #b,C,w,w,16\n",
    "            sigmas = sigma.view(b,self.C,w,w,16) #b,C,w,w,16\n",
    "            activations = a_c.view(b,self.C,w,w) #b,C,w,w\n",
    "#            print(time()-t)\n",
    "#            t = time()\n",
    "\n",
    "            #E-step\n",
    "            for i in range(width_in):\n",
    "                #compute the x axis range of capsules c that i connect to.\n",
    "                x_range = (max(floor((i-self.K)/self.stride)+1,0),min(i//self.stride+1,width_out))\n",
    "                #without padding, some capsules i may not be convolutional layer catched, in mnist case, i or j == 11\n",
    "                u = len(range(*x_range))\n",
    "                if not u: \n",
    "                    continue\n",
    "                for j in range(width_in):\n",
    "                    y_range = (max(floor((j-self.K)/self.stride)+1,0),min(j//self.stride+1,width_out))\n",
    "\n",
    "                    v = len(range(*y_range))\n",
    "                    if not v:\n",
    "                        continue\n",
    "                    mu = mus[:,:,x_range[0]:x_range[1],y_range[0]:y_range[1],:].contiguous() #b,C,u,v,16\n",
    "                    sigma = sigmas[:,:,x_range[0]:x_range[1],y_range[0]:y_range[1],:].contiguous() #b,C,u,v,16 \n",
    "                    mu = mu.view(b,1,self.C,u,v,16).expand(b,self.B,self.C,u,v,16).contiguous()#b,B,C,u,v,16\n",
    "                    sigma = sigma.view(b,1,self.C,u,v,16).expand(b,self.B,self.C,u,v,16).contiguous()#b,B,C,u,v,16            \n",
    "                    V = []; a = []                 \n",
    "                    for x in range(*x_range):\n",
    "                        for y in range(*y_range):\n",
    "                            #compute where is the V_ic\n",
    "                            pos_x = self.stride*x - i\n",
    "                            pos_y = self.stride*y - j\n",
    "                            V.append(votes[:,:,pos_x,pos_y,:,x,y,:,:]) #b,B,C,4,4\n",
    "                            a.append(activations[:,:,x,y].contiguous().view(b,1,self.C).expand(b,self.B,self.C).contiguous()) #b,B,C\n",
    "                    V = torch.stack(V,dim=3).view(b,self.B,self.C,u,v,16) #b,B,C,u,v,16\n",
    "                    a = torch.stack(a,dim=3).view(b,self.B,self.C,u,v) #b,B,C,u,v\n",
    "                    p = torch.exp(-(V-mu)**2)/torch.sqrt(2*pi*sigma) #b,B,C,u,v,16\n",
    "                    p = p.prod(dim=5)#b,B,C,u,v\n",
    "                    p_hat = a*p  #b,B,C,u,v\n",
    "                    sum_p_hat = p_hat.sum(4).sum(3).sum(2) #b,B\n",
    "                    sum_p_hat = sum_p_hat.view(b,self.B,1,1,1).expand(b,self.B,self.C,u,v)\n",
    "                    r = (p_hat/sum_p_hat) #b,B,C,u,v --> R: b,B,12,12,32,5,5\n",
    "                    \n",
    "                    if use_cuda:\n",
    "                        r = r.cpu()\n",
    "                    R[:,:,i,j,:,x_range[0]:x_range[1],        #b,B,u,v,C\n",
    "                      y_range[0]:y_range[1]] = r.data.numpy()\n",
    "#            print(time()-t)\n",
    "        \n",
    "        mus = mus.permute(0,4,1,2,3).contiguous().view(b,self.C*16,w,w)#b,16*C,5,5\n",
    "        output = torch.cat([mus,activations], 1) #b,C*17,5,5\n",
    "        return output\n",
    "                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(args):\n",
    "    # MNIST Dataset\n",
    "    train_dataset = datasets.MNIST(root='./data/',\n",
    "                                   train=True,\n",
    "                                   transform=transforms.ToTensor(),\n",
    "                                   download=True)\n",
    "\n",
    "    test_dataset = datasets.MNIST(root='./data/',\n",
    "                                  train=False,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "    # Data Loader (Input Pipeline)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                               batch_size=args.batch_size,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                              batch_size=args.batch_size,\n",
    "                                              shuffle=True)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='CapsNet')\n",
    "\n",
    "    parser.add_argument('-batch_size', type=int, default=128)\n",
    "    parser.add_argument('-num_epochs', type=int, default=1)\n",
    "    parser.add_argument('-lr', type=float, default=2e-2)\n",
    "    parser.add_argument('-clip', type=float, default=5)\n",
    "    parser.add_argument('-r', type=int, default=3)\n",
    "    parser.add_argument('-disable_cuda', action='store_true',\n",
    "                    help='Disable CUDA')\n",
    "    parser.add_argument('-print_freq', type=int, default=10)\n",
    "    parser.add_argument('-pretrained', type=str, default=\"\")\n",
    "    parser.add_argument('-gpu', type=int, default=0, help = \"which gpu to use\") \n",
    "    args = parser.parse_args()\n",
    "    args.use_cuda = not args.disable_cuda and torch.cuda.is_available()\n",
    "\n",
    "    return args\n",
    "\n",
    "def pseudo_args():\n",
    "    args = {\n",
    "        'batch_size': 8,\n",
    "        'num_epochs': 1,\n",
    "        'lr': 2e-2,\n",
    "        'clip': 5,\n",
    "        'r': 3,\n",
    "        'disable_cuda': 'store_true',\n",
    "        'print_freq': 10,\n",
    "        'pretrained': \"\",\n",
    "        'gpu': 0,\n",
    "        'use_cuda': True,\n",
    "    }\n",
    "    args = DottedDict(args)\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    def __init__(self,A=32,B=32,C=32,D=32, E=10,r = 3):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=A,\n",
    "                               kernel_size=5, stride=2)\n",
    "        self.primary_caps = PrimaryCaps(A,B)\n",
    "        self.convcaps1 = ConvCaps(B, C, kernel = 3, stride=2,iteration=r,\n",
    "                                  coordinate_add=False, transform_share = False)\n",
    "        self.convcaps2 = ConvCaps(C, D, kernel = 3, stride=1,iteration=r,\n",
    "                                  coordinate_add=False, transform_share = False)\n",
    "        self.classcaps = ConvCaps(D, E, kernel = 0, stride=1,iteration=r,\n",
    "                                  coordinate_add=True, transform_share = True) \n",
    "        \n",
    "        \n",
    "    def forward(self,x,lambda_): #b,1,28,28\n",
    "        x = F.relu(self.conv1(x)) #b,32,12,12\n",
    "        x = self.primary_caps(x) #b,32*(4*4+1),12,12\n",
    "        x = self.convcaps1(x,lambda_) #b,32*(4*4+1),5,5\n",
    "        x = self.convcaps2(x,lambda_) #b,32*(4*4+1),3,3\n",
    "        x = self.classcaps(x,lambda_).view(-1,10*16+10) #b,10*16+10\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, target, m): #x:b,10 target:b\n",
    "        b = x.size(0)\n",
    "        a_t = torch.cat([x[i][target[i]] for i in range(b)]) #b\n",
    "        a_t_stack = a_t.view(b,1).expand(b,10).contiguous() #b,10\n",
    "        u = m-(a_t_stack-x) #b,10\n",
    "        mask = u.ge(0).float() #max(u,0) #b,10\n",
    "        loss = ((mask*u)**2).sum()/b - m**2  #float\n",
    "        return loss\n",
    "    \n",
    "    def loss2(self,x ,target):\n",
    "        loss = F.cross_entropy(x,target)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activating cuda\n",
      "Epoch 0\n",
      "tensor([[0.5975, 0.5965, 0.5957, 0.5988, 0.5986, 0.5983, 0.5976, 0.5964, 0.5974,\n",
      "         0.5961],\n",
      "        [0.5967, 0.5972, 0.5953, 0.5979, 0.5992, 0.5989, 0.5978, 0.5965, 0.5980,\n",
      "         0.5954],\n",
      "        [0.5970, 0.5968, 0.5958, 0.5988, 0.6001, 0.5988, 0.5978, 0.5961, 0.5973,\n",
      "         0.5951],\n",
      "        [0.5972, 0.5967, 0.5959, 0.5982, 0.5987, 0.5985, 0.5984, 0.5970, 0.5972,\n",
      "         0.5951],\n",
      "        [0.5966, 0.5973, 0.5962, 0.5987, 0.5986, 0.5987, 0.5981, 0.5953, 0.5982,\n",
      "         0.5953],\n",
      "        [0.5966, 0.5977, 0.5949, 0.5982, 0.5985, 0.5982, 0.5977, 0.5977, 0.5981,\n",
      "         0.5953],\n",
      "        [0.5966, 0.5973, 0.5957, 0.5979, 0.5982, 0.5986, 0.5978, 0.5977, 0.5977,\n",
      "         0.5952],\n",
      "        [0.5968, 0.5971, 0.5965, 0.5979, 0.5988, 0.5988, 0.5985, 0.5957, 0.5980,\n",
      "         0.5948]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "tensor([3, 3, 5, 6, 5, 2, 2, 5], device='cuda:0')\n",
      "0.20002666666666669\n",
      "Epoch0 Train acc: 0.0\n",
      "Testing...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb Cell 5'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000007vscode-remote?line=73'>74</a>\u001b[0m out \u001b[39m=\u001b[39m model(imgs,lambda_) \u001b[39m#b,10,17\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000007vscode-remote?line=74'>75</a>\u001b[0m out_poses, out_labels \u001b[39m=\u001b[39m out[:,:\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m],out[:,\u001b[39m-\u001b[39m\u001b[39m10\u001b[39m:] \u001b[39m#b,16*10; b,10\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000007vscode-remote?line=75'>76</a>\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mloss(out_labels, labels, m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000007vscode-remote?line=76'>77</a>\u001b[0m \u001b[39m#stats\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000007vscode-remote?line=77'>78</a>\u001b[0m pred \u001b[39m=\u001b[39m out_labels\u001b[39m.\u001b[39mmax(\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m] \u001b[39m#b\u001b[39;00m\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb Cell 4'\u001b[0m in \u001b[0;36mCapsNet.loss\u001b[0;34m(self, x, target, m)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000006vscode-remote?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss\u001b[39m(\u001b[39mself\u001b[39m, x, target, m): \u001b[39m#x:b,10 target:b\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000006vscode-remote?line=23'>24</a>\u001b[0m     b \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000006vscode-remote?line=24'>25</a>\u001b[0m     a_t \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mcat([x[i][target[i]] \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(b)]) \u001b[39m#b\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000006vscode-remote?line=25'>26</a>\u001b[0m     a_t_stack \u001b[39m=\u001b[39m a_t\u001b[39m.\u001b[39mview(b,\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mexpand(b,\u001b[39m10\u001b[39m)\u001b[39m.\u001b[39mcontiguous() \u001b[39m#b,10\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff2.ipynb#ch0000006vscode-remote?line=26'>27</a>\u001b[0m     u \u001b[39m=\u001b[39m m\u001b[39m-\u001b[39m(a_t_stack\u001b[39m-\u001b[39mx) \u001b[39m#b,10\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #args = get_args()\n",
    "    args = pseudo_args()\n",
    "    train_loader, test_loader = get_dataloader(args)\n",
    "    use_cuda = args.use_cuda\n",
    "    steps = len(train_loader.dataset)//args.batch_size\n",
    "    lambda_ = 1e-3 #TODO:find a good schedule to increase lambda and m\n",
    "    m = 0.2\n",
    "    A,B,C,D,E,r = 64,8,16,16,10,args.r # a small CapsNet\n",
    "#    A,B,C,D,E,r = 32,32,32,32,10,args.r # a classic CapsNet\n",
    "    model = CapsNet(A,B,C,D,E,r)\n",
    "    with torch.cuda.device(args.gpu):\n",
    "#        print(args.gpu, type(args.gpu))\n",
    "        if args.pretrained:\n",
    "            model.load_state_dict(torch.load(args.pretrained))\n",
    "            m = 0.8\n",
    "            lambda_ = 0.9\n",
    "        if use_cuda:\n",
    "            print(\"activating cuda\")\n",
    "            model.cuda()\n",
    "            \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'max',patience = 1)\n",
    "        for epoch in range(args.num_epochs):\n",
    "            #Train\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            b = 0\n",
    "            correct = 0\n",
    "            for data in train_loader:\n",
    "                b += 1\n",
    "                if lambda_ < 1:\n",
    "                    lambda_ += 2e-1/steps\n",
    "                if m < 0.9:\n",
    "                    m += 2e-1/steps\n",
    "                optimizer.zero_grad()\n",
    "                imgs,labels = data #b,1,28,28; #b\n",
    "                imgs,labels = Variable(imgs),Variable(labels)\n",
    "                if use_cuda:\n",
    "                    imgs = imgs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                out = model(imgs,lambda_) #b,10,17\n",
    "                out_poses, out_labels = out[:,:-10],out[:,-10:] #b,16*10; b,10\n",
    "\n",
    "                print(out_labels)\n",
    "                print(labels)\n",
    "                print(m)\n",
    "\n",
    "\n",
    "                break\n",
    "                loss = model.loss(out_labels, labels, m)\n",
    "                torch.nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #stats\n",
    "                pred = out_labels.max(1)[1] #b\n",
    "                acc = pred.eq(labels).cpu().sum().data[0]\n",
    "                correct += acc\n",
    "                if b % args.print_freq == 0:                          \n",
    "                    print(\"batch:{}, loss:{:.4f}, acc:{:}/{}\".format(\n",
    "                            b, loss.data[0],acc, args.batch_size))\n",
    "            acc = correct/len(train_loader.dataset)\n",
    "            print(\"Epoch{} Train acc:{:4}\".format(epoch, acc))\n",
    "            scheduler.step(acc)\n",
    "            torch.save(model.state_dict(), \"./model_{}.pth\".format(epoch))\n",
    "            #Test\n",
    "            print('Testing...')\n",
    "            correct = 0\n",
    "            for data in test_loader:\n",
    "                imgs,labels = data #b,1,28,28; #b\n",
    "                imgs,labels = Variable(imgs),Variable(labels)\n",
    "                if use_cuda:\n",
    "                    imgs = imgs.cuda()\n",
    "                    labels = labels.cuda()\n",
    "                out = model(imgs,lambda_) #b,10,17\n",
    "                out_poses, out_labels = out[:,:-10],out[:,-10:] #b,16*10; b,10\n",
    "                loss = model.loss(out_labels, labels, m)\n",
    "                #stats\n",
    "                pred = out_labels.max(1)[1] #b\n",
    "                acc = pred.eq(labels).cpu().sum().data[0]\n",
    "                correct += acc\n",
    "            acc = correct/len(test_loader.dataset)\n",
    "            print(\"Epoch{} Test acc:{:4}\".format(epoch, acc))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss( x, target, m): #x:b,10 target:b\n",
    "    b = x.size(0)\n",
    "    a_t = torch.cat([x[i][target[i]] for i in range(b)]) #b\n",
    "    #a_t_stack = a_t.view(b,1).expand(b,10).contiguous() #b,10\n",
    "    #u = m-(a_t_stack-x) #b,10\n",
    "    #mask = u.ge(0).float() #max(u,0) #b,10\n",
    "    #loss = ((mask*u)**2).sum()/b - m**2  #float\n",
    "    #return loss\n",
    "\n",
    "\n",
    "y_pred = out_labels\n",
    "y_true = labels\n",
    "c = m\n",
    "\n",
    "loss(y_pred, y_true, c)\n",
    "\n",
    "y_true.unsqueeze(0).shape, y_pred.shape\n",
    "\n",
    "y_true.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0052, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0095, 0.0000, 0.0000],\n",
       "        [0.2347, 0.5157, 0.4584, 0.0494, 0.1266, 0.5710, 0.0000, 0.0000, 0.0311],\n",
       "        [0.2241, 1.2106, 0.1185, 0.1919, 0.1017, 0.1417, 1.2058, 0.7946, 0.8292],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0494, 0.0000, 0.0000],\n",
       "        [0.2045, 0.3963, 0.1095, 0.2187, 0.0000, 0.0509, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0230, 0.0160, 0.0000, 0.0059, 0.0000, 0.0000, 0.0017, 0.0556, 0.1645],\n",
       "        [0.1617, 0.6112, 0.9992, 1.0412, 1.0537, 0.4690, 0.0227, 0.3985, 0.0743]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### my interprtation\n",
    "\n",
    "\n",
    "def spread_loss(y_pred, y_true, m):\n",
    "\n",
    "    at = torch.zeros(y_true.shape).to(device)\n",
    "    zr = torch.zeros(y_pred.shape).to(device)\n",
    "\n",
    "    #create at\n",
    "    for i, cl in enumerate(y_true):\n",
    "        at[i] = y_pred[i][cl]\n",
    "    at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "\n",
    "    ai = y_pred[y_pred!=at].view(y_pred.shape[0],-1)\n",
    "\n",
    "    print(at[:,:-1].shape)\n",
    "\n",
    "    loss = ((torch.max( m-(at[:,:-1] - ai), zr[:,:-1]))**2)#.sum(dim=1)\n",
    "\n",
    "\n",
    "    return loss\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.manual_seed(0)\n",
    "y_pred = torch.rand(8,10).to(device)\n",
    "spread_loss(y_pred, y_true, 0.2)\n",
    "\n",
    "#y_true.unsqueeze(1).repeat(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x7fd98a697940>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.arange(0,10,1).unsqueeze(0).repeat(4,1)\n",
    "\n",
    "\n",
    "b = torch.arange(1,5,1)\n",
    "b\n",
    "\n",
    "enumerate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "72/8"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
