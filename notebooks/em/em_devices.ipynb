{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import numpy as np\n",
    "#local\n",
    "from misc.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spread Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### my interprtation off spread loss\n",
    "\n",
    "\n",
    "def spread_loss(y_pred, y_true, m, device):\n",
    "\n",
    "    at = torch.zeros(y_true.shape).to(device)\n",
    "    zr = torch.zeros((y_pred.shape[0],y_pred.shape[1]-1)).to(device)\n",
    "\n",
    "    #create at\n",
    "    for i, cl in enumerate(y_true):\n",
    "        at[i] = y_pred[i][cl]\n",
    "    \n",
    "    at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "    ai = y_pred[y_pred!=at].view(y_pred.shape[0],-1)\n",
    "\n",
    "    loss = ((torch.max( m-(at[:,:-1] - ai), zr))**2).sum(dim=1)\n",
    "\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadLoss(_Loss):\n",
    "\n",
    "    def __init__(self, device, m_min=0.2, m_max=0.9):\n",
    "        super(SpreadLoss, self).__init__()\n",
    "        self.m_min = m_min\n",
    "        self.m_max = m_max\n",
    "        self.device = device\n",
    "\n",
    "    def margin(self, reps):\n",
    "        return self.m_min + (self.m_max - self.m_min)*reps\n",
    "\n",
    "    def forward(self, y_pred, y_true, reps):\n",
    "        at = torch.zeros(y_true.shape).to(self.device)\n",
    "        zr = torch.zeros((y_pred.shape[0],y_pred.shape[1]-1)).to(self.device)\n",
    "        ma = self.margin(reps)\n",
    "\n",
    "        #create at\n",
    "        for i, cl in enumerate(y_true):\n",
    "            at[i] = y_pred[i][cl]\n",
    "        \n",
    "        at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "        ai = y_pred[y_pred!=at].view(y_pred.shape[0],-1)\n",
    "\n",
    "        loss = ((torch.max( ma - (at[:,:-1] - ai), zr))**2).sum(dim=1)\n",
    "\n",
    "        # mean over batch\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread_loss2(y_pred, y_true, m, device):\n",
    "    at = torch.zeros(y_true.shape).to(device)\n",
    "    zr = torch.zeros((y_pred.shape[0],y_pred.shape[1])).to(device)\n",
    "    #create at\n",
    "    for i, cl in enumerate(y_true):\n",
    "        at[i] = y_pred[i][cl]\n",
    "    at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "    \n",
    "    loss = torch.max(m - (at - y_pred), zr)\n",
    "    loss = loss**2\n",
    "    loss = loss.sum() / y_true.shape[0] - m**2    \n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CapsNetEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNetEM(nn.Module):\n",
    "    \"\"\"\n",
    "    Genrate CapsNet with EM routing\n",
    "    Args:\n",
    "        A: output channels of normal conv\n",
    "        B: output channels of primary caps\n",
    "        C: output channels of 1st conv caps\n",
    "        D: output channels of 2nd conv caps\n",
    "        E: output channels of class caps (i.e. number of classes)\n",
    "        K: kernel of conv caps\n",
    "        P: size of square pose matrix\n",
    "        iters: number of EM iterations\n",
    "        ...\n",
    "\n",
    "        input: (bs, 1, 28, 28)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A=32, B=32, C=32, D=32,E=10, K=3, P=4, iter=3, hw_out=(28,28), device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        hw_out = self.hw_cal(hw_out, kernel=5, padding=2, dilatation=1, stride=2)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=A, kernel_size=(5, 5), stride=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.BatchNorm2d(num_features=A),\n",
    "        )\n",
    "        hw_out = self.hw_cal(hw_out, kernel=1, padding=0, dilatation=1, stride=1)\n",
    "        self.prime_caps = PrimaryCaps(ch_in=A, ch_out=B, K=1, P=P, stride=1, padding=\"valid\")\n",
    "        #\n",
    "        hw_out = self.hw_cal(hw_out, kernel=K, padding=0, dilatation=1, stride=2)\n",
    "        self.conv_caps1 = ConvCaps(ch_in=B, ch_out=C, K=K, P=P, stride=2, iter=iter, hw_out=hw_out, class_caps=False, device=device)\n",
    "        #\n",
    "        hw_out = self.hw_cal(hw_out, kernel=K, padding=0, dilatation=1, stride=1)\n",
    "        self.conv_caps2 = ConvCaps(ch_in=C, ch_out=D, K=K, P=P, stride=1, iter=iter, hw_out=hw_out, class_caps=False, device=device)\n",
    "        #\n",
    "        self.class_caps = ConvCaps(ch_in=D, ch_out=E, K=1, P=P, stride=1, iter=iter, hw_out=hw_out, class_caps=True, device=device)\n",
    "\n",
    "    def hw_cal(self, hw_in, kernel, padding=0, dilatation=1, stride=1):\n",
    "        if type(hw_in) == type(int()):\n",
    "            hw_out = math.floor((hw_in + 2*padding - dilatation * (kernel - 1) - 1) / stride + 1)\n",
    "        elif type(hw_in) == type(tuple()):\n",
    "            h_out = math.floor((hw_in[0] + 2*padding - dilatation * (kernel - 1) - 1) / stride + 1)\n",
    "            w_out = math.floor((hw_in[1] + 2*padding - dilatation * (kernel - 1) - 1) / stride + 1)\n",
    "            hw_out = (h_out, w_out)\n",
    "        return hw_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.prime_caps(x)\n",
    "        x = self.conv_caps1(x)\n",
    "        x = self.conv_caps2(x)\n",
    "        x = self.class_caps(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        A: output of the normal conv layer\n",
    "        B: number of types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "    Shape:\n",
    "        input:  (*, A, h, w)                (bs, 32, 14, 14)\n",
    "        output: p -> (*,B, h', w', P, P)    (bs, 32, 14, 14, 4, 4)\n",
    "                a -> (*,B, h', w')          (bs, 32, 14, 14)\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*A*B*P*P + B*P*P\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch_in=32, ch_out=32, K=1, P=4, stride=1, padding=\"valid\"):\n",
    "        super().__init__()\n",
    "        self.pose = nn.Conv2d(in_channels=ch_in, out_channels=ch_out*P*P, kernel_size=K, stride=stride, bias=True)\n",
    "        self.acti = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=ch_out, kernel_size=K, stride=stride, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.P = P\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = self.pose(x)\n",
    "        a = self.acti(x)\n",
    "        p = p.view(p.shape[0],-1,p.shape[2],p.shape[3],self.P,self.P)\n",
    "\n",
    "        return p, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCaps(nn.Module):\n",
    "    \"\"\"Create a convolutional capsule layer\n",
    "    that transfer capsule layer L to capsule layer L+1\n",
    "    by EM routing.\n",
    "    Args:\n",
    "        B: input number of types of capsules\n",
    "        C: output number on types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "        iters: number of EM iterations\n",
    "        coor_add: use scaled coordinate addition or not\n",
    "        w_shared: share transformation matrix across w*h.\n",
    "    Shape:\n",
    "        input:  (*,B, h,  w, P, P)      (bs, 32, 14, 14, 4, 4)\n",
    "                (*,B, h,  w, 1)         (bs, 32, 14, 14)\n",
    "        output: (*,C, h,  w, P, P)      (bs, 32, 6, 6, 4, 4)\n",
    "                (*,C, h,  w, 1)         (bs, 32, 6, 6)\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*B*C*P*P + B*P*P\n",
    "    \"\"\"   \n",
    "\n",
    "    def __init__(self, ch_in=32, ch_out=32, K=3, P=4, stride=2, iter=3, hw_out=(1,1), final_lambda=1e-02, class_caps=False, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        # init vars\n",
    "        self.ch_in  = ch_in\n",
    "        self.ch_out = ch_out\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.psize = P*P\n",
    "        self.stride = stride\n",
    "        self.iter = iter\n",
    "        self.hw_out = hw_out\n",
    "        self.class_caps = class_caps\n",
    "        self.final_lambda = final_lambda\n",
    "        self.device = torch.device(device)\n",
    "\n",
    "        # constants\n",
    "        self.eps = 1e-8\n",
    "        \n",
    "        # params\n",
    "        self.b_u = nn.Parameter(torch.zeros(ch_out), requires_grad=True)\n",
    "        self.b_a = nn.Parameter(torch.zeros(ch_out), requires_grad=True)\n",
    "        self.w = nn.Parameter(torch.rand([1, ch_in, hw_out[0], hw_out[0], P, P, ch_out]), requires_grad=True)\n",
    "\n",
    "        #torch.nn.init.xavier_normal_(self.w)\n",
    "\n",
    "        #conv with static kernel\n",
    "        self.conv_stat = nn.Conv2d(in_channels=ch_in, out_channels=ch_in, kernel_size=K, stride=stride, bias=False, padding=0)\n",
    "        self.conv_stat.weight = torch.nn.Parameter((torch.ones_like(self.conv_stat.weight)/K**2),requires_grad=False)\n",
    "\n",
    "        # activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def voting(self, x):\n",
    "        \"\"\"\n",
    "                Input:     (bs, ch_in, h_in, w_in, p, p)\n",
    "                Output:    (bs, ch_in, h_ out, w_out, p, p, ch_out)\n",
    "        \"\"\"        \n",
    "        sh_in = x.shape\n",
    "        print(sh_in)\n",
    "        #conv & shaping\n",
    "        x = x.view(sh_in[0]*self.P*self.P, self.ch_in,sh_in[2], sh_in[3])\n",
    "        x = self.conv_stat(x)\n",
    "        x = x.view(-1, x.shape[1], x.shape[2], x.shape[3], self.P,self.P)\n",
    "        \n",
    "        #expand x and w to number of out channels\n",
    "        x = x.unsqueeze(-1).repeat([1, 1, 1, 1, 1, 1, self.ch_out])\n",
    "        w = self.w.repeat([sh_in[0], 1, 1, 1, 1, 1, 1])\n",
    "        \n",
    "        assert x.shape == w.shape\n",
    "\n",
    "        # compute v\n",
    "        x = x.view(-1, x.shape[1], x.shape[2], x.shape[3], self.ch_out, self.P,self.P)\n",
    "        w = w.view(-1, w.shape[1], w.shape[2], w.shape[3], self.ch_out, self.P,self.P)\n",
    "        v = torch.matmul(x, w)\n",
    "        v = v.view(-1, v.shape[1], v.shape[2], v.shape[3], self.P,self.P, self.ch_out)\n",
    "\n",
    "        return v\n",
    "    \n",
    "    def add_cord(self, v):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "                v:         (bs, ch_in, h, w, p, p, ch_out)\n",
    "            Output:\n",
    "                v:         (bs, ch_in, h, w, p, p, ch_out)\n",
    "        \"\"\"        \n",
    "        #split shapes\n",
    "        s_bs, s_ch_in, s_h, s_w, s_p1, s_p2, s_ch_out = v.shape\n",
    "        v = v.view(s_bs, s_ch_in, s_h, s_w, s_ch_out, s_p1* s_p2)\n",
    "        #coordinate addition\n",
    "        ar_h = torch.arange(s_h, dtype=torch.float32) / s_h\n",
    "        ar_w = torch.arange(s_w, dtype=torch.float32) / s_w\n",
    "        coor_h = torch.FloatTensor(1, 1, s_h, 1, 1, s_p1* s_p2).fill_(0.).to(self.device)  \n",
    "        coor_w = torch.FloatTensor(1, 1, 1, s_w, 1, s_p1* s_p2).fill_(0.).to(self.device)    \n",
    "        coor_h[0, 0, :, 0, 0, 0] = ar_h\n",
    "        coor_w[0, 0, 0, :, 0, 1] = ar_w\n",
    "        v = v + coor_h + coor_w\n",
    "        v = v.view(s_bs, s_ch_in, s_h, s_w, s_p1, s_p2, s_ch_out)     \n",
    "        return v\n",
    "    \n",
    "    def _inv_temp(self,it):\n",
    "        # AG 18/07/2018: modified schedule for inverse_temperature (lambda) based\n",
    "        # on Hinton's response to questions on OpenReview.net: \n",
    "        # https://openreview.net/forum?id=HJWLfGWRb\n",
    "        return (self.final_lambda * (1. - 0.95**(1 + it)))\n",
    "\n",
    "    def em_routing(self, v, a):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "                v:         (bs, ch_in, h, w, p, p, ch_out)\n",
    "                a_in:      (bs, ch_in, h, w)\n",
    "            \n",
    "            For ConvCaps:\n",
    "            Output:\n",
    "                mu:        (bs, ch_out, h, w, p, p)\n",
    "                a_out:     (bs, ch_out, h, w)\n",
    "            Note that some dimensions are merged\n",
    "            for computation convenient, that is\n",
    "                v:         (bs*h*w, ch_in, p*p, ch_out)\n",
    "                a_in:      (bs*h*w, ch_in, 1)\n",
    "            \n",
    "            For ClassCaps:\n",
    "            Output:\n",
    "                mu:        (bs, ch_out, p, p)\n",
    "                a_out:     (bs, ch_out)\n",
    "            Note that some dimensions are merged\n",
    "            for computation convenient, that is\n",
    "                v:         (bs, ch_in*h*w, p*p, ch_out)\n",
    "                a_in:      (bs, ch_in*h*w, 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # split shapes\n",
    "        s_bs, s_ch_in, s_h, s_w, s_p1, s_p2, s_ch_out = v.shape\n",
    "\n",
    "        if self.class_caps == False:\n",
    "            # reshape for conv caps\n",
    "            v = v.view(s_bs*s_h*s_w, s_ch_in, s_ch_out, s_p1*s_p2)\n",
    "            a = a.view(s_bs*s_h*s_w, s_ch_in).unsqueeze(-1)\n",
    "            #declare r\n",
    "            r = torch.FloatTensor(s_bs*s_h*s_w, s_ch_in, s_ch_out).fill_(1./s_ch_out).to(self.device)\n",
    "        else:\n",
    "            # cood add\n",
    "            v = self.add_cord(v)\n",
    "            # reshape for class caps\n",
    "            v = v.view(s_bs, s_ch_in*s_h*s_w, s_ch_out, s_p1*s_p2)\n",
    "            a = a.view(s_bs, s_ch_in*s_h*s_w).unsqueeze(-1)            \n",
    "            # declare r\n",
    "            r = torch.FloatTensor(s_bs, s_ch_in*s_h*s_w, s_ch_out).fill_(1./s_ch_out).to(self.device)\n",
    "\n",
    "\n",
    "        #iteration\n",
    "        for it in range(self.iter):\n",
    "            # M-Step (with inverse temperatur schedulder lambda)\n",
    "            lambd=self._inv_temp(it)\n",
    "            a_out, mu, sig_sq = self.m_step(a, r, v, lambd=lambd)\n",
    "            \n",
    "            # E-Step\n",
    "            if it < self.iter - 1:\n",
    "                r = self.e_step(mu, sig_sq, a_out, v)\n",
    "\n",
    "        #reshape from M and a as output\n",
    "        if self.class_caps == False:\n",
    "            mu = mu.view(s_bs, s_ch_out, s_h, s_w, s_p1, s_p2)\n",
    "            a_out = a_out.view(s_bs, s_ch_out, s_h, s_w)\n",
    "        else:\n",
    "            mu = mu.view(s_bs, s_ch_out, s_p1, s_p2)\n",
    "            a_out = a_out.view(s_bs, s_ch_out)\n",
    "\n",
    "        return mu, a_out\n",
    "\n",
    "    def e_step(self, mu, sig_sq, a_out, v):\n",
    "        \"\"\"\n",
    "            ln_p_j = sum_h \\dfrac{(\\V^h_{ij} - \\mu^h_j)^2}{2 \\sigma^h_j}\n",
    "                    - sum_h ln(\\sigma^h_j) - 0.5*\\sum_h ln(2*\\pi)\n",
    "            r = softmax(ln(a_j*p_j))\n",
    "              = softmax(ln(a_j) + ln(p_j))\n",
    "            Input:\n",
    "                mu:        (bs*h*w, 1, ch_out, P*P)\n",
    "                sig_sq:    (bs*h*w, 1, ch_out, P*P)\n",
    "                a_out:     (bs*h*w, 1, ch_out, 1)\n",
    "                v:         (bs*h*w, ch_in, ch_out, p*p)\n",
    "            Local:\n",
    "                p_ln:  (bs*h*w, ch_in, ch_out, p*p)\n",
    "                ap_ln:     (bs*h*w, ch_in, ch_out, 1)\n",
    "            Output:\n",
    "                r:         (bs*h*w, ch_in, ch_out)\n",
    "        \"\"\"\n",
    "        p_ln = -1. * (v - mu)**2 / (2 * sig_sq) - torch.log(sig_sq.sqrt()) - 0.5*torch.log(torch.tensor(2*math.pi))\n",
    "        ap_ln = (p_ln.sum(dim=3, keepdim=True) + torch.log(a_out)).squeeze(-1)\n",
    "        r = self.softmax(ap_ln)\n",
    "\n",
    "        return r\n",
    "\n",
    "    def m_step(self, a, r, v, lambd):\n",
    "        \"\"\"\n",
    "            \\mu^h_j = \\dfrac{\\sum_i r_{ij} V^h_{ij}}{\\sum_i r_{ij}}\n",
    "            (\\sigma^h_j)^2 = \\dfrac{\\sum_i r_{ij} (V^h_{ij} - mu^h_j)^2}{\\sum_i r_{ij}}\n",
    "            cost_h = (\\beta_u + log \\sigma^h_j) * \\sum_i r_{ij}\n",
    "            a_j = logistic(\\lambda * (\\beta_a - \\sum_h cost_h))\n",
    "            Input:\n",
    "                a_in:      (bs*h*w, ch_in, 1)\n",
    "                r:         (bs*h*w, ch_in, ch_out)\n",
    "                v:         (bs*h*w, ch_in, ch_out, p*p)\n",
    "            Local:\n",
    "                cost_h:    (bs*h*w, 1, ch_out, P*P)\n",
    "                r_sum:     (bs*h*w, 1, ch_out, 1)\n",
    "            Output:\n",
    "                a_out:     (bs*h*w, 1, ch_out, 1)\n",
    "                mu:        (bs*h*w, 1, ch_out, P*P)\n",
    "                sig_sq:    (bs*h*w, 1, ch_out, P*P)\n",
    "        \"\"\"\n",
    "        s_st, s_ch_in, s_ch_out, p = v.shape \n",
    "        r = (r * a).unsqueeze(-1) + self.eps\n",
    "        r_sum = r.sum(dim=1, keepdim=True)\n",
    "        mu = torch.sum(r * v, dim=1, keepdim=True) / r_sum\n",
    "        sig_sq = (torch.sum(r * (v - mu)**2, dim=1, keepdim=True) / r_sum)  + self.eps\n",
    "        cost = (self.b_u.view(1,1,s_ch_out,1) + torch.log(sig_sq.sqrt())) * r_sum\n",
    "        a_out = self.sigmoid(lambd*(self.b_a.view(1,1,s_ch_out,1) - cost.sum(dim=3, keepdim=True)))\n",
    "        \n",
    "        return a_out, mu, sig_sq\n",
    "\n",
    "    def forward(self, x):\n",
    "        #split pose and activation\n",
    "        x, a = x\n",
    "\n",
    "        # conv of poses to get votes v\n",
    "        x = self.voting(x) \n",
    "        \n",
    "        # conv activations\n",
    "        a = self.conv_stat(a)\n",
    "\n",
    "        #routing\n",
    "        x, a = self.em_routing(x, a)\n",
    "\n",
    "\n",
    "        return x, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.0679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "tensor(3.0679, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss_dev = torch.device(\"cuda\")\n",
    "torch.manual_seed(0)\n",
    "bs = 2\n",
    "y_true = torch.randint(0, 9, (bs,), requires_grad=False).to(loss_dev)\n",
    "y_pred = torch.rand(bs,10, requires_grad=True).to(loss_dev)\n",
    "\n",
    "### my interprtation off spread loss\n",
    "print(spread_loss(y_pred, y_true, 0.2, loss_dev))\n",
    "\n",
    "print(spread_loss2(y_pred, y_true, 0.2, loss_dev))\n",
    "\n",
    "# git stuff\n",
    "A = SpreadLoss(loss_dev)\n",
    "#print(A.forward(y_pred, y_true, 0))\n",
    "\n",
    "#print(y_pred.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=True, download=True, transform=T.ToTensor())\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        batch_size=3, \n",
    "                                        shuffle=False,\n",
    "                                        num_workers=2)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 28, 28]), tensor([5, 0, 4]))"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl_train))\n",
    "\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42418\n",
      "torch.Size([3, 64, 14, 14, 4, 4])\n",
      "torch.Size([3, 32, 6, 6, 4, 4])\n",
      "torch.Size([3, 16, 4, 4, 4, 4])\n",
      "torch.Size([2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 10, 4, 4]),\n",
       " torch.Size([3, 10]),\n",
       " tensor([[7.7178e-03, 3.9128e-02, 4.5947e-02, 1.9033e-04, 1.0217e-11, 0.0000e+00,\n",
       "          4.5688e-01, 8.9342e-03, 1.4686e-03, 1.1025e-17],\n",
       "         [1.3620e-02, 2.2888e-02, 4.1294e-02, 4.5176e-04, 1.8100e-12, 0.0000e+00,\n",
       "          4.7867e-01, 3.0319e-02, 8.0994e-06, 3.1430e-15],\n",
       "         [6.6028e-02, 1.6719e-01, 4.5234e-03, 3.0731e-04, 2.7295e-11, 0.0000e+00,\n",
       "          4.9612e-01, 5.0045e-03, 2.2621e-02, 1.7432e-19]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor(0.8330, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = \"cpu\"\n",
    "mod_dev = torch.device(device)\n",
    "B = CapsNetEM(A=64, B=64, C=32, D=16,E=10, K=3, P=4, iter=3, hw_out=(28,28), device=device)\n",
    "B.to(mod_dev)\n",
    "print(count_parameters(B)*1e-6)\n",
    "z, a = B(x.to(mod_dev))\n",
    "\n",
    "loss = spread_loss(y_pred=a, y_true=y, m=0.2, device=mod_dev)\n",
    "\n",
    "print(y_true.shape)\n",
    "z.shape, a.shape, a, loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_margin_hinton(step_abs, m_max, m_min):\n",
    "    # AG 31/07/2018: function for margin of loss func\n",
    "    # on Hinton's response to questions on OpenReview.net: \n",
    "    # https://openreview.net/forum?id=HJWLfGWRb\n",
    "    # !!! I actually do not understand the fix hyper-parameter\n",
    "    # !!! They only makes sence with the right size of steps...\n",
    "    return (m_min + (m_max - m_min - 0.01) * torch.sigmoid(torch.min(torch.tensor([10.0, step_abs / 50000.0 - 4])))).item()\n",
    "\n",
    "def func_margin_linear(step_rel, m_max, m_min):\n",
    "    return m_min + (m_max - m_min)*step_rel\n",
    "\n",
    "def func_step_rel(num_epochs, batch_size, epoch_idx, idx):\n",
    "    return (1.*idx + (epoch_idx-1)*batch_size) / (num_epochs*batch_size)\n",
    "\n",
    "def func_step_abs(batch_size, epoch_idx, idx):\n",
    "    return (1.*idx + (epoch_idx-1)*batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.104, 6240.0, 0.2728, 0.2140265703201294)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "batch_size = 60\n",
    "epoch_idx = 90\n",
    "idx = 900\n",
    "m_max = 0.9\n",
    "m_min = 0.2\n",
    "\n",
    "\n",
    "st_rel = func_step_rel(num_epochs, batch_size, epoch_idx, idx)\n",
    "\n",
    "st_abs = func_step_abs(batch_size, epoch_idx, idx)\n",
    "\n",
    "marg_linear = func_margin_linear(st_rel, m_max, m_min)\n",
    "\n",
    "marg_hinton = func_margin_hinton(st_abs, m_max, m_min)\n",
    "\n",
    "st_rel, st_abs, marg_linear, marg_hinton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pr = a\n",
    "pose = z\n",
    "lss = loss\n",
    "y_tr = y\n",
    "\n",
    "\n",
    "y_pr_val, y_pr_idx = torch.topk(input=y_pr, k=1, dim=1, largest=True, sorted=True)\n",
    "\n",
    "y_pr_val, y_pr_idx, y_tr\n",
    "\n",
    "y_pr_idx[1]=0\n",
    "\n",
    "(y_pr_idx.squeeze(-1) == y_tr).sum() / y_tr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_acc(y_pred, y_true):\n",
    "    y_pr_val, y_pr_idx = torch.topk(input=y_pred, k=1, dim=1, largest=True, sorted=True)\n",
    "    acc = (y_pr_idx.squeeze(-1) == y_true).sum() / y_true.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_acc(y_pr, y_tr)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
