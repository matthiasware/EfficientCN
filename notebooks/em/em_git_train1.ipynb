{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from misc.utils import count_parameters\n",
    "from effcn.em_git import CapsNet, SpreadLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"../../data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        batch_size=8, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4)\n",
    "\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                        batch_size=8, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CapsNet()\n",
    "model = model.to(device)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = SpreadLoss(num_class=10, m_min=0.2, m_max=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=2e-7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def exp_lr_decay(optimizer, global_step, init_lr = 3e-3, decay_steps = 20000,\n",
    "                                        decay_rate = 0.96, lr_clip = 3e-3 ,staircase=False):\n",
    "    \n",
    "    ''' decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)  '''\n",
    "    \n",
    "    if staircase:\n",
    "        lr = (init_lr * decay_rate**(global_step // decay_steps)) \n",
    "    else:\n",
    "        lr = (init_lr * decay_rate**(global_step / decay_steps)) \n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train [  0/  2]:â–Œ         | 433/7500 [01:52<30:44,  3.83it/s, loss=-.0164, acc=[tensor([12.5000], device='cuda:0')]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb#ch0000021vscode-remote?line=13'>14</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb#ch0000021vscode-remote?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb#ch0000021vscode-remote?line=17'>18</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb#ch0000021vscode-remote?line=18'>19</a>\u001b[0m r \u001b[39m=\u001b[39m (\u001b[39m1.\u001b[39m\u001b[39m*\u001b[39midx \u001b[39m+\u001b[39m (epoch_idx\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mtrain_len) \u001b[39m/\u001b[39m (num_epochs\u001b[39m*\u001b[39mtrain_len)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/em_git_train1.ipynb#ch0000021vscode-remote?line=19'>20</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(y_pred, y_true,r)         \n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py:334\u001b[0m, in \u001b[0;36mCapsNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=331'>332</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_caps1(x)\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=332'>333</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_caps2(x)\n\u001b[0;32m--> <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=333'>334</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_caps(x)\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=334'>335</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py:275\u001b[0m, in \u001b[0;36mConvCaps.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=272'>273</a>\u001b[0m \u001b[39m# coor_add\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=273'>274</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoor_add:\n\u001b[0;32m--> <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=274'>275</a>\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_coord(v, b, h, w, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mB, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpsize)\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=276'>277</a>\u001b[0m \u001b[39m# em_routing\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=277'>278</a>\u001b[0m _, out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcaps_em_routing(v, a_in, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\n",
      "File \u001b[0;32m~/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py:237\u001b[0m, in \u001b[0;36mConvCaps.add_coord\u001b[0;34m(self, v, b, h, w, B, C, psize)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=234'>235</a>\u001b[0m coor_h \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mFloatTensor(\u001b[39m1\u001b[39m, h, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpsize)\u001b[39m.\u001b[39mfill_(\u001b[39m0.\u001b[39m)\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=235'>236</a>\u001b[0m coor_w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mFloatTensor(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, w, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpsize)\u001b[39m.\u001b[39mfill_(\u001b[39m0.\u001b[39m)\n\u001b[0;32m--> <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=236'>237</a>\u001b[0m coor_h[\u001b[39m0\u001b[39m, :, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m coor\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=237'>238</a>\u001b[0m coor_w[\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, :, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m coor\n\u001b[1;32m    <a href='file:///home/mkoch/projects/EfficientCN/notebooks/em/./../../effcn/em_git.py?line=238'>239</a>\u001b[0m v \u001b[39m=\u001b[39m v \u001b[39m+\u001b[39m coor_h \u001b[39m+\u001b[39m coor_w\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "train_len = len(dl_train)\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for idx, (x,y_true) in enumerate(pbar):\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        y_pred = model(x)\n",
    "        r = (1.*idx + (epoch_idx-1)*train_len) / (num_epochs*train_len)\n",
    "        loss = loss_func(y_pred, y_true,r)         \n",
    "        acc = accuracy(y_pred, y_true)\n",
    "\n",
    "        global_step = (batch_idx+1) + (epoch - 1) * len(train_loader) \n",
    "        exp_lr_decay(optimizer = optimizer, global_step = global_step) # moein - change the learning rate exponentially\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_acc += acc[0].item()\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc[0].item()\n",
    "                 }\n",
    "        )\n",
    "    \n",
    "\n",
    "        \n",
    "    # I guess this is done once per epoch\n",
    "    #lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    test_len = len(test_loader)\n",
    "\n",
    "    for x,y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "\n",
    "            test_loss += criterion(y_pred, y_true, r=1).item()\n",
    "            acc += accuracy(y_pred, y_true)[0].item()\n",
    "\n",
    "    test_loss /= test_len\n",
    "    acc /= test_len\n",
    "    print(\"   acc_valid: {:.3f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
