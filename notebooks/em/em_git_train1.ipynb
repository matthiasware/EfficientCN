{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from misc.utils import count_parameters\n",
    "from effcn.em_git import CapsNet, SpreadLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"../../data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        batch_size=8, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=2)\n",
    "\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                        batch_size=8, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CapsNet()\n",
    "model = model.to(device)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = SpreadLoss(num_class=10, m_min=0.2, m_max=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=2e-7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def exp_lr_decay(optimizer, global_step, init_lr = 3e-3, decay_steps = 20000,\n",
    "                                        decay_rate = 0.96, lr_clip = 3e-3 ,staircase=False):\n",
    "    \n",
    "    ''' decayed_learning_rate = learning_rate * decay_rate ^ (global_step / decay_steps)  '''\n",
    "    \n",
    "    if staircase:\n",
    "        lr = (init_lr * decay_rate**(global_step // decay_steps)) \n",
    "    else:\n",
    "        lr = (init_lr * decay_rate**(global_step / decay_steps)) \n",
    "    \n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "train_len = len(dl_train)\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    for idx, (x,y_true) in enumerate(pbar):\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        y_pred = model(x)\n",
    "        r = (1.*idx + (epoch_idx-1)*train_len) / (num_epochs*train_len)\n",
    "        loss = loss_func(y_pred, y_true,r)         \n",
    "        acc = accuracy(y_pred, y_true)\n",
    "\n",
    "        global_step = (idx+1) + (epoch_idx - 1) * train_len\n",
    "        exp_lr_decay(optimizer = optimizer, global_step = global_step) # moein - change the learning rate exponentially\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_acc += acc[0].item()\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc[0].item()\n",
    "                 }\n",
    "        )\n",
    "    \n",
    "\n",
    "        \n",
    "    # I guess this is done once per epoch\n",
    "    #lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    acc = 0\n",
    "    test_len = len(dl_valid)\n",
    "\n",
    "    for x,y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x)\n",
    "\n",
    "            test_loss += criterion(y_pred, y_true, r=1).item()\n",
    "            acc += accuracy(y_pred, y_true)[0].item()\n",
    "\n",
    "    test_loss /= test_len\n",
    "    acc /= test_len\n",
    "    print(\"   acc_valid: {:.3f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
