{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.datasets as datasets\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import numpy as np\n",
    "#local\n",
    "from misc.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spread Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### my interprtation off spread loss\n",
    "\n",
    "\n",
    "def spread_loss(y_pred, y_true, m):\n",
    "\n",
    "    at = torch.zeros(y_true.shape).to(device)\n",
    "    zr = torch.zeros((y_pred.shape[0],y_pred.shape[1]-1)).to(device)\n",
    "\n",
    "    #create at\n",
    "    for i, cl in enumerate(y_true):\n",
    "        at[i] = y_pred[i][cl]\n",
    "    \n",
    "    at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "    ai = y_pred[y_pred!=at].view(y_pred.shape[0],-1)\n",
    "\n",
    "    loss = ((torch.max( m-(at[:,:-1] - ai), zr))**2).sum(dim=1)\n",
    "\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadLoss(_Loss):\n",
    "\n",
    "    def __init__(self, device, m_min=0.2, m_max=0.9):\n",
    "        super(SpreadLoss, self).__init__()\n",
    "        self.m_min = m_min\n",
    "        self.m_max = m_max\n",
    "        self.device = device\n",
    "\n",
    "    def margin(self, reps):\n",
    "        return self.m_min + (self.m_max - self.m_min)*reps\n",
    "\n",
    "    def forward(self, y_pred, y_true, reps):\n",
    "        at = torch.zeros(y_true.shape).to(self.device)\n",
    "        zr = torch.zeros((y_pred.shape[0],y_pred.shape[1]-1)).to(self.device)\n",
    "        ma = self.margin(reps)\n",
    "\n",
    "        #create at\n",
    "        for i, cl in enumerate(y_true):\n",
    "            at[i] = y_pred[i][cl]\n",
    "        \n",
    "        at = at.unsqueeze(1).repeat(1,y_pred.shape[1])\n",
    "        ai = y_pred[y_pred!=at].view(y_pred.shape[0],-1)\n",
    "\n",
    "        loss = ((torch.max( ma - (at[:,:-1] - ai), zr))**2).sum(dim=1)\n",
    "\n",
    "        # mean over batch\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0286, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\")\n",
    "torch.manual_seed(0)\n",
    "bs = 8\n",
    "y_true = torch.randint(0, 9, (bs,), requires_grad=False).to(device)\n",
    "y_pred = torch.rand(bs,10, requires_grad=True).to(device)\n",
    "spread_loss(y_pred, y_true, 0.2)\n",
    "\n",
    "#y_true.unsqueeze(1).repeat(1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0286, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = SpreadLoss(device)\n",
    "A.margin(0)\n",
    "loss = A.forward(y_pred, y_true, 0)\n",
    "\n",
    "#loss.backward()\n",
    "loss\n",
    "\n",
    "#same result as in gitstuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CapsNetEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=True, download=True, transform=T.ToTensor())\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        batch_size=1, \n",
    "                                        shuffle=False,\n",
    "                                        num_workers=2)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 28, 28]), tensor([5]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl_train))\n",
    "\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNetEM(nn.Module):\n",
    "    \"\"\"\n",
    "    Genrate CapsNet with EM routing\n",
    "    Args:\n",
    "        A: output channels of normal conv\n",
    "        B: output channels of primary caps\n",
    "        C: output channels of 1st conv caps\n",
    "        D: output channels of 2nd conv caps\n",
    "        E: output channels of class caps (i.e. number of classes)\n",
    "        K: kernel of conv caps\n",
    "        P: size of square pose matrix\n",
    "        iters: number of EM iterations\n",
    "        ...\n",
    "\n",
    "        input: (bs, 1, 28, 28)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, A=32, B=32, C=32, D=32,E=10, K=3, P=4, iter=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=A, kernel_size=(5, 5), stride=2, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #nn.BatchNorm2d(num_features=A),\n",
    "        )\n",
    "        self.prim_caps0 = PrimaryCaps(ch_in=A, ch_out=B, K=1, P=P, stride=1, padding=\"valid\")\n",
    "        self.conv_caps1 = ConvCaps(ch_in=B, ch_out=C, K=K, P=P, stride=2, iter=iter, class_caps=False)\n",
    "        self.conv_caps2 = ConvCaps(ch_in=C, ch_out=B, K=K, P=P, stride=1, iter=iter, class_caps=False)\n",
    "        self.class_caps = ConvCaps(ch_in=D, ch_out=E, K=1, P=P, stride=1, iter=iter, class_caps=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.prim_caps0(x)\n",
    "        x = self.conv_caps1(x)\n",
    "        #x = self.conv_caps2(x)\n",
    "        #x = self.class_caps(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        A: output of the normal conv layer\n",
    "        B: number of types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "    Shape:\n",
    "        input:  (*, A, h, w)                (bs, 32, 14, 14)\n",
    "        output: p -> (*,B, h', w', P, P)    (bs, 32, 14, 14, 4, 4)\n",
    "                a -> (*,B, h', w')          (bs, 32, 14, 14)\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*A*B*P*P + B*P*P\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ch_in=32, ch_out=32, K=1, P=4, stride=1, padding=\"valid\"):\n",
    "        super().__init__()\n",
    "        self.pose = nn.Conv2d(in_channels=ch_in, out_channels=ch_out*P*P, kernel_size=K, stride=stride, bias=True)\n",
    "        self.acti = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=ch_out, kernel_size=K, stride=stride, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.P = P\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = self.pose(x)\n",
    "        a = self.acti(x)\n",
    "        p = p.view(p.shape[0],-1,p.shape[2],p.shape[3],self.P,self.P)\n",
    "\n",
    "        return p, a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCaps(nn.Module):\n",
    "    \"\"\"Create a convolutional capsule layer\n",
    "    that transfer capsule layer L to capsule layer L+1\n",
    "    by EM routing.\n",
    "    Args:\n",
    "        B: input number of types of capsules\n",
    "        C: output number on types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "        iters: number of EM iterations\n",
    "        coor_add: use scaled coordinate addition or not\n",
    "        w_shared: share transformation matrix across w*h.\n",
    "    Shape:\n",
    "        input:  (*,B, h,  w, P, P)      (bs, 32, 14, 14, 4, 4)\n",
    "                (*,B, h,  w, 1)         (bs, 32, 14, 14)\n",
    "        output: (*,C, h,  w, P, P)      (bs, 32, 6, 6, 4, 4)\n",
    "                (*,C, h,  w, 1)         (bs, 32, 6, 6)\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*B*C*P*P + B*P*P\n",
    "    \"\"\"   \n",
    "\n",
    "    def __init__(self, ch_in=32, ch_out=32, K=3, P=4, stride=2, iter=3, class_caps=False):\n",
    "        super().__init__()\n",
    "        # init vars\n",
    "        self.ch_in  = ch_in\n",
    "        self.ch_out = ch_out\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.psize = P*P\n",
    "        self.stride = stride\n",
    "        self.iter = iter\n",
    "        self.class_caps = class_caps\n",
    "\n",
    "        # constants\n",
    "            #actualy none\n",
    "        \n",
    "        # params\n",
    "        self.b_u = nn.Parameter(torch.zeros(ch_out))\n",
    "        self.b_a = nn.Parameter(torch.zeros(ch_out))\n",
    "\n",
    "        #deepwiese conv for single caps poses M to generate trained W\n",
    "        self.conv_deep = nn.Conv2d(in_channels=(ch_in*P*P), out_channels=(ch_in*ch_out*P*P), kernel_size=K, stride=stride,\n",
    "                        padding=0, groups=ch_in*ch_out)\n",
    "\n",
    "        # activations\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #split pose and activation\n",
    "        p, a = x\n",
    "\n",
    "        #deepwise conv of poses to get votes v\n",
    "        v = p.view(p.shape[0],-1,p.shape[2],p.shape[3])\n",
    "        v = self.conv_deep(v)\n",
    "\n",
    "        v = v.view(v.shape[0],-1,v.shape[2],v.shape[3],self.P,self.P)\n",
    "        return v, a\n",
    "\n",
    "    def em_routing(self):\n",
    "        pass\n",
    "\n",
    "    def e_step(self):\n",
    "        pass\n",
    "\n",
    "    def m_step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in_channels must be divisible by groups",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m B \u001b[39m=\u001b[39m CapsNetEM()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(count_parameters(B))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m z, b \u001b[39m=\u001b[39m B(x)\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb Cell 13'\u001b[0m in \u001b[0;36mCapsNetEM.__init__\u001b[0;34m(self, A, B, C, D, E, K, P, iter)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=19'>20</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1 \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=20'>21</a>\u001b[0m     nn\u001b[39m.\u001b[39mConv2d(in_channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, out_channels\u001b[39m=\u001b[39mA, kernel_size\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=21'>22</a>\u001b[0m     nn\u001b[39m.\u001b[39mReLU(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39m#nn.BatchNorm2d(num_features=A),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=23'>24</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=24'>25</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprim_caps0 \u001b[39m=\u001b[39m PrimaryCaps(ch_in\u001b[39m=\u001b[39mA, ch_out\u001b[39m=\u001b[39mB, K\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, P\u001b[39m=\u001b[39mP, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_caps1 \u001b[39m=\u001b[39m ConvCaps(ch_in\u001b[39m=\u001b[39;49mB, ch_out\u001b[39m=\u001b[39;49mC, K\u001b[39m=\u001b[39;49mK, P\u001b[39m=\u001b[39;49mP, stride\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39miter\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39miter\u001b[39;49m, class_caps\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=26'>27</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_caps2 \u001b[39m=\u001b[39m ConvCaps(ch_in\u001b[39m=\u001b[39mC, ch_out\u001b[39m=\u001b[39mB, K\u001b[39m=\u001b[39mK, P\u001b[39m=\u001b[39mP, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \u001b[39miter\u001b[39m\u001b[39m=\u001b[39m\u001b[39miter\u001b[39m, class_caps\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000012vscode-remote?line=27'>28</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_caps \u001b[39m=\u001b[39m ConvCaps(ch_in\u001b[39m=\u001b[39mD, ch_out\u001b[39m=\u001b[39mE, K\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, P\u001b[39m=\u001b[39mP, stride\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \u001b[39miter\u001b[39m\u001b[39m=\u001b[39m\u001b[39miter\u001b[39m, class_caps\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb Cell 15'\u001b[0m in \u001b[0;36mConvCaps.__init__\u001b[0;34m(self, ch_in, ch_out, K, P, stride, iter, class_caps)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=39'>40</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_a \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(torch\u001b[39m.\u001b[39mzeros(ch_out))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=41'>42</a>\u001b[0m \u001b[39m#deepwiese conv for single caps poses M to generate trained W\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=42'>43</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_deep \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mConv2d(in_channels\u001b[39m=\u001b[39;49m(ch_in\u001b[39m*\u001b[39;49mP\u001b[39m*\u001b[39;49mP), out_channels\u001b[39m=\u001b[39;49m(ch_in\u001b[39m*\u001b[39;49mch_out\u001b[39m*\u001b[39;49mP\u001b[39m*\u001b[39;49mP), kernel_size\u001b[39m=\u001b[39;49mK, stride\u001b[39m=\u001b[39;49mstride,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=43'>44</a>\u001b[0m                 padding\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, groups\u001b[39m=\u001b[39;49mch_in\u001b[39m*\u001b[39;49mch_out)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=45'>46</a>\u001b[0m \u001b[39m# activations\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000014vscode-remote?line=46'>47</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msigmoid \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSigmoid()\n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py:433\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=430'>431</a>\u001b[0m padding_ \u001b[39m=\u001b[39m padding \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(padding, \u001b[39mstr\u001b[39m) \u001b[39melse\u001b[39;00m _pair(padding)\n\u001b[1;32m    <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=431'>432</a>\u001b[0m dilation_ \u001b[39m=\u001b[39m _pair(dilation)\n\u001b[0;32m--> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=432'>433</a>\u001b[0m \u001b[39msuper\u001b[39;49m(Conv2d, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=433'>434</a>\u001b[0m     in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n\u001b[1;32m    <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=434'>435</a>\u001b[0m     \u001b[39mFalse\u001b[39;49;00m, _pair(\u001b[39m0\u001b[39;49m), groups, bias, padding_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py:84\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[0;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[1;32m     <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=81'>82</a>\u001b[0m \u001b[39msuper\u001b[39m(_ConvNd, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n\u001b[1;32m     <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=82'>83</a>\u001b[0m \u001b[39mif\u001b[39;00m in_channels \u001b[39m%\u001b[39m groups \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=83'>84</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39min_channels must be divisible by groups\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=84'>85</a>\u001b[0m \u001b[39mif\u001b[39;00m out_channels \u001b[39m%\u001b[39m groups \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=85'>86</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mout_channels must be divisible by groups\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: in_channels must be divisible by groups"
     ]
    }
   ],
   "source": [
    "B = CapsNetEM()\n",
    "print(count_parameters(B))\n",
    "z, b = B(x)\n",
    "\n",
    "z.shape, b.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pathes(x, B, K, psize, stride):\n",
    "    \"\"\"\n",
    "        Shape:\n",
    "            Input:     (b, H, W, B*(P*P+1))\n",
    "            Output:    (b, H', W', K, K, B*(P*P+1))\n",
    "    \"\"\"\n",
    "    b, h, w, c = x.shape\n",
    "    assert h == w\n",
    "    assert c == B*(psize+1)\n",
    "    oh = ow = int(((h - K )/stride)+ 1) # moein - changed from: oh = ow = int((h - K + 1) / stride)\n",
    "    idxs = [[(h_idx + k_idx) \\\n",
    "            for k_idx in range(0, K)] \\\n",
    "            for h_idx in range(0, h - K + 1, stride)]\n",
    "    print(idxs)\n",
    "    print(x.shape)\n",
    "    x = x[:, idxs, :, :]\n",
    "    print(x.shape)\n",
    "    x = x[:, :, :, idxs, :]\n",
    "    print(x.shape)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous()\n",
    "    return x, oh, ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 2], [2, 3, 4], [4, 5, 6], [6, 7, 8], [8, 9, 10], [10, 11, 12]]\n",
      "torch.Size([1, 14, 14, 544])\n",
      "torch.Size([1, 6, 3, 14, 544])\n",
      "torch.Size([1, 6, 3, 6, 3, 544])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 6, 3, 3, 544]), 6, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.randn(1, 14, 14,32*17)\n",
    "B = 32\n",
    "K = 3\n",
    "psize = 16\n",
    "stride = 2\n",
    "\n",
    "q, oh, ow = add_pathes(x=q, B=B, K=K, psize=psize, stride=stride)\n",
    "\n",
    "q.shape, oh, ow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000019vscode-remote?line=0'>1</a>\u001b[0m r \u001b[39m=\u001b[39m z\u001b[39m.\u001b[39mview(z\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,z\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m],z\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000019vscode-remote?line=1'>2</a>\u001b[0m r\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "r = z.view(z.shape[0],-1,z.shape[2],z.shape[3])\n",
    "r.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb Cell 21'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000020vscode-remote?line=0'>1</a>\u001b[0m c_out \u001b[39m=\u001b[39m \u001b[39m16\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000020vscode-remote?line=1'>2</a>\u001b[0m CV \u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mConv2d(in_channels\u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], out_channels\u001b[39m=\u001b[39mc_out, kernel_size\u001b[39m=\u001b[39m(\u001b[39m3\u001b[39m,\u001b[39m3\u001b[39m), stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000020vscode-remote?line=2'>3</a>\u001b[0m  dilation\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, groups\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m, bias\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, padding_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000020vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(count_parameters(CV))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/cl_func.ipynb#ch0000020vscode-remote?line=6'>7</a>\u001b[0m cv \u001b[39m=\u001b[39m CV(r)\u001b[39m.\u001b[39mview(\u001b[39m1\u001b[39m,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m6\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m)\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "c_out = 16 * 4 * 4\n",
    "CV =nn.Conv2d(in_channels= r.shape[1], out_channels=c_out, kernel_size=(3,3), stride=2, padding=0,\n",
    " dilation=1, groups=32, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "\n",
    "\n",
    "print(count_parameters(CV))\n",
    "cv = CV(r).view(1,-1,6,6,4,4).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,  16,  32,  48,  64,  80,  96, 112, 128, 144, 160, 176, 192, 208,\n",
       "        224, 240, 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432,\n",
       "        448, 464, 480, 496,   1,  17,  33,  49,  65,  81,  97, 113, 129, 145,\n",
       "        161, 177, 193, 209, 225, 241, 257, 273, 289, 305, 321, 337, 353, 369,\n",
       "        385, 401, 417, 433, 449, 465, 481, 497,   2,  18,  34,  50,  66,  82,\n",
       "         98, 114, 130, 146, 162, 178, 194, 210, 226, 242, 258, 274, 290, 306,\n",
       "        322, 338, 354, 370, 386, 402, 418, 434, 450, 466, 482, 498,   3,  19,\n",
       "         35,  51,  67,  83,  99, 115, 131, 147, 163, 179, 195, 211, 227, 243,\n",
       "        259, 275, 291, 307, 323, 339, 355, 371, 387, 403, 419, 435, 451, 467,\n",
       "        483, 499,   4,  20,  36,  52,  68,  84, 100, 116, 132, 148, 164, 180,\n",
       "        196, 212, 228, 244, 260, 276, 292, 308, 324, 340, 356, 372, 388, 404,\n",
       "        420, 436, 452, 468, 484, 500,   5,  21,  37,  53,  69,  85, 101, 117,\n",
       "        133, 149, 165, 181, 197, 213, 229, 245, 261, 277, 293, 309, 325, 341,\n",
       "        357, 373, 389, 405, 421, 437, 453, 469, 485, 501,   6,  22,  38,  54,\n",
       "         70,  86, 102, 118, 134, 150, 166, 182, 198, 214, 230, 246, 262, 278,\n",
       "        294, 310, 326, 342, 358, 374, 390, 406, 422, 438, 454, 470, 486, 502,\n",
       "          7,  23,  39,  55,  71,  87, 103, 119, 135, 151, 167, 183, 199, 215,\n",
       "        231, 247, 263, 279, 295, 311, 327, 343, 359, 375, 391, 407, 423, 439,\n",
       "        455, 471, 487, 503,   8,  24,  40,  56,  72,  88, 104, 120, 136, 152,\n",
       "        168, 184, 200, 216, 232, 248, 264, 280, 296, 312, 328, 344, 360, 376,\n",
       "        392, 408, 424, 440, 456, 472, 488, 504,   9,  25,  41,  57,  73,  89,\n",
       "        105, 121, 137, 153, 169, 185, 201, 217, 233, 249, 265, 281, 297, 313,\n",
       "        329, 345, 361, 377, 393, 409, 425, 441, 457, 473, 489, 505,  10,  26,\n",
       "         42,  58,  74,  90, 106, 122, 138, 154, 170, 186, 202, 218, 234, 250,\n",
       "        266, 282, 298, 314, 330, 346, 362, 378, 394, 410, 426, 442, 458, 474,\n",
       "        490, 506,  11,  27,  43,  59,  75,  91, 107, 123, 139, 155, 171, 187,\n",
       "        203, 219, 235, 251, 267, 283, 299, 315, 331, 347, 363, 379, 395, 411,\n",
       "        427, 443, 459, 475, 491, 507,  12,  28,  44,  60,  76,  92, 108, 124,\n",
       "        140, 156, 172, 188, 204, 220, 236, 252, 268, 284, 300, 316, 332, 348,\n",
       "        364, 380, 396, 412, 428, 444, 460, 476, 492, 508,  13,  29,  45,  61,\n",
       "         77,  93, 109, 125, 141, 157, 173, 189, 205, 221, 237, 253, 269, 285,\n",
       "        301, 317, 333, 349, 365, 381, 397, 413, 429, 445, 461, 477, 493, 509,\n",
       "         14,  30,  46,  62,  78,  94, 110, 126, 142, 158, 174, 190, 206, 222,\n",
       "        238, 254, 270, 286, 302, 318, 334, 350, 366, 382, 398, 414, 430, 446,\n",
       "        462, 478, 494, 510,  15,  31,  47,  63,  79,  95, 111, 127, 143, 159,\n",
       "        175, 191, 207, 223, 239, 255, 271, 287, 303, 319, 335, 351, 367, 383,\n",
       "        399, 415, 431, 447, 463, 479, 495, 511])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test view\n",
    "dd = torch.arange(0,512,1)\n",
    "dd = dd.reshape(-1,4,4)\n",
    "dd.view(-1)\n",
    "\n",
    "cc = dd.clone()\n",
    "#cc =cc.reshape(4,4,-1)\n",
    "cc = cc.permute(1,2,0)\n",
    "cc.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 4, 4, 6, 6])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test view\n",
    "dd = torch.rand(1,32,4,4,6,6)\n",
    "dd = dd.reshape(1,32,4)\n",
    "#dd.view(-1)\n",
    "dd.shape\n",
    "#cc = dd.clone()\n",
    "#cc =cc.reshape(4,4,-1)\n",
    "#cc = cc.permute(1,2,0)\n",
    "#cc.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17408\n",
      "147456\n",
      "147456\n",
      "5120\n",
      "317440\n"
     ]
    }
   ],
   "source": [
    "2359808\n",
    "147968\n",
    "74240\n",
    "\n",
    "4609\n",
    "\n",
    "print(32*32*17)\n",
    "print(9*32*32*16)\n",
    "print(9*32*32*16)\n",
    "print(32*10*16)\n",
    "print(32*32*17 + 9*32*32*16 + 9*32*32*16+ 32*10*16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 288, 32, 4, 4])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = torch.randn(24, 288, 32, 4, 4)\n",
    "j = torch.randn(24, 288, 32, 4, 4)\n",
    "torch.matmul(q,j).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 12, 12])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "nb_channels = 10\n",
    "h, w = 14,14\n",
    "k = 3\n",
    "x = torch.randn(5, nb_channels, h, w)\n",
    "weights = torch.tensor([[0., 0., 0.],\n",
    "                        [0., 1., 0.],\n",
    "                        [0., 0., 0.]])\n",
    "weights = (torch.ones(1,1,k,k)/k**2).repeat(2, 5, 1, 1)\n",
    "#weights = weights.view(1, 1, 3, 3).repeat(1, nb_channels, 1, 1)\n",
    "\n",
    "output = F.conv2d(x, weights,groups=2)\n",
    "\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_conv(x):\n",
    "    D = nn.Conv2d(in_channels=nb_channels, out_channels=out_channels, kernel_size=k, stride=1, bias=False)\n",
    "    D.weight = torch.nn.Parameter((torch.ones_like(D.weight)/k**2),requires_grad=False)\n",
    "    \n",
    "    x = x.view(bs*p*p, nb_channels,h, w)\n",
    "    x = D(x)\n",
    "    x = x.view(-1, x.shape[1], x.shape[2], x.shape[3], p,p)\n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 32, 12, 12, 4, 4]), 73728, 73728)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "nb_channels = 32\n",
    "out_channels = 32\n",
    "h, w = 14,14\n",
    "p = 4\n",
    "k = 3\n",
    "bs = 1\n",
    "x = torch.randn(bs, nb_channels, p, p , h, w)\n",
    "C = 32\n",
    "\n",
    "#D = nn.Conv2d(in_channels=nb_channels, out_channels=out_channels, kernel_size=k, stride=1, bias=False)\n",
    "#D.weight = torch.nn.Parameter((torch.ones_like(D.weight)/k**2),requires_grad=False)\n",
    "\n",
    "\n",
    "#x = x.view(bs*p*p, nb_channels,h, w)\n",
    "#x = x.view(bs, nb_channels, p, p , h, w)\n",
    "#x.shape\n",
    "#D.weight.shape , D.weight.requires_grad, D.weight.mean(), torch.numel(D.weight)\n",
    "\n",
    "#x = D(x)\n",
    "#x = x.view(-1, x.shape[1], x.shape[2], x.shape[3], p,p)\n",
    "\n",
    "x = fix_conv(x)\n",
    "\n",
    "\n",
    "x.shape\n",
    "\n",
    "\n",
    "w = torch.rand([1, 32, 12, 12, 4, 4])\n",
    "#w.shape\n",
    "\n",
    "v = torch.mul(x, w)\n",
    "\n",
    "v.shape, v.numel(), w.numel()#*3+ count_parameters(PrimaryCaps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(10,1).repeat(1,4)\n",
    "b = torch.rand(10,4)\n",
    "\n",
    "c = torch.mul(a,b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def transform_view(x, w, C, P, w_shared=False):\n",
    "        \"\"\"\n",
    "            For conv_caps:\n",
    "                Input:     (b*H*W, K*K*B, P*P)\n",
    "                Output:    (b*H*W, K*K*B, C, P*P)\n",
    "            For class_caps:\n",
    "                Input:     (b, H*W*B, P*P)\n",
    "                Output:    (b, H*W*B, C, P*P)\n",
    "        \"\"\"\n",
    "        b, B, psize = x.shape\n",
    "        assert psize == P*P\n",
    "\n",
    "        x = x.view(b, B, 1, P, P)\n",
    "        if w_shared:\n",
    "            hw = int(B / w.size(1))\n",
    "            w = w.repeat(1, hw, 1, 1, 1)\n",
    "\n",
    "        w = w.repeat(b, 1, 1, 1, 1)\n",
    "        x = x.repeat(1, 1, C, 1, 1)\n",
    "        v = torch.matmul(x, w)\n",
    "        v = v.view(b, B, C, P*P)\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([144, 288, 32, 16]), 21233664, 147456)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1*12*12,3*3*32,4*4)\n",
    "w = torch.rand(1,3*3*32,32,4,4)\n",
    "t = transform_view(x=x, w=w, C=32, P=4)\n",
    "\n",
    "t.shape, t.numel(), w.numel()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
