{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch import optim\n",
    "import torchvision.datasets as datasets\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from misc.utils import count_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4d3e49ee50>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#R = np.array([[1,2,3],[1,2,3],[1,2,3]])\n",
    "#V = np.array([[1,2,3],[1,2,3],[1,2,3]])+1\n",
    "np.random.seed(0)\n",
    "\n",
    "d1 = 10\n",
    "d2 = 2\n",
    "R  = np.random.rand(d1,d2)\n",
    "V  = np.random.rand(d1,d2)\n",
    "bv = np.random.rand(d2)\n",
    "ba = np.random.rand(d2)\n",
    "la = 0.5\n",
    "\n",
    "ax = 0\n",
    "mu = np.expand_dims((np.sum(R * V, axis=ax)/ np.sum(R, axis=ax)), axis=0)\n",
    "s2 = (np.sum(R * (V-mu)**2, axis=ax)/ np.sum(R, axis=ax))\n",
    "si = np.sqrt(s2)\n",
    "sl = np.log(si)\n",
    "co = (bv + sl) * np.sum(R, axis=ax)\n",
    "ac = (1 / (1 + np.exp(-(la*(ba - np.sum(co))))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pn = 1/np.sqrt(2*math.pi*s2) * np.exp(-((V-mu)**2 / 2*s2))\n",
    "pl = -((V-mu)**2 / 2*s2) - sl - np.log(2*math.pi)/2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "R, V, mu, s2, si, sl, pn, pl, (np.round(pl - np.log(pn), 10))\n",
    "\n",
    "xa = np.arange(1,len(pn[:,0])+1,1)\n",
    "\n",
    "plt.plot(xa, pn[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63386027, 0.6715468 ],\n",
       "       [0.64628827, 0.63294764],\n",
       "       [0.60435748, 0.65608461],\n",
       "       [0.60768396, 0.70925592],\n",
       "       [0.72385455, 0.59470289],\n",
       "       [0.68820161, 0.62922533],\n",
       "       [0.63831185, 0.71618109],\n",
       "       [0.51775155, 0.52176856],\n",
       "       [0.50505443, 0.6969086 ],\n",
       "       [0.68528272, 0.70474823]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 / (1+np.exp(-R)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CN EM from Git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    r\"\"\"Creates a primary convolutional capsule layer\n",
    "    that outputs a pose matrix and an activation.\n",
    "    Note that for computation convenience, pose matrix\n",
    "    are stored in first part while the activations are\n",
    "    stored in the second part.\n",
    "    Args:\n",
    "        A: output of the normal conv layer\n",
    "        B: number of types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "    Shape:\n",
    "        input:  (*, A, h, w)\n",
    "        output: (*, h', w', B*(P*P+1))\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*A*B*P*P + B*P*P\n",
    "    \"\"\"\n",
    "    def __init__(self, A=32, B=32, K=1, P=4, stride=1):\n",
    "        super(PrimaryCaps, self).__init__()\n",
    "        self.pose = nn.Conv2d(in_channels=A, out_channels=B*P*P,\n",
    "                            kernel_size=K, stride=stride, bias=True)\n",
    "        self.a = nn.Conv2d(in_channels=A, out_channels=B,\n",
    "                            kernel_size=K, stride=stride, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = self.pose(x)\n",
    "        a = self.a(x)\n",
    "        a = self.sigmoid(a)\n",
    "        out = torch.cat([p, a], dim=1)\n",
    "        out = out.permute(0, 2, 3, 1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvCaps(nn.Module):\n",
    "    r\"\"\"Create a convolutional capsule layer\n",
    "    that transfer capsule layer L to capsule layer L+1\n",
    "    by EM routing.\n",
    "    Args:\n",
    "        B: input number of types of capsules\n",
    "        C: output number on types of capsules\n",
    "        K: kernel size of convolution\n",
    "        P: size of pose matrix is P*P\n",
    "        stride: stride of convolution\n",
    "        iters: number of EM iterations\n",
    "        coor_add: use scaled coordinate addition or not\n",
    "        w_shared: share transformation matrix across w*h.\n",
    "    Shape:\n",
    "        input:  (*, h,  w, B*(P*P+1))\n",
    "        output: (*, h', w', C*(P*P+1))\n",
    "        h', w' is computed the same way as convolution layer\n",
    "        parameter size is: K*K*B*C*P*P + B*P*P\n",
    "    \"\"\"\n",
    "    def __init__(self, B=32, C=32, K=3, P=4, stride=2, iters=3,\n",
    "                 coor_add=False, w_shared=False):\n",
    "        super(ConvCaps, self).__init__()\n",
    "        # TODO: lambda scheduler\n",
    "        # Note that .contiguous() for 3+ dimensional tensors is very slow\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.psize = P*P\n",
    "        self.stride = stride\n",
    "        self.iters = iters\n",
    "        self.coor_add = coor_add\n",
    "        self.w_shared = w_shared\n",
    "        # constant\n",
    "        self.eps = 1e-8\n",
    "        self._lambda = 1e-03\n",
    "        self.ln_2pi = torch.cuda.FloatTensor(1).fill_(math.log(2*math.pi))\n",
    "        # params\n",
    "        # Note that \\beta_u and \\beta_a are per capsule type,\n",
    "        # which are stated at https://openreview.net/forum?id=HJWLfGWRb&noteId=rJUY2VdbM\n",
    "        self.beta_u = nn.Parameter(torch.zeros(C))\n",
    "        self.beta_a = nn.Parameter(torch.zeros(C))\n",
    "        # Note that the total number of trainable parameters between\n",
    "        # two convolutional capsule layer types is 4*4*k*k\n",
    "        # and for the whole layer is 4*4*k*k*B*C,\n",
    "        # which are stated at https://openreview.net/forum?id=HJWLfGWRb&noteId=r17t2UIgf\n",
    "        self.weights = nn.Parameter(torch.randn(1, K*K*B, C, P, P))\n",
    "        # op\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def m_step(self, a_in, r, v, eps, b, B, C, psize):\n",
    "        \"\"\"\n",
    "            \\mu^h_j = \\dfrac{\\sum_i r_{ij} V^h_{ij}}{\\sum_i r_{ij}}\n",
    "            (\\sigma^h_j)^2 = \\dfrac{\\sum_i r_{ij} (V^h_{ij} - mu^h_j)^2}{\\sum_i r_{ij}}\n",
    "            cost_h = (\\beta_u + log \\sigma^h_j) * \\sum_i r_{ij}\n",
    "            a_j = logistic(\\lambda * (\\beta_a - \\sum_h cost_h))\n",
    "            Input:\n",
    "                a_in:      (b, C, 1)\n",
    "                r:         (b, B, C, 1)\n",
    "                v:         (b, B, C, P*P)\n",
    "            Local:\n",
    "                cost_h:    (b, C, P*P)\n",
    "                r_sum:     (b, C, 1)\n",
    "            Output:\n",
    "                a_out:     (b, C, 1)\n",
    "                mu:        (b, 1, C, P*P)\n",
    "                sigma_sq:  (b, 1, C, P*P)\n",
    "        \"\"\"\n",
    "        r = r * a_in\n",
    "        r = r / (r.sum(dim=2, keepdim=True) + eps)\n",
    "        r_sum = r.sum(dim=1, keepdim=True)\n",
    "        coeff = r / (r_sum + eps)\n",
    "        coeff = coeff.view(b, B, C, 1)\n",
    "\n",
    "        mu = torch.sum(coeff * v, dim=1, keepdim=True)\n",
    "        sigma_sq = torch.sum(coeff * (v - mu)**2, dim=1, keepdim=True) + eps\n",
    "\n",
    "        r_sum = r_sum.view(b, C, 1)\n",
    "        sigma_sq = sigma_sq.view(b, C, psize)\n",
    "        cost_h = (self.beta_u.view(C, 1) + torch.log(sigma_sq.sqrt())) * r_sum\n",
    "\n",
    "        a_out = self.sigmoid(self._lambda*(self.beta_a - cost_h.sum(dim=2)))\n",
    "        sigma_sq = sigma_sq.view(b, 1, C, psize)\n",
    "\n",
    "        return a_out, mu, sigma_sq\n",
    "\n",
    "    def e_step(self, mu, sigma_sq, a_out, v, eps, b, C):\n",
    "        \"\"\"\n",
    "            ln_p_j = sum_h \\dfrac{(\\V^h_{ij} - \\mu^h_j)^2}{2 \\sigma^h_j}\n",
    "                    - sum_h ln(\\sigma^h_j) - 0.5*\\sum_h ln(2*\\pi)\n",
    "            r = softmax(ln(a_j*p_j))\n",
    "              = softmax(ln(a_j) + ln(p_j))\n",
    "            Input:\n",
    "                mu:        (b, 1, C, P*P)\n",
    "                sigma:     (b, 1, C, P*P)\n",
    "                a_out:     (b, C, 1)\n",
    "                v:         (b, B, C, P*P)\n",
    "            Local:\n",
    "                ln_p_j_h:  (b, B, C, P*P)\n",
    "                ln_ap:     (b, B, C, 1)\n",
    "            Output:\n",
    "                r:         (b, B, C, 1)\n",
    "        \"\"\"\n",
    "        ln_p_j_h = -1. * (v - mu)**2 / (2 * sigma_sq) \\\n",
    "                    - torch.log(sigma_sq.sqrt()) \\\n",
    "                    - 0.5*self.ln_2pi\n",
    "\n",
    "        ln_ap = ln_p_j_h.sum(dim=3) + torch.log(a_out.view(b, 1, C))\n",
    "        r = self.softmax(ln_ap)\n",
    "        return r\n",
    "\n",
    "    def caps_em_routing(self, v, a_in, C, eps):\n",
    "        \"\"\"\n",
    "            Input:\n",
    "                v:         (b, B, C, P*P)\n",
    "                a_in:      (b, C, 1)\n",
    "            Output:\n",
    "                mu:        (b, 1, C, P*P)\n",
    "                a_out:     (b, C, 1)\n",
    "            Note that some dimensions are merged\n",
    "            for computation convenient, that is\n",
    "            `b == batch_size*oh*ow`,\n",
    "            `B == self.K*self.K*self.B`,\n",
    "            `psize == self.P*self.P`\n",
    "        \"\"\"\n",
    "        b, B, c, psize = v.shape\n",
    "        assert c == C\n",
    "        assert (b, B, 1) == a_in.shape\n",
    "\n",
    "        r = torch.cuda.FloatTensor(b, B, C).fill_(1./C)\n",
    "        for iter_ in range(self.iters):\n",
    "            a_out, mu, sigma_sq = self.m_step(a_in, r, v, eps, b, B, C, psize)\n",
    "            if iter_ < self.iters - 1:\n",
    "                r = self.e_step(mu, sigma_sq, a_out, v, eps, b, C)\n",
    "\n",
    "        return mu, a_out\n",
    "\n",
    "    def add_pathes(self, x, B, K, psize, stride):\n",
    "        \"\"\"\n",
    "            Shape:\n",
    "                Input:     (b, H, W, B*(P*P+1))\n",
    "                Output:    (b, H', W', K, K, B*(P*P+1))\n",
    "        \"\"\"\n",
    "        b, h, w, c = x.shape\n",
    "        assert h == w\n",
    "        assert c == B*(psize+1)\n",
    "        oh = ow = int(((h - K )/stride)+ 1) # moein - changed from: oh = ow = int((h - K + 1) / stride)\n",
    "        idxs = [[(h_idx + k_idx) \\\n",
    "                for k_idx in range(0, K)] \\\n",
    "                for h_idx in range(0, h - K + 1, stride)]\n",
    "        x = x[:, idxs, :, :]\n",
    "        x = x[:, :, :, idxs, :]\n",
    "        x = x.permute(0, 1, 3, 2, 4, 5).contiguous()\n",
    "        return x, oh, ow\n",
    "\n",
    "    def transform_view(self, x, w, C, P, w_shared=False):\n",
    "        \"\"\"\n",
    "            For conv_caps:\n",
    "                Input:     (b*H*W, K*K*B, P*P)\n",
    "                Output:    (b*H*W, K*K*B, C, P*P)\n",
    "            For class_caps:\n",
    "                Input:     (b, H*W*B, P*P)\n",
    "                Output:    (b, H*W*B, C, P*P)\n",
    "        \"\"\"\n",
    "        b, B, psize = x.shape\n",
    "        assert psize == P*P\n",
    "\n",
    "        x = x.view(b, B, 1, P, P)\n",
    "        if w_shared:\n",
    "            hw = int(B / w.size(1))\n",
    "            w = w.repeat(1, hw, 1, 1, 1)\n",
    "\n",
    "        w = w.repeat(b, 1, 1, 1, 1)\n",
    "        x = x.repeat(1, 1, C, 1, 1)\n",
    "        v = torch.matmul(x, w)\n",
    "        v = v.view(b, B, C, P*P)\n",
    "        return v\n",
    "\n",
    "    def add_coord(self, v, b, h, w, B, C, psize):\n",
    "        \"\"\"\n",
    "            Shape:\n",
    "                Input:     (b, H*W*B, C, P*P)\n",
    "                Output:    (b, H*W*B, C, P*P)\n",
    "        \"\"\"\n",
    "        assert h == w\n",
    "        v = v.view(b, h, w, B, C, psize)\n",
    "        coor = torch.arange(h, dtype=torch.float32) / h\n",
    "        coor_h = torch.cuda.FloatTensor(1, h, 1, 1, 1, self.psize).fill_(0.)\n",
    "        coor_w = torch.cuda.FloatTensor(1, 1, w, 1, 1, self.psize).fill_(0.)\n",
    "        coor_h[0, :, 0, 0, 0, 0] = coor\n",
    "        coor_w[0, 0, :, 0, 0, 1] = coor\n",
    "        v = v + coor_h + coor_w\n",
    "        v = v.view(b, h*w*B, C, psize)\n",
    "        return v\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, h, w, c = x.shape\n",
    "        if not self.w_shared:\n",
    "            # add patches\n",
    "            x, oh, ow = self.add_pathes(x, self.B, self.K, self.psize, self.stride)\n",
    "\n",
    "            # transform view\n",
    "            p_in = x[:, :, :, :, :, :self.B*self.psize].contiguous()\n",
    "            a_in = x[:, :, :, :, :, self.B*self.psize:].contiguous()\n",
    "            p_in = p_in.view(b*oh*ow, self.K*self.K*self.B, self.psize)\n",
    "            a_in = a_in.view(b*oh*ow, self.K*self.K*self.B, 1)\n",
    "            v = self.transform_view(p_in, self.weights, self.C, self.P)\n",
    "\n",
    "            # em_routing\n",
    "            p_out, a_out = self.caps_em_routing(v, a_in, self.C, self.eps)\n",
    "            p_out = p_out.view(b, oh, ow, self.C*self.psize)\n",
    "            a_out = a_out.view(b, oh, ow, self.C)\n",
    "            out = torch.cat([p_out, a_out], dim=3)\n",
    "        else:\n",
    "            assert c == self.B*(self.psize+1)\n",
    "            assert 1 == self.K\n",
    "            assert 1 == self.stride\n",
    "            p_in = x[:, :, :, :self.B*self.psize].contiguous()\n",
    "            p_in = p_in.view(b, h*w*self.B, self.psize)\n",
    "            a_in = x[:, :, :, self.B*self.psize:].contiguous()\n",
    "            a_in = a_in.view(b, h*w*self.B, 1)\n",
    "\n",
    "            # transform view\n",
    "            v = self.transform_view(p_in, self.weights, self.C, self.P, self.w_shared)\n",
    "\n",
    "            # coor_add\n",
    "            if self.coor_add:\n",
    "                v = self.add_coord(v, b, h, w, self.B, self.C, self.psize)\n",
    "\n",
    "            # em_routing\n",
    "            _, out = self.caps_em_routing(v, a_in, self.C, self.eps)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsNet(nn.Module):\n",
    "    \"\"\"A network with one ReLU convolutional layer followed by\n",
    "    a primary convolutional capsule layer and two more convolutional capsule layers.\n",
    "    Suppose image shape is 28x28x1, the feature maps change as follows:\n",
    "    1. ReLU Conv1\n",
    "        (_, 1, 28, 28) -> 5x5 filters, 32 out channels, stride 2 with padding\n",
    "        x -> (_, 32, 14, 14)\n",
    "    2. PrimaryCaps\n",
    "        (_, 32, 14, 14) -> 1x1 filter, 32 out capsules, stride 1, no padding\n",
    "        x -> pose: (_, 14, 14, 32x4x4), activation: (_, 14, 14, 32)\n",
    "    3. ConvCaps1\n",
    "        (_, 14, 14, 32x(4x4+1)) -> 3x3 filters, 32 out capsules, stride 2, no padding\n",
    "        x -> pose: (_, 6, 6, 32x4x4), activation: (_, 6, 6, 32)\n",
    "    4. ConvCaps2\n",
    "        (_, 6, 6, 32x(4x4+1)) -> 3x3 filters, 32 out capsules, stride 1, no padding\n",
    "        x -> pose: (_, 4, 4, 32x4x4), activation: (_, 4, 4, 32)\n",
    "    5. ClassCaps\n",
    "        (_, 4, 4, 32x(4x4+1)) -> 1x1 conv, 10 out capsules\n",
    "        x -> pose: (_, 10x4x4), activation: (_, 10)\n",
    "        Note that ClassCaps only outputs activation for each class\n",
    "    Args:\n",
    "        A: output channels of normal conv\n",
    "        B: output channels of primary caps\n",
    "        C: output channels of 1st conv caps\n",
    "        D: output channels of 2nd conv caps\n",
    "        E: output channels of class caps (i.e. number of classes)\n",
    "        K: kernel of conv caps\n",
    "        P: size of square pose matrix\n",
    "        iters: number of EM iterations\n",
    "        ...\n",
    "    \"\"\"\n",
    "    def __init__(self, A=32, B=32, C=32, D=32, E=10, K=3, P=4, iters=3):\n",
    "        super(CapsNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=A,\n",
    "                               kernel_size=5, stride=2, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(num_features=A, eps=0.001,\n",
    "                                 momentum=0.1, affine=True)\n",
    "        self.relu1 = nn.ReLU(inplace=False)\n",
    "        self.primary_caps = PrimaryCaps(A, B, 1, P, stride=1)\n",
    "        self.conv_caps1 = ConvCaps(B, C, K, P, stride=2, iters=iters)\n",
    "        self.conv_caps2 = ConvCaps(C, D, K, P, stride=1, iters=iters)\n",
    "        self.class_caps = ConvCaps(D, E, 1, P, stride=1, iters=iters,\n",
    "                                        coor_add=True, w_shared=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.primary_caps(x)\n",
    "        x = self.conv_caps1(x)\n",
    "        x = self.conv_caps2(x)\n",
    "        x = self.class_caps(x)\n",
    "        return x\n",
    "\n",
    "    def forward_debug(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.primary_caps(x)\n",
    "        x = self.conv_caps1(x)\n",
    "        x = self.conv_caps2(x)\n",
    "        x = self.class_caps(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsules(**kwargs):\n",
    "    \"\"\"Constructs a CapsNet model.\n",
    "    \"\"\"\n",
    "    model = CapsNet(**kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CapsNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (primary_caps): PrimaryCaps(\n",
      "    (pose): Conv2d(32, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (a): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      "  (conv_caps1): ConvCaps(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      "  (conv_caps2): ConvCaps(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      "  (class_caps): ConvCaps(\n",
      "    (sigmoid): Sigmoid()\n",
      "    (softmax): Softmax(dim=2)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TEST\n",
    "Run this code with:\n",
    "```\n",
    "python -m capsules.py\n",
    "```\n",
    "'''\n",
    "#if __name__ == '__main__':\n",
    "model = capsules(E=10)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpreadLoss(_Loss):\n",
    "\n",
    "    def __init__(self, m_min=0.2, m_max=0.9, num_class=10):\n",
    "        super(SpreadLoss, self).__init__()\n",
    "        self.m_min = m_min\n",
    "        self.m_max = m_max\n",
    "        self.num_class = num_class\n",
    "\n",
    "    def forward(self, x, target, r):\n",
    "        b, E = x.shape\n",
    "        assert E == self.num_class\n",
    "        margin = self.m_min + (self.m_max - self.m_min)*r\n",
    "\n",
    "        at = torch.cuda.FloatTensor(b).fill_(0)\n",
    "        for i, lb in enumerate(target):\n",
    "            at[i] = x[i][lb]\n",
    "        at = at.view(b, 1).repeat(1, E)\n",
    "\n",
    "        zeros = x.new_zeros(x.shape)\n",
    "        loss = torch.max(margin - (at - x), zeros)\n",
    "        loss = loss**2\n",
    "        loss = loss.sum() / b - margin**2\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"../../data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                        batch_size=16, \n",
    "                                        shuffle=True,\n",
    "                                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 1, 28, 28]),\n",
       " tensor([0, 7, 7, 7, 7, 7, 6, 4, 6, 6, 0, 1, 4, 8, 4, 1]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(dl_train))\n",
    "\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "#CN = CapsNet()\n",
    "#CN.to(device)\n",
    "\n",
    "#o = CN.forward_debug(x.to(device))\n",
    "\n",
    "#o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "319028"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CapsNet()\n",
    "model = model.to(device)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = SpreadLoss(num_class=10, m_min=0.2, m_max=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 7.79 GiB total capacity; 6.46 GiB already allocated; 95.94 MiB free; 6.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000025vscode-remote?line=6'>7</a>\u001b[0m y_true \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000025vscode-remote?line=7'>8</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000025vscode-remote?line=8'>9</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000025vscode-remote?line=9'>10</a>\u001b[0m r \u001b[39m=\u001b[39m (\u001b[39m1.\u001b[39m\u001b[39m*\u001b[39midx \u001b[39m+\u001b[39m (epoch\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mtrain_len) \u001b[39m/\u001b[39m (num_epochs\u001b[39m*\u001b[39mtrain_len)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000025vscode-remote?line=10'>11</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(y_pred, y_true,r)         \n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb Cell 9'\u001b[0m in \u001b[0;36mCapsNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000005vscode-remote?line=47'>48</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000005vscode-remote?line=48'>49</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprimary_caps(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000005vscode-remote?line=49'>50</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv_caps1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000005vscode-remote?line=50'>51</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv_caps2(x)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000005vscode-remote?line=51'>52</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_caps(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/mkoch/anaconda3/envs/EffCN/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb Cell 8'\u001b[0m in \u001b[0;36mConvCaps.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=205'>206</a>\u001b[0m p_in \u001b[39m=\u001b[39m p_in\u001b[39m.\u001b[39mview(b\u001b[39m*\u001b[39moh\u001b[39m*\u001b[39mow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpsize)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=206'>207</a>\u001b[0m a_in \u001b[39m=\u001b[39m a_in\u001b[39m.\u001b[39mview(b\u001b[39m*\u001b[39moh\u001b[39m*\u001b[39mow, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mK\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=207'>208</a>\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_view(p_in, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mP)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=209'>210</a>\u001b[0m \u001b[39m# em_routing\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=210'>211</a>\u001b[0m p_out, a_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcaps_em_routing(v, a_in, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\n",
      "\u001b[1;32m/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb Cell 8'\u001b[0m in \u001b[0;36mConvCaps.transform_view\u001b[0;34m(self, x, w, C, P, w_shared)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=170'>171</a>\u001b[0m     hw \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(B \u001b[39m/\u001b[39m w\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=171'>172</a>\u001b[0m     w \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, hw, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=173'>174</a>\u001b[0m w \u001b[39m=\u001b[39m w\u001b[39m.\u001b[39;49mrepeat(b, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=174'>175</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrepeat(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, C, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Bamy.inf-i2.uni-jena.de/home/mkoch/projects/EfficientCN/notebooks/em/gitstuff.ipynb#ch0000004vscode-remote?line=175'>176</a>\u001b[0m v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(x, w)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 324.00 MiB (GPU 0; 7.79 GiB total capacity; 6.46 GiB already allocated; 95.94 MiB free; 6.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "train_len = len(dl_train)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (x, y_true) in enumerate(dl_train):\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        r = (1.*idx + (epoch-1)*train_len) / (num_epochs*train_len)\n",
    "        loss = loss_func(y_pred, y_true,r)         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(\"Epoch[{}/{}] - step {} loss: {:.4f}\".format(epoch, num_epochs, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf positional addition encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 4, 1), (4, 4, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spatial output of ConvCaps2 is 4x4\n",
    "v1 = [[[8.],  [12.], [16.], [20.]],\n",
    "      [[8.],  [12.], [16.], [20.]],\n",
    "      [[8.],  [12.], [16.], [20.]],\n",
    "      [[8.],  [12.], [16.], [20.]],\n",
    "     ]\n",
    "\n",
    "v2 = [[[8.],  [8.],  [8.],  [8]],\n",
    "      [[12.], [12.], [12.], [12.]],\n",
    "      [[16.], [16.], [16.], [16.]],\n",
    "      [[20.], [20.], [20.], [20.]]\n",
    "         ]\n",
    "\n",
    "c1 = np.array(v1, dtype=np.float32) / 28.0\n",
    "c2 = np.array(v2, dtype=np.float32) / 28.0\n",
    "\n",
    "\n",
    "c1.shape,c2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_addition(votes, H, W):\n",
    "    \"\"\"Coordinate addition.\n",
    "\n",
    "    :param votes: (24, 4, 4, 32, 10, 16)\n",
    "    :param H, W: spaital height and width 4\n",
    "\n",
    "    :return votes: (24, 4, 4, 32, 10, 16)\n",
    "    \"\"\"\n",
    "    coordinate_offset_hh = tf.reshape(\n",
    "      (tf.range(H, dtype=tf.float32) + 0.50) / H, [1, H, 1, 1, 1]\n",
    "    )\n",
    "    coordinate_offset_h0 = tf.constant(\n",
    "      0.0, shape=[1, H, 1, 1, 1], dtype=tf.float32\n",
    "    )\n",
    "    coordinate_offset_h = tf.stack(\n",
    "      [coordinate_offset_hh, coordinate_offset_h0] + [coordinate_offset_h0 for _ in range(14)], axis=-1\n",
    "    )  # (1, 4, 1, 1, 1, 16)\n",
    "\n",
    "    coordinate_offset_ww = tf.reshape(\n",
    "      (tf.range(W, dtype=tf.float32) + 0.50) / W, [1, 1, W, 1, 1]\n",
    "    )\n",
    "    coordinate_offset_w0 = tf.constant(\n",
    "      0.0, shape=[1, 1, W, 1, 1], dtype=tf.float32\n",
    "    )\n",
    "    coordinate_offset_w = tf.stack(\n",
    "      [coordinate_offset_w0, coordinate_offset_ww] + [coordinate_offset_w0 for _ in range(14)], axis=-1\n",
    "    ) # (1, 1, 4, 1, 1, 16)\n",
    "\n",
    "    # (24, 4, 4, 32, 10, 16)\n",
    "    votes = votes + coordinate_offset_h + coordinate_offset_w\n",
    "\n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 4, 4, 32, 10, 16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[0.125     , 0.12500001, 0.12500006, 0.125     ],\n",
       "       [0.375     , 0.375     , 0.37499994, 0.375     ],\n",
       "       [0.625     , 0.62499994, 0.625     , 0.625     ],\n",
       "       [0.875     , 0.87499994, 0.875     , 0.875     ]], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "a = np.random.rand(24, 4, 4, 32, 10, 16)\n",
    "print(a.shape)\n",
    "\n",
    "\n",
    "b = coord_addition(votes=a, H=4, W=4)\n",
    "\n",
    "c = b-a\n",
    "p = 3\n",
    "c[0,:,:,31,9,0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
