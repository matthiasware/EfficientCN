{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d762dcb-6188-490f-88d2-f16edd740f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a47b5ccc-2ae8-4fd5-87e7-ff710ff91282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ef41a0-b79a-4c10-a9c2-e1840cbe113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint\n",
    "import hashlib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotted_dict import DottedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e911adc-a442-4a63-b88a-47dd2737c32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5e82fa2-31bb-4431-8401-8ba886c362b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "486749a0-528c-4f20-9bf2-5685efb023c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True)\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08b350c8-aed0-4ad9-88d7-e21b74c6542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x219ECC10700>, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f488019-065d-4b99-a0ea-70ec7d0e9423",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds_train[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76dc15d-afde-4edc-84da-cd7434cce713",
   "metadata": {},
   "source": [
    "### Padding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "074fdf1e-a387-4d2a-8b51-e06ff0e61bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = T.Pad(padding=[2,2,2,2])(ds_train[0][0])\n",
    "#0 & 2 -> x\n",
    "#1 & 3 -> y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "312ab4cd-2578-4394-968f-1f821c23f616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=L size=32x32 at 0x23C737221F0>\n"
     ]
    }
   ],
   "source": [
    "print(pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f327a794-0fa5-4dd8-8ec2-a8dab37ab4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1, high=5, size=None, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d13a638-7bfd-40b4-afae-4f6ae960d700",
   "metadata": {},
   "source": [
    "### Random Pads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3460a76-2094-4861-84a6-cfd66f4f6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_rand():\n",
    "    ref = 8\n",
    "    left = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    rigth = ref - left\n",
    "    up = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    down = ref - up\n",
    "    \n",
    "    return [left, up, rigth, down]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df9baf1f-7cfa-472f-b6ee-ee8dbafe3680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 2, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fdf09d-6f21-467d-81f0-0e45e8f63f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_0 = T.Pad(padding=pad_rand())(ds_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed022001-c1af-453c-a197-314fd58b295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.array(pad_0)\n",
    "print(pr)\n",
    "print(pr.shape)\n",
    "print(pr.max())\n",
    "print(pr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2da657c-ed48-4ef2-aca9-0102ac8c7809",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aa3b203-90b9-4611-9511-206505b18cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_42 = T.Pad(padding=pad_rand())(ds_train[42][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c31f043-e9eb-4e7e-8038-7b396b1b2f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = np.array(pad_42)\n",
    "print(pr)\n",
    "print(pr.shape)\n",
    "print(pr.max())\n",
    "print(pr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708ac38-a7ba-4c87-9995-9535c8f92290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6ae6a0d-c858-4d1c-a445-d61db4383bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(pad_42)\n",
    "b = np.array(pad_0)\n",
    "add = a + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b183535-9090-4a02-8382-e1fae515ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = add\n",
    "print(pr)\n",
    "print(pr.shape)\n",
    "print(pr.max())\n",
    "print(pr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4cfc076-99e2-438f-9fcd-c494ec4658b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil = Image.fromarray(add, mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3704d5-7e0a-43a1-b663-390ace4d7890",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d5b76e0-14b5-46a1-a37b-f1fa09a7a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = add - np.array(pad_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4805e3-474f-4b0a-839b-39f08b5a1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(rec, mode='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6706f1f-5860-45f1-aaa5-14b979431437",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_1 = T.Pad(padding=pad_rand())(ds_train[1][0])\n",
    "pad_15 = T.Pad(padding=pad_rand())(ds_train[15][0])\n",
    "\n",
    "a = np.array(pad_1)\n",
    "b = np.array(pad_15)\n",
    "add = a + b\n",
    "pil = Image.fromarray(add, mode='L')\n",
    "\n",
    "i1 = T.ToTensor()(pad_1)\n",
    "i2 = T.ToTensor()(pad_15)\n",
    "i3 = T.ToTensor()(pil)\n",
    "cat = torch.cat([i1,i2,i3], dim=0)\n",
    "cat = cat.unsqueeze(1)\n",
    "grid = torchvision.utils.make_grid(cat, nrow=3)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd481f9d-9271-456f-81c2-006462b4c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_1 = T.Pad(padding=pad_rand())(ds_train[1][0])\n",
    "pad_15 = T.Pad(padding=pad_rand())(ds_train[15][0])\n",
    "\n",
    "a = T.ToTensor()(pad_1)\n",
    "b = T.ToTensor()(pad_15)\n",
    "add = torch.clamp(a + b,min=0, max=1)\n",
    "pil = T.ToPILImage()(add)\n",
    "\n",
    "#i1 = T.ToTensor()(pad_1)\n",
    "#i2 = T.ToTensor()(pad_15)\n",
    "#i3 = T.ToTensor()(pil)\n",
    "cat = torch.cat([a,b,add], dim=0)\n",
    "cat = cat.unsqueeze(1)\n",
    "grid = torchvision.utils.make_grid(cat, nrow=3)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88699e-7da7-46a9-8b5d-ed92f3e7f0f4",
   "metadata": {},
   "source": [
    "### generate from tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdae9a86-2d2a-4fc5-9ffe-fa4cc3ce9c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "081078ae-f8db-489b-9045-8ef924e4f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_train[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c367ece-60a4-45c0-83ef-4daf9829c1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_1 = T.Pad(padding=pad_rand())(ds_train[1][0])\n",
    "pad_15 = T.Pad(padding=pad_rand())(ds_train[15][0])\n",
    "\n",
    "a = pad_1\n",
    "b = pad_15\n",
    "add = torch.clamp(a + b,min=0, max=1)\n",
    "\n",
    "cat = torch.cat([a,b,add], dim=0)\n",
    "cat = cat.unsqueeze(1)\n",
    "grid = torchvision.utils.make_grid(cat, nrow=3)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499afd2c-c997-4b5a-bade-0e761d48e47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "size = 10\n",
    "np.random.randint(1, high=n, size=size, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652341c-b7fa-4fc0-aca1-cf0910d32e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=0)\n",
    "\n",
    "img, label = ds_train.data, ds_train.targets\n",
    "img = img[:10]\n",
    "label = label[:10]\n",
    "n_multi = 3\n",
    "\n",
    "ref = 7\n",
    "i_ref = ds_train.data[ref]\n",
    "l_ref = ds_train.targets[ref]\n",
    "indexes = np.where(label != l_ref)[0]\n",
    "indexes = np.random.choice(indexes,n_multi,replace=False)\n",
    "\n",
    "\n",
    "print(l_ref)\n",
    "print(label)\n",
    "print(indexes)\n",
    "print(label[indexes[0]],label[indexes[1]],label[indexes[2]])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3649b5b4-6f5e-474c-9de0-54a0351c6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_rand():\n",
    "    ref = 8\n",
    "    left = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    rigth = ref - left\n",
    "    up = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    down = ref - up\n",
    "    \n",
    "    return [left, up, rigth, down]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bede3e-7b97-46f6-86f2-c850faac5a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multimatch(images, labels, ref_idx, n=1000):\n",
    "    #reference img\n",
    "    img_ref = images[ref_idx]\n",
    "    lab_ref = labels[ref_idx]\n",
    "    \n",
    "    #choose random top images from different classes\n",
    "    top_idx = np.where(labels != lab_ref)[0]\n",
    "    top_idx = np.random.choice(top_idx,n,replace=False)\n",
    "\n",
    "    all_imgs = []\n",
    "    all_targets1 = []\n",
    "    all_targets2 = []\n",
    "\n",
    "    for i, idx in enumerate(top_idx):\n",
    "        \n",
    "        base  = T.Pad(padding=pad_rand())(images[ref_idx])\n",
    "        top   = T.Pad(padding=pad_rand())(images[top_idx[i]])\n",
    "\n",
    "        merge = torch.clamp(base + top,min=0, max=1)\n",
    "        merge = merge.unsqueeze(0)\n",
    "        label1 = labels[ref_idx]\n",
    "        label2 = labels[top_idx[i]]\n",
    "        \n",
    "        all_imgs.append(merge)\n",
    "        all_targets1.append(label1)\n",
    "        all_targets2.append(label2)\n",
    "    \n",
    "    return all_imgs, all_targets1, all_targets2\n",
    "\n",
    "img, label1, label2 = multimatch(images=ds_train.data, labels=ds_train.targets, ref_idx=0, n=22)\n",
    "print(len(img), \"\\n\", label1, \"\\n\", label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fdcd3a-5995-4494-bbdd-74a422a9c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = torchvision.utils.make_grid(img, nrow=5)\n",
    "grid = grid.permute(1, 2, 0)\n",
    "plt.imshow(grid)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e27e364-a761-417b-a64a-a97c54e414f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj = 9\n",
    "print(label1[jj])\n",
    "print(label2[jj])\n",
    "plt.imshow(img[jj].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b7866c-b281-4c2c-bf0c-481642ddf7f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generator to pil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fb0634d-483e-4797-9435-91a9620f6910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ff90fc-8e16-4199-a8c5-b2e12bb66746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "153657b2-e0ac-4f4a-9814-61b3d0e2d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a06cae0e-0fe5-4e2f-bc03-527c3dcb2519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint\n",
    "import hashlib\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotted_dict import DottedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "65ec53c0-108b-4520-8cf0-33449f2468d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b724d74c-f2f8-4a13-aa7e-d53af6fdedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_rand():\n",
    "    ref = 8\n",
    "    left = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    rigth = ref - left\n",
    "    up = np.random.randint(1, high=9, size=None, dtype=int)\n",
    "    down = ref - up\n",
    "    \n",
    "    return [left, up, rigth, down]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18095b9d-3153-43d9-bab5-39ad157d3188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def mkdir_directories(dirs, parents, exist_ok):\n",
    "    for director in dirs:\n",
    "        Path(director).mkdir(parents=parents, exist_ok=exist_ok)\n",
    "\n",
    "def multimatch(p_data, images, labels, n=1000):\n",
    "    #paths\n",
    "    p_data = Path(p_data)\n",
    "    p_imgs = p_data  / 'Img'\n",
    "    \n",
    "    mkdir_directories([p_data, p_imgs], parents=True, exist_ok=True)\n",
    "\n",
    "    #lists\n",
    "    all_targets1 = []\n",
    "    all_targets2 = []\n",
    "    \n",
    "    #generator index\n",
    "    index = 1\n",
    "    \n",
    "    #test dataset\n",
    "    test = images[0:3]\n",
    "    print(test.size())\n",
    "    for j, image in enumerate(test):\n",
    "    \n",
    "    #generate for whole dataset\n",
    "    #for j, image in enumerate(images):\n",
    "    \n",
    "        #reference img\n",
    "        img_ref = images[j]\n",
    "        lab_ref = labels[j]\n",
    "\n",
    "        #choose random top images from different classes\n",
    "        top_idx = np.where(labels != lab_ref)[0]\n",
    "        top_idx = np.random.choice(top_idx,n,replace=False)\n",
    "\n",
    "        #generate images\n",
    "        for i, idx in enumerate(top_idx):\n",
    "            \n",
    "            #randomize position\n",
    "            base  = T.Pad(padding=pad_rand())(images[j])\n",
    "            top   = T.Pad(padding=pad_rand())(images[top_idx[i]])\n",
    "            \n",
    "            #merge images\n",
    "            merge = torch.clamp(base + top,min=0, max=1)\n",
    "            merge = merge.unsqueeze(0)\n",
    "            \n",
    "            #add labels to list\n",
    "            label1 = labels[j]\n",
    "            label2 = labels[top_idx[i]]\n",
    "            all_targets1.append(label1)\n",
    "            all_targets2.append(label2)\n",
    "\n",
    "            #Save Img as png\n",
    "            torchvision.utils.save_image(merge.float(), p_imgs / \"{:08d}.png\".format(index))\n",
    "            index += 1 \n",
    "    \n",
    "    #create target 1\n",
    "    file_targets1 = open(p_data /'targets_1.plk', 'wb')\n",
    "    pickle.dump(all_targets1, file_targets1)\n",
    "    file_targets1.close()\n",
    "    \n",
    "    #create target 2\n",
    "    file_targets2 = open(p_data /'targets_2.plk', 'wb')\n",
    "    pickle.dump(all_targets2, file_targets2)\n",
    "    file_targets2.close()\n",
    "\n",
    "multimatch(p_data=\"data/MultiMNIST\" ,images=ds_train.data, labels=ds_train.targets,n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6955a100-c99d-47fe-be66-666c0f61f7bf",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cdb266-de47-4030-8fbe-5161b0e6b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_targets2 = open('data/MultiMNIST/t/targets_1.plk', 'rb')\n",
    "l_data = pickle.load(file_targets2)\n",
    "file_targets2.close()\n",
    "print(l_data)\n",
    "file_targets2 = open('data/MultiMNIST/t/targets_2.plk', 'rb')\n",
    "l_data = pickle.load(file_targets2)\n",
    "file_targets2.close()\n",
    "print(l_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "155a7a0e-e791-4680-879e-aa49708ef15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_dir = 'data/MultiMNIST/t/Img/'\n",
    "\n",
    "filenames = [name for name in os.listdir(data_dir) if os.path.splitext(name)[-1] == '.png']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9110e0f3-7419-4264-8046-0761ab324d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [name for name in os.listdir(data_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcb682ab-c0d3-48cf-bbc2-10a795e1b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_img = torchvision.io.read_image('data/MultiMNIST/t/Img/00000006.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3778e-1f9b-4be0-8dc4-6dc4f3117c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tsr_img.permute((1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a6aac0-03b1-4690-a58c-0830b28c0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsr_img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9879cc-017a-482d-aeac-d8eb1c691a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Image.open('data/MultiMNIST/t/Img/00000006.png')\n",
    "plt.imshow(a)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff271ea-be5a-422c-94ea-c10241b87765",
   "metadata": {},
   "source": [
    "## Dataloader via Torch tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8027ba55-803a-4ee7-bf74-80eaa09bb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "293e4ef9-c7ff-4a3f-8b13-46afdf97769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataClass(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, generate=False):\n",
    "        self.p_root = Path(root)\n",
    "        self.p_img = self.p_root / \"Img\"\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train\n",
    "        \n",
    "        if generate:\n",
    "            pass\n",
    "            #self.generate()\n",
    "        \n",
    "        #exist check!!!\n",
    "\n",
    "        file = open(self.p_root / 'targets_1.plk', 'rb')\n",
    "        self.targets_1 = pickle.load(file)\n",
    "        file.close()\n",
    "\n",
    "        file = open(self.p_root / 'targets_2.plk', 'rb')\n",
    "        self.targets_2 = pickle.load(file)\n",
    "        file.close()\n",
    "        \n",
    "        self.data = os.listdir(self.p_img)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_loc = os.path.join(self.p_img, self.data[idx])\n",
    "        x = Image.open(data_loc).convert(\"L\")\n",
    "        y = self.targets_1[idx]\n",
    "        z = self.targets_2[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            x = self.transform(x)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            y = self.target_transform(y)\n",
    "            z = self.target_transform(z)\n",
    "        \n",
    "        return x, y, z\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9715d3-2efb-4517-9292-20d4d117866f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data/MultiMNIST\"\n",
    "A = DataClass(root)\n",
    "print(A.__len__())\n",
    "print(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6d96b7-ded6-457d-bd0c-50b6b07aa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"data/MultiMNIST\"\n",
    "data = DataClass(root, transform = T.ToTensor())\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=32)\n",
    "\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775f925-b2ea-4138-9a23-159e88e23305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dataloader))\n",
    "img = torchvision.utils.make_grid(x[:64], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
