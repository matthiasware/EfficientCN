{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b2bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a27a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")\n",
    "\n",
    "# standard lib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "# external imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dotted_dict import DottedDict\n",
    "import pprint\n",
    "from tqdm import tqdm\n",
    "import scipy as sp\n",
    "#\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# local imports\n",
    "from datasets import AffNIST\n",
    "from effcn.layers import FCCaps, Squash\n",
    "from effcn.functions import margin_loss, max_norm_masking\n",
    "from effcn.utils import count_parameters\n",
    "from misc.optimizer import get_optimizer, get_scheduler\n",
    "from misc.utils import get_sting_timestamp, mkdir_directories\n",
    "from misc.plot_utils import plot_couplings, plot_capsules, plot_mat, plot_mat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df83289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:1\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b8a87f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1085e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomAffine(degrees=(-8, 8),\n",
    "                   shear=(-15, 15),\n",
    "                   scale=(0.9, 1.1)\n",
    "                  )\n",
    "])\n",
    "transform_valid = None # converts [0,255] to [0,1] by dividing through 255\n",
    "\n",
    "p_data = '/home/matthias/projects/EfficientCN/data'\n",
    "\n",
    "ds_mnist_train = AffNIST(p_root=p_data, split=\"mnist_train\", download=True, transform=transform_train, target_transform=None)\n",
    "ds_mnist_valid = AffNIST(p_root=p_data, split=\"mnist_valid\", download=True, transform=transform_valid, target_transform=None)\n",
    "ds_affnist_valid = AffNIST(p_root=p_data, split=\"affnist_valid\", download=True, transform=transform_valid, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd145857",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "dl_mnist_train = torch.utils.data.DataLoader(\n",
    "    ds_mnist_train, \n",
    "    batch_size=bs, \n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4)\n",
    "dl_mnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_mnist_valid, \n",
    "    batch_size=bs, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=4)\n",
    "dl_affnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_affnist_valid, \n",
    "    batch_size=bs, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb430ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(dl_mnist_train))\n",
    "x_vis_train = x[:32]\n",
    "\n",
    "x, _ = next(iter(dl_mnist_valid))\n",
    "x_vis_mnist_valid = x[:32]\n",
    "\n",
    "x, _ = next(iter(dl_affnist_valid))\n",
    "x_vis_affnist_valid = x[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1404fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torchvision.utils.make_grid(x_vis_train).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_mnist_valid).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_affnist_valid).permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce22576",
   "metadata": {},
   "source": [
    "# Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomBB(nn.Module):\n",
    "    def __init__(self, ch_in=3, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.ch_in = ch_in\n",
    "        self.n_classes=n_classes\n",
    "    \n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=ch_in, out_channels=128, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256, 256, kernel_size=9, groups=256, stride=1, padding=\"valid\"),\n",
    "        )\n",
    "        self.fc = nn.Linear(256 , n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = torch.flatten(x, 1)     # -> (b, 256), remove 1 X 1 grid and make vector of tensor shape \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d9e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomBB(ch_in=1)\n",
    "y = model(torch.rand(128, 1, 40, 40))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11846e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCCaps(nn.Module):\n",
    "    \"\"\"\n",
    "        Attributes\n",
    "        ----------\n",
    "        n_l ... number of lower layer capsules\n",
    "        d_l ... dimension of lower layer capsules\n",
    "        n_h ... number of higher layer capsules\n",
    "        d_h ... dimension of higher layer capsules\n",
    "\n",
    "        W   (n_l, n_h, d_l, d_h) ... weight tensor\n",
    "        B   (n_l, n_h)           ... bias tensor\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_l, n_h, d_l, d_h):\n",
    "        super().__init__()\n",
    "        self.n_l = n_l\n",
    "        self.d_l = d_l\n",
    "        self.n_h = n_h\n",
    "        self.d_h = d_h\n",
    "        \n",
    "        \n",
    "        self.W = torch.nn.Parameter(torch.rand(\n",
    "            n_l, n_h, d_l, d_h), requires_grad=True)\n",
    "        #self.B = torch.nn.Parameter(torch.rand(n_l, n_h), requires_grad=True)\n",
    "        self.squash = Squash(eps=1e-20)\n",
    "\n",
    "        # init custom weights\n",
    "        # i'm relly unsure about this initialization scheme\n",
    "        # i don't think it makes sense in our case, but the paper says so ...\n",
    "        torch.nn.init.kaiming_normal_(\n",
    "            self.W, a=0, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        #torch.nn.init.kaiming_normal_(\n",
    "        #    self.B, a=0, mode=\"fan_in\", nonlinearity=\"leaky_relu\")\n",
    "\n",
    "        self.attention_scaling = np.sqrt(self.d_l)\n",
    "\n",
    "    def forward(self, U_l):\n",
    "        \"\"\"\n",
    "        einsum convenventions:\n",
    "          n_l = i | h\n",
    "          d_l = j\n",
    "          n_h = k\n",
    "          d_h = l\n",
    "\n",
    "        Data tensors:\n",
    "            IN:  U_l ... lower layer capsules\n",
    "            OUT: U_h ... higher layer capsules\n",
    "            DIMS:\n",
    "                U_l (n_l, d_l)\n",
    "                U_h (n_h, d_h)\n",
    "                W   (n_l, n_h, d_l, d_h)\n",
    "                B   (n_l, n_h)\n",
    "                A   (n_l, n_l, n_h)\n",
    "                C   (n_l, n_h)\n",
    "        \"\"\"\n",
    "        U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, self.W)\n",
    "        A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "        U_norm = torch.norm(U_l, dim=-1)\n",
    "        A = torch.einsum(\"...ijk,...j->...ijk\", A, U_norm)\n",
    "        #A = A / self.attention_scaling)\n",
    "        A_sum = torch.einsum(\"...hij->...hj\", A)\n",
    "        #A_sum = torch.einsum(\"...ij,...i->...ij\", A_sum, U_norm)\n",
    "        C = torch.softmax(A_sum, dim=-1)\n",
    "        #CB = C + self.B\n",
    "        U_h = torch.einsum('...ikl,...ik->...kl', U_hat, C)\n",
    "        return self.squash(U_h)\n",
    "\n",
    "    def forward_debug(self, U_l):\n",
    "        \"\"\"\n",
    "        einsum convenventions:\n",
    "          n_l = i | h\n",
    "          d_l = j\n",
    "          n_h = k\n",
    "          d_h = l\n",
    "\n",
    "        Data tensors:\n",
    "            IN:  U_l ... lower layer capsules\n",
    "            OUT: U_h ... higher layer capsules\n",
    "            DIMS:\n",
    "                U_l (n_l, d_l)\n",
    "                U_h (n_h, d_h)\n",
    "                W   (n_l, n_h, d_l, d_h)\n",
    "                B   (n_l, n_h)\n",
    "                A   (n_l, n_l, n_h)\n",
    "                C   (n_l, n_h)\n",
    "        \"\"\"\n",
    "        U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, self.W)\n",
    "        A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "        #A = A / self.attention_scaling\n",
    "        U_norm = torch.norm(U_l, dim=-1)\n",
    "        A = torch.einsum(\"...ijk,...j->...ijk\", A, U_norm)\n",
    "        A_sum = torch.einsum(\"...hij->...hj\", A)\n",
    "        #A_sum = torch.einsum(\"...ij,...i->...ij\", A_sum, U_norm)\n",
    "        C = torch.softmax(A_sum, dim=-1)\n",
    "        #CB = C + self.B\n",
    "        U_h = torch.einsum('...ikl,...ik->...kl', U_hat, C)\n",
    "        return self.squash(U_h), C\n",
    "\n",
    "class DeepCapsNet(nn.Module):\n",
    "    def __init__(self, ns, ds):\n",
    "        super().__init__()\n",
    "        self.ns = ns\n",
    "        self.ds = ds\n",
    "        \n",
    "        self.backbone = CustomBB(ch_in=1)\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        self.squash = Squash(eps=1e-20)\n",
    "        layers = []\n",
    "        for idx in range(1, len(ns), 1):\n",
    "            n_l = ns[idx - 1]\n",
    "            n_h = ns[idx]\n",
    "            d_l = ds[idx - 1]\n",
    "            d_h = ds[idx]\n",
    "            layers.append(FCCaps(n_l, n_h, d_l, d_h) )\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # primecaps\n",
    "        x = self.squash(x.view(-1, self.ns[0], self.ds[0]))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward_debug(self, x):\n",
    "        x = self.backbone(x)\n",
    "        \n",
    "        # primecaps\n",
    "        x = self.squash(x.view(-1, self.ns[0], self.ds[0]))\n",
    "        \n",
    "        us = [torch.clone(x)]\n",
    "        cc = []\n",
    "        # fccaps\n",
    "        for layer in self.layers:\n",
    "            x, c = layer.forward_debug(x)\n",
    "            cc.append(c.detach())\n",
    "            us.append(torch.clone(x).detach())\n",
    "        return x, cc, us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01791255",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [32, 32, 16, 10]\n",
    "ds = [8, 8, 8, 8]\n",
    "\n",
    "model = DeepCapsNet(ns=ns, ds=ds)\n",
    "#\n",
    "print(\"tot Model \", count_parameters(model))\n",
    "print(\"Backbone  \", count_parameters(model.backbone))\n",
    "#\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04deec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay=2e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf55e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 101\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_mnist_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        u_h = model.forward(x)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=10)\n",
    "        loss = margin_loss(u_h, y_one_hot)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_mnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            u_h = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   mnist acc_valid: {:.3f}\".format(total_correct / total))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_affnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            u_h = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   affnist acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb329f52",
   "metadata": {},
   "source": [
    "baseline:\n",
    "- normal routing: 80% acc "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6f8a12",
   "metadata": {},
   "source": [
    "# Visualize and Analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f7ae3",
   "metadata": {},
   "source": [
    "### Show parse tree and activations for individual samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdfd446",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(dl_affnist_valid))\n",
    "x = x[:128]\n",
    "y = y[:128]\n",
    "#\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    u_h, CC, US = model.forward_debug(x.to(device))\n",
    "y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "#\n",
    "US = [u.cpu().numpy() for u in US]\n",
    "CS = [c.cpu().numpy() for c in CC]\n",
    "#\n",
    "Y_true = y.cpu().numpy()\n",
    "Y_pred = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d102f1ad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cl = 9\n",
    "for idx in range(128):\n",
    "    if cl is not None and Y_true[idx] != cl:\n",
    "        continue\n",
    "    cs = [c[idx] for c in CS]\n",
    "    us = [u[idx] for u in US]\n",
    "    u_norms = [np.linalg.norm(u, axis=1) for u in us]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    title = \"exp={} a={}\".format(y[idx], y_pred[idx])\n",
    "    #\n",
    "    plot_couplings(cs, title=title, ax=axes[0], show=False)\n",
    "    #\n",
    "    plot_capsules(u_norms, title=title , ax=axes[1], show=False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb9b79",
   "metadata": {},
   "source": [
    "# Collect Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "YY = []\n",
    "CC = [[] for _ in range(len(ns) - 1)]\n",
    "US = [[] for _ in range(len(ns))]\n",
    "\n",
    "\n",
    "for x,y_true in dl_affnist_valid:\n",
    "    x = x.to(device)\n",
    "    #y_true = y_true.to(device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        _, cc, us = model.forward_debug(x.to(device))\n",
    "        for idx in range(len(cc)):\n",
    "            CC[idx].append(cc[idx].detach().cpu().numpy())\n",
    "        for idx in range(len(us)):\n",
    "            US[idx].append(us[idx].detach().cpu().numpy())\n",
    "        YY.append(y_true.numpy())\n",
    "YY = np.concatenate(YY)\n",
    "CC = [np.concatenate(c) for c in CC]\n",
    "US = [np.concatenate(u) for u in US]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a733919",
   "metadata": {},
   "source": [
    "### Mean parse tree and mean activation for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "# Mean parse tree\n",
    "cc_mean = [np.mean(c, axis=0) for c in CC]\n",
    "cc_std = [np.std(c, axis=0) for c in CC]\n",
    "plot_couplings(cc_mean, ax=axes[0], show=False, title=\"mean couplings\")\n",
    "plot_couplings(cc_std, ax=axes[1], show=False, title=\"std couplings\")\n",
    "    \n",
    "# mean and std capsule activation\n",
    "us_mean = [np.linalg.norm(u, axis=-1).mean(axis=0) for u in US]\n",
    "us_std = [np.linalg.norm(u, axis=-1).std(axis=0) for u in US]\n",
    "plot_capsules(us_mean, scale_factor=1, ax=axes[2], show=False, title=\"mean activation\")\n",
    "plot_capsules(us_std, scale_factor=1, ax=axes[3], show=False, title=\"std activation\")\n",
    "plt.suptitle(\"dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f4597",
   "metadata": {},
   "source": [
    "### classwise mean parse tree and mean activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75155b8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# mean and variance activation\n",
    "for cls in range(10):\n",
    "    idcs = np.where(YY == cls)[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Mean parse tree\n",
    "    cc = [C[idcs] for C in CC]\n",
    "    cc_mean = [np.mean(c, axis=0) for c in cc]\n",
    "    cc_std = [np.std(c, axis=0) for c in cc]\n",
    "    plot_couplings(cc_mean, ax=axes[0], show=False, title=\"mean couplings\")\n",
    "    plot_couplings(cc_std, ax=axes[1], show=False, title=\"std couplings\")\n",
    "    \n",
    "    # mean and std capsule activation\n",
    "    us = [u[idcs] for u in US]\n",
    "    us_mean = [np.linalg.norm(u, axis=-1).mean(axis=0) for u in us]\n",
    "    us_std = [np.linalg.norm(u, axis=-1).std(axis=0) for u in us]\n",
    "    plot_capsules(us_mean, scale_factor=1, ax=axes[2], show=False, title=\"mean activation\")\n",
    "    plot_capsules(us_std, scale_factor=1, ax=axes[3], show=False, title=\"std activation\")\n",
    "    plt.suptitle(\"class {}\".format(cls))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfa0203",
   "metadata": {},
   "source": [
    "# Capsules - Dead and Alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_th_mu = 1e-2\n",
    "c_th_sd = 1e-2\n",
    "\n",
    "fig, axes = plt.subplots(len(US), 2, figsize=(8, 4 * len(US)))\n",
    "#\n",
    "US_alive = []\n",
    "for idx in range(len(US)):\n",
    "    U = US[idx]\n",
    "    U_norm = np.linalg.norm(U, axis=2)\n",
    "    U_norm_mu = U_norm.mean(axis=0)\n",
    "    U_norm_sd = U_norm.std(axis=0)\n",
    "    #\n",
    "    U_dead = (U_norm_sd < 1e-2) * (U_norm_mu < 1e-2)\n",
    "    #\n",
    "    xx = range(len(U_norm_mu))\n",
    "    axes[idx][0].set_title(\"mu(norm(U))\")\n",
    "    axes[idx][0].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][0].bar(xx, U_norm_mu)\n",
    "    axes[idx][0].set_ylim(0, 1)\n",
    "    axes[idx][1].set_title(\"sd(norm(U))\")\n",
    "    axes[idx][1].bar(xx, U_norm_sd)\n",
    "    axes[idx][1].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][1].set_ylim(0, 1)\n",
    "    U_alive = 1 - U_dead\n",
    "    US_alive.append(U_alive)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for U in US_alive:\n",
    "    print(\"Alive/Dead: {:2d}/{:2d},  {:.2f}\".format(np.sum(U), np.sum(1 - U), np.sum(U) / len(U)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c00fb3",
   "metadata": {},
   "source": [
    "# Couplings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0ec07",
   "metadata": {},
   "source": [
    "#### Couplings FROM DEAD Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    C = C[:,np.where(Ul_alive == False)[0],:]\n",
    "    \n",
    "    if len(C.flatten()) < 1:\n",
    "        print(\"No dead capsules for layer {}\".format(idx))\n",
    "        continue\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(33, 11))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ce33",
   "metadata": {},
   "source": [
    "#### Couplings FROM Alive Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f3c510",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    C = C[:,np.where(Ul_alive == True)[0],:]\n",
    "    \n",
    "    C_mu = C.mean(axis=0)\n",
    "    C_sd = C.std(axis=0)\n",
    "    C_mx = C.max(axis=0)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(42, 14))\n",
    "    plot_mat2(C_mu, ax=axes[0], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_sd, ax=axes[1], vmin=0, vmax=0.5)\n",
    "    plot_mat2(C_mx, ax=axes[2], vmin=0, vmax=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750004af",
   "metadata": {},
   "source": [
    "per sample count max coupling and use max to find out if coupling in general gets lower or just the average as they are loosly connected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b5d3f",
   "metadata": {},
   "source": [
    "### Couplings TO Dead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52314d8",
   "metadata": {},
   "source": [
    "### Couplings TO Alive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613d3e2",
   "metadata": {},
   "source": [
    "# Capsules and Coupling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed6a89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_max(C):\n",
    "    return np.max(C, axis=2).mean()\n",
    "\n",
    "def max_std_dev(C):\n",
    "    return np.max(C.std(axis=0), axis=1).mean()\n",
    "\n",
    "def calc_norm_entropy(C):\n",
    "    Cm = C.mean(axis=0)\n",
    "    Ce = np.sum(Cm * np.log(Cm) * (1/np.log(Cm.shape[1])), axis=1) * -1\n",
    "    return Ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac569c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform routing\n",
    "CC_uni = []\n",
    "for C in CC:\n",
    "    CC_uni.append(np.ones(C.shape) / C.shape[2])\n",
    "for C in CC_uni:\n",
    "    print(\"{:.3f}   {:.3f}  {:.3f}\".format(mean_max(C), max_std_dev(C), calc_norm_entropy(C).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e74066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random routing\n",
    "CC_rand = []\n",
    "for C in CC:\n",
    "    Cr = np.random.rand(*C.shape) * 10\n",
    "    Cr = torch.softmax(torch.Tensor(Cr), dim=-1).numpy()\n",
    "    CC_rand.append(Cr)\n",
    "for C in CC_rand:\n",
    "    print(\"{:.3f}   {:.3f}  {:.3f}\".format(mean_max(C), max_std_dev(C), calc_norm_entropy(C).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92e4934",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"      mu(max(c)) sd(max(c))\")\n",
    "for idx in range(1, len(CC) + 1, 1):\n",
    "    Ul = US[idx - 1]\n",
    "    Uh = US[idx]\n",
    "    C = CC[idx - 1]\n",
    "    Ul_alive = US_alive[idx-1]\n",
    "    Ul_dead = 1 - Ul_alive\n",
    "    #\n",
    "    C_alive = C[:,np.where(Ul_alive == True)[0],:]\n",
    "    C_dead = C[:,np.where(Ul_alive == False)[0],:]\n",
    "    print(\"#\" * 30)\n",
    "    #\n",
    "    print(\"total:   {:.3f}     {:.3f}\".format(mean_max(C), max_std_dev(C)))\n",
    "    if len(C_dead.flatten()) > 1:\n",
    "        print(\"alive:   {:.3f}     {:.3f}\".format(mean_max(C_alive), max_std_dev(C_alive)))\n",
    "        print(\"dead:    {:.3f}     {:.3f}\".format(mean_max(C_dead), max_std_dev(C_dead)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b5e62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = 3\n",
    "fig, axes = plt.subplots(3, len(CC), figsize=(sf * len(CC), sf * 3))\n",
    "for idx in range(len(CC)):\n",
    "    C = CC[idx]\n",
    "    Ul_alive = US_alive[idx]\n",
    "    #\n",
    "    C = C[:,np.where(Ul_alive == True)[0],:]\n",
    "    C_ent = calc_norm_entropy(C)\n",
    "    MAXC_mean = C.max(axis=2).mean(axis=0)\n",
    "    MAXC_std = C.max(axis=2).std(axis=0)\n",
    "    \n",
    "    xx = range(C.shape[1])\n",
    "    axes[idx][0].bar(xx, MAXC_mean)\n",
    "    axes[idx][0].set_title(\"mean MAX coupling\")\n",
    "    axes[idx][0].set_ylim(0, 1)\n",
    "    axes[idx][1].bar(xx, MAXC_std)\n",
    "    axes[idx][1].set_title(\"std MAX coupling\")\n",
    "    axes[idx][1].set_ylim(0, 1)\n",
    "    axes[idx][2].bar(xx, C_ent)\n",
    "    axes[idx][2].set_ylim(0, 1)\n",
    "    axes[idx][2].set_title(\"entropy coupling\")\n",
    "    #plt.bar(MAX)\n",
    "    #plot_mat(MAXC, scale_factor=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc21215",
   "metadata": {},
   "source": [
    "# Correlation of lower level capsule activation and max coupling coefficients!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23228eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(US) - 1):\n",
    "    UL = US[idx]\n",
    "    UH = US[idx + 1]\n",
    "    C = CC[idx]\n",
    "    \n",
    "    # correlation for all capsules\n",
    "    U_norm = np.linalg.norm(UL, axis=2)\n",
    "    C_max = np.max(C, axis=2)\n",
    "    u = U_norm.flatten()\n",
    "    c = C_max.flatten()\n",
    "    corr, _ = pearsonr(u, c)\n",
    "    print(corr)\n",
    "    \n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # correlation for each capsule\n",
    "    corrs = [pearsonr(U_norm[:, idx], C_max[:, idx])[0] for idx in range(U_norm.shape[1])]\n",
    "    nans = [int(np.isnan(i)) for i in corrs]\n",
    "    \n",
    "    xx = range(len(corrs))\n",
    "    axes[0].bar(xx, corrs)\n",
    "    axes[0].bar(xx, nans)\n",
    "    axes[0].set_xticks(xx)\n",
    "    \n",
    "    xx = range(len(corrs))\n",
    "    # capsule mean & std\n",
    "    axes[1].bar(xx, U_norm.mean(axis=0))\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_xticks(xx)\n",
    "    axes[2].bar(xx, U_norm.std(axis=0), alpha=0.5)\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].set_xticks(xx)\n",
    "    plt.show()\n",
    "    # capsule sld\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c04746f",
   "metadata": {},
   "source": [
    "# Correlation of HIGHER level capsule activation and max coupling coefficients to lower capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a8a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(US) - 1):\n",
    "    UH = US[idx + 1]\n",
    "    C = CC[idx]\n",
    "    \n",
    "    # correlation for all capsules\n",
    "    U_norm = np.linalg.norm(UH, axis=2)\n",
    "    C_max = np.max(C, axis=1)\n",
    "    u = U_norm.flatten()\n",
    "    c = C_max.flatten()\n",
    "    corr, _ = pearsonr(u, c)\n",
    "    print(corr)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # correlation for each capsule\n",
    "    corrs = [pearsonr(U_norm[:, idx], C_max[:, idx])[0] for idx in range(U_norm.shape[1])]\n",
    "    nans = [int(np.isnan(i)) for i in corrs]\n",
    "\n",
    "    xx = range(len(corrs))\n",
    "    axes[0].bar(xx, corrs)\n",
    "    axes[0].bar(xx, nans)\n",
    "    axes[0].set_xticks(xx)\n",
    "    \n",
    "    xx = range(len(corrs))\n",
    "    # capsule mean & std\n",
    "    axes[1].bar(xx, U_norm.mean(axis=0))\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].set_xticks(xx)\n",
    "    axes[2].bar(xx, U_norm.std(axis=0), alpha=0.5)\n",
    "    axes[2].set_ylim(0, 1)\n",
    "    axes[2].set_xticks(xx)\n",
    "    plt.show()\n",
    "    # capsule sld\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e788a",
   "metadata": {},
   "source": [
    "# How dynamic is the Parse Tree?\n",
    "\n",
    "- For lower level capsules: variation in the routing to upper level capsules\n",
    "- For higher level capsules: variation in the capsules that route to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_norm_entropy(C):\n",
    "    Cm = C.mean(axis=0)\n",
    "    Ce = np.sum(Cm * np.log(Cm) * (1/np.log(Cm.shape[1])), axis=1) * -1\n",
    "    return Ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63f983",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.3, 0.3, 0.2, 0.2],\n",
    "    [0.5, 0.4, 0.05, 0.05],\n",
    "    [0.7, 0.1, 0.1, 0.1],\n",
    "    [0.9, 0.05, 0.02, 0.01],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0992d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(C * np.log(C) * (1/np.log(C.shape[1])), axis=1) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1fec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in C:\n",
    "    e = np.sum(1/np.log(len(c)) * np.log(c) * c) * -1\n",
    "    print(e, sp.stats.entropy(c))\n",
    "Ce = np.sum(Cm * np.log(Cm) * (1/np.log(Cm.shape[1])), axis=1) * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa7da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [\n",
    "    np.array([0.5, 0.5]),\n",
    "    np.array([0.25, 0.25, 0.25, 0.25]),\n",
    "    np.array([0.2, 0.2, 0.2, 0.2, 0.2]),\n",
    "    np.array([0.1] * 10),\n",
    "    np.array([1 / 100] * 100)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in C:\n",
    "    e = np.sum(np.log(c) * c * 1/np.log(len(c))) * -1 \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c7d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.log(c) * c) * - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a84ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.stats.entropy(C.T).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68614022",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in CC:\n",
    "    C_mean = C.mean(axis=0)\n",
    "    C_std = C.std(axis=0)\n",
    "    #\n",
    "    m = C_std.mean(axis=1)\n",
    "    plt.bar(range(len(m)), m)\n",
    "    plt.ylim(0, 0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96db87",
   "metadata": {},
   "source": [
    "# Dead and Alive Capsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e65f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_th_mu = 1e-2\n",
    "c_th_sd = 1e-2\n",
    "\n",
    "fig, axes = plt.subplots(len(US), 2, figsize=(8, 4 * len(US)))\n",
    "#\n",
    "US_alive = []\n",
    "for idx in range(len(US)):\n",
    "    U = US[idx]\n",
    "    U_norm = np.linalg.norm(U, axis=2)\n",
    "    U_norm_mu = U_norm.mean(axis=0)\n",
    "    U_norm_sd = U_norm.std(axis=0)\n",
    "    #\n",
    "    U_dead = (U_norm_sd < 1e-2) * (U_norm_mu < 1e-2)\n",
    "    #\n",
    "    xx = range(len(U_norm_mu))\n",
    "    axes[idx][0].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][0].bar(xx, U_norm_mu)\n",
    "    axes[idx][0].set_ylim(0, 1)\n",
    "    axes[idx][1].bar(xx, U_norm_sd)\n",
    "    axes[idx][1].bar(xx, U_dead, color=\"red\",alpha=0.1)\n",
    "    axes[idx][1].set_ylim(0, 1)\n",
    "    U_alive = 1 - U_dead\n",
    "    US_alive.append(U_alive)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f433c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in CC:\n",
    "    \n",
    "    print(\"{:.3f}   {:.3f}  {:.3f}\".format(mean_max(C), max_std_dev(C), calc_norm_entropy(C).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e700dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1, len(CC) + 1, 1):\n",
    "    Ul = US[idx - 1]\n",
    "    Uh = US[idx]\n",
    "    C = CC[idx - 1]\n",
    "    Ul_alive = US_alive[idx-1]\n",
    "    Ul_dead = 1 - Ul_alive\n",
    "    #\n",
    "    C_alive = C[:,np.where(Ul_alive == True)[0],:]\n",
    "    C_dead = C[:,np.where(Ul_alive == False)[0],:]\n",
    "    print(\"#\" * 50)\n",
    "    #\n",
    "    print(\"total: {:.3f}   {:.3f}  {:.3f}\".format(mean_max(C), max_std_dev(C), calc_norm_entropy(C).mean()))\n",
    "    print(\"alive: {:.3f}   {:.3f}  {:.3f}\".format(mean_max(C_alive), max_std_dev(C_alive), calc_norm_entropy(C_alive).mean()))\n",
    "    if len(C_dead.flatten()) > 1:\n",
    "        print(\"dead:  {:.3f}   {:.3f}  {:.3f}\".format(mean_max(C_dead), max_std_dev(C_dead), calc_norm_entropy(C_dead).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e79552",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(C_dead.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f12d7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C[:,np.where(Ul_alive == True)[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98e4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ul_alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab41e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take_along_axis(C, U_alive, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac980d2",
   "metadata": {},
   "source": [
    "# CrossCorrelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_matrix(x1, x2):\n",
    "    x1 = reshape_(x1)\n",
    "    x2 = reshape_(x2)\n",
    "    c = x1.T @ x2\n",
    "    c.div_(x1.shape[0])\n",
    "    return c\n",
    "\n",
    "def reshape_(x):\n",
    "    if len(x.shape) == 1:\n",
    "        x = x.reshape((-1, 1))\n",
    "    return x\n",
    "\n",
    "def cc_bn(x1, x2, debug=False, eps=1e-5):\n",
    "    x1 = reshape_(x1)\n",
    "    x2 = reshape_(x2)\n",
    "    \n",
    "    bn = torch.nn.BatchNorm1d(x1.shape[1], affine=False, eps=eps)\n",
    "    x1 = bn(x1)\n",
    "    bn = torch.nn.BatchNorm1d(x1.shape[1], affine=False, eps=eps)\n",
    "    x2 = bn(x2)\n",
    "    if debug:\n",
    "        print(\"bn(X1)\", x1.mean(axis=0), x1.var(axis=0))\n",
    "        print(\"bn(X2)\", x2.mean(axis=0), x1.var(axis=0))\n",
    "    #\n",
    "    return cc_matrix(x1, x2)\n",
    "\n",
    "def cc_norm(x1, x2, debug=False, eps=1e-5):\n",
    "    x1 = reshape_(x1)\n",
    "    x2 = reshape_(x2)\n",
    "    \n",
    "    # recenter\n",
    "    #x1 = x1 - x1.mean()\n",
    "    #x2 = x2 - x2.mean()\n",
    "    \n",
    "    # unit variance\n",
    "    if eps > 0:\n",
    "        x1 = (x1 - x1.mean(axis=0)) / torch.sqrt(x1.var(axis=0) + eps)\n",
    "        x2 = (x2 - x2.mean(axis=0)) / torch.sqrt(x2.var(axis=0) + eps)\n",
    "    else:\n",
    "        x1 = (x1 - x1.mean(axis=0)) / x1.std()\n",
    "        x2 = (x2 - x2.mean(axis=0)) / x2.std()\n",
    "    \n",
    "    if debug:\n",
    "        print(\"mv(X1)\", x1.mean(axis=0), x1.var(axis=0))\n",
    "        print(\"mv(X2)\", x2.mean(axis=0), x1.var(axis=0))\n",
    "    #\n",
    "    return cc_matrix(x1, x2)\n",
    "\n",
    "def cc_norm2(x1, x2, debug=False, eps=1e-5):\n",
    "    x1 = reshape_(x1)\n",
    "    x2 = reshape_(x2)\n",
    "    \n",
    "    # recenter\n",
    "    x1 = x1 - x1.mean(axis=0)\n",
    "    x2 = x2 - x2.mean(axis=0)\n",
    "    \n",
    "    # unit variance\n",
    "    if eps > 0:\n",
    "        x1 = x1 / torch.sqrt(x1.var(axis=0) + eps)\n",
    "        x2 = x2 / torch.sqrt(x2.var(axis=0) + eps)\n",
    "    else:\n",
    "        x1 = x1 / x1.std()\n",
    "        x2 = x2 / x2.std()\n",
    "    \n",
    "    if debug:\n",
    "        print(\"mv(X1)\", x1.mean(axis=0), x1.var(axis=0))\n",
    "        print(\"mv(X2)\", x2.mean(axis=0), x1.var(axis=0))\n",
    "    #\n",
    "    return cc_matrix(x1, x2)\n",
    "\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 0\n",
    "C = CC[layer_idx]\n",
    "U = US[layer_idx]\n",
    "#\n",
    "U_norm = np.linalg.norm(U, axis=2)\n",
    "C_max = C.max(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6006dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(U_norm.shape[1]):\n",
    "    plt.scatter(U_norm[:,idx], C_max[:,idx])\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"U_norm\")\n",
    "    plt.ylabel(\"C_max\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max coupling\n",
    "# min coupling\n",
    "# mean coupling\n",
    "# std coupling\n",
    "# to how many capsules is a capsule connected?\n",
    "# how strong is the connection?\n",
    "# visualize routing together with activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6f272",
   "metadata": {},
   "source": [
    "# CNN Only Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12d299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "epochs = 050, acc = 98,0, 73.0\n",
    "epochs = 101, acc = 98.5, 74.1\n",
    "epochs = 201, acc = \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2d5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomBB(ch_in=1, n_classes=10)\n",
    "#\n",
    "model = model.to(device)\n",
    "#backbone\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay=2e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)\n",
    "#\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b6e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609b403",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 101\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_mnist_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model.forward(x)\n",
    "        loss = criterion(logits, y_true)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_mnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   mnist acc_valid: {:.3f}\".format(total_correct / total))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_affnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   affnist acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c4f8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
