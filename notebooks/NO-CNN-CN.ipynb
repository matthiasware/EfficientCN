{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a2223",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce747cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "#\n",
    "\n",
    "from misc.plot_utils import plot_mat, imshow\n",
    "from effcn.layers import FCCaps, FCCapsWOBias, Squash\n",
    "from effcn.utils import count_parameters\n",
    "from effcn.functions import margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631c4564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b95d8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(\n",
    "    root = '/mnt/data/pytorch',\n",
    "    train = True,                         \n",
    "    transform = T.ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "ds_test = datasets.MNIST(\n",
    "    root = '/mnt/data/pytorch',\n",
    "    train = False, \n",
    "    transform = T.ToTensor()\n",
    ")\n",
    "dl_train = DataLoader(ds_train, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceed8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomRotation(degrees=(-30, 30)),\n",
    "    T.RandomResizedCrop(\n",
    "        28,\n",
    "        scale=(0.8, 1.0),\n",
    "        ratio=(1, 1),\n",
    "    ),\n",
    "    T.RandomAffine(\n",
    "        degrees=(-30, 30),\n",
    "        #translate=(0.1, 0.1)\n",
    "    ),\n",
    "    T.ToTensor()\n",
    "])\n",
    "transform_valid = T.Compose([\n",
    "    T.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./../data', train=True, download=True, transform=transform_train)\n",
    "ds_valid = datasets.MNIST(root=\"./../data\", train=False, download=True, transform=transform_valid)\n",
    "#\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                       batch_size=512, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                       batch_size=512, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y = next(iter(dl_train))\n",
    "img = torchvision.utils.make_grid(x[:64], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# plot valid imgs\n",
    "x, y = next(iter(dl_valid))\n",
    "img = torchvision.utils.make_grid(x[:64], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualCapsules(nn.Module):\n",
    "    \"\"\"\n",
    "        Add Dropout ?\n",
    "    \"\"\"\n",
    "    def __init__(self, h, w, c, patch_hw, d_out):\n",
    "        super().__init__()\n",
    "        self.h = h                    # img height\n",
    "        self.w = w                    # img width\n",
    "        self.c = c                    # img channels\n",
    "        self.d_out = d_out            # embedding dim\n",
    "        self.patch_hw = patch_hw      # patch size = patch_h, patch_w\n",
    "        \n",
    "        self.n_patches = h//patch_hw * w//patch_hw  # = #capsules\n",
    "        \n",
    "        # make sure it adds up\n",
    "        self.d_patch = patch_hw**2 * c \n",
    "        assert self.n_patches * self.d_patch == h * w * c\n",
    "\n",
    "        self.pos_emb = nn.Parameter(\n",
    "            torch.rand(1, self.n_patches, d_out),\n",
    "            requires_grad=True\n",
    "        )\n",
    "        self.patch_emb = nn.Sequential(\n",
    "            nn.Linear(self.d_patch, self.d_out),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "            in:  x (b, c, h, w)\n",
    "            out: (b, patch_hw, d)\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        x = rearrange(\n",
    "            x, 'b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)',\n",
    "                                patch_x=self.patch_hw, patch_y=self.patch_hw)\n",
    "        x = self.patch_emb(x)\n",
    "        x = x + self.pos_emb\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f72c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 1, 28, 28))\n",
    "VC = VisualCapsules(28, 28, 1, 4, 16)\n",
    "y = VC(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dface49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartCapsules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657dd42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistCaps(nn.Module):\n",
    "    def __init__(self, patch_dim=7,d_i=64, d_l=8, d_h=16):\n",
    "        super().__init__()\n",
    "        self.patch_dim = patch_dim\n",
    "        self.d_i = d_i\n",
    "        self.d_l = d_l\n",
    "        self.d_h = d_h\n",
    "\n",
    "        self.visualcn = VisualCapsules(28, 28, 1, patch_dim, d_i)\n",
    "        \n",
    "        self.primcaps = nn.Sequential(\n",
    "            nn.Linear(self.d_i, self.d_l),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(self.d_l, self.d_l),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(self.d_l, self.d_l),\n",
    "            Squash(eps=1e-20)\n",
    "        )\n",
    "        \n",
    "        self.fccaps = FCCapsWOBias(\n",
    "            n_l=self.visualcn.n,\n",
    "            n_h=10,\n",
    "            d_l=d_l,\n",
    "            d_h=d_h\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.visualcn(x)\n",
    "        x = self.primcaps(x)\n",
    "        x = self.fccaps(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0209c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_dim = 4\n",
    "d_i = 16\n",
    "d_l = 16\n",
    "d_h = 16\n",
    "\n",
    "model = MnistCaps(\n",
    "    patch_dim=patch_dim,\n",
    "    d_i = d_i,\n",
    "    d_l = d_l,\n",
    "    d_h = d_h,\n",
    ")\n",
    "model = model.to(device)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e9c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((1, 1, 28, 28)).to(device)\n",
    "x = model.visualcn(x)\n",
    "print(x.shape)\n",
    "x = model.primcaps(x)\n",
    "print(x.shape)\n",
    "x = model.fccaps(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccc80e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 16\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        u_h = model.forward(x)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=10)\n",
    "        loss = margin_loss(u_h, y_one_hot)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            u_h = model.forward(x)\n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c40345",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, cmap=\"gray\", vmin=None, vmax=None):\n",
    "    npimg = img.detach().cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)), cmap=cmap, vmin=None, vmax=None)\n",
    "    plt.show()\n",
    "\n",
    "def visTensor(tensor, ch=0, allkernels=False, nrow=8, padding=1):\n",
    "    tensor = tensor.cpu()\n",
    "    n,c,w,h = tensor.shape\n",
    "\n",
    "    if allkernels: tensor = tensor.view(n*c, -1, w, h)\n",
    "    elif c != 3: tensor = tensor[:,ch,:,:].unsqueeze(dim=1)\n",
    "\n",
    "    rows = np.min((tensor.shape[0] // nrow + 1, 64))    \n",
    "    grid = utils.make_grid(tensor, nrow=nrow, normalize=True, padding=padding)\n",
    "    plt.figure( figsize=(nrow,rows) )\n",
    "    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
    "    #return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcebdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef7730",
   "metadata": {},
   "outputs": [],
   "source": [
    "YY = []\n",
    "CC = []\n",
    "UUH = []\n",
    "UUHSQ = []\n",
    "UUHFIN = []\n",
    "UUL = []\n",
    "\n",
    "for X, Y in dl_valid:\n",
    "    X = X.to(device)\n",
    "    X = model.visualcn(X)\n",
    "    U_l = model.primcaps(X)\n",
    "    U_hat, A, A_scaled, A_sum, C, U_h_fin, U_h_sq = model.fccaps.forward_debug(U_l)\n",
    "    \n",
    "    UUL.append(U_l.detach().cpu().numpy())\n",
    "    UUH.append(U_hat.detach().cpu().numpy())\n",
    "    YY.append(Y.numpy())\n",
    "    CC.append(C.detach().cpu().numpy())\n",
    "    UUHSQ.append(U_h_sq.detach().cpu())\n",
    "    UUHFIN.append(U_h_fin.detach().cpu())\n",
    "YY = np.concatenate(YY)\n",
    "CC = np.concatenate(CC)\n",
    "UUHSQ = np.concatenate(UUHSQ)\n",
    "UUHFIN = np.concatenate(UUHFIN)\n",
    "UUH = np.concatenate(UUH)\n",
    "UUL = np.concatenate(UUL)\n",
    "\n",
    "print(YY.shape)\n",
    "print(CC.shape)\n",
    "\n",
    "print(\"U_l      \", U_l.shape[1:])\n",
    "print(\"U_hat    \", U_hat.shape[1:])\n",
    "print(\"A        \", A.shape[1:])\n",
    "print(\"A_scaled \", A_scaled.shape[1:])\n",
    "print(\"A_sum    \", A_sum.shape[1:])\n",
    "print(\"C        \", C.shape[1:])\n",
    "print(\"U_h_fin  \", U_h_fin.shape[1:])\n",
    "print(\"U_h_sq   \", U_h_sq.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4081b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idcs = np.where(YY == 2)\n",
    "Y = YY[idcs]\n",
    "C = CC[idcs]\n",
    "UH = UUH[idcs]\n",
    "UHS = UUHSQ[idcs]\n",
    "UHF = UUHFIN[idcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78bdc22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx in range(3):\n",
    "    print(\"#\"*100)\n",
    "    y = Y[idx]\n",
    "    c = C[idx]\n",
    "    uhs = UHS[idx]\n",
    "    uhf = UHF[idx]\n",
    "    ul = UUL[idx]\n",
    "    plot_mat(ul, scale_factor=0.4, title=\"U_l = lower level capsules\")\n",
    "    plot_mat(c, scale_factor=0.4, title=\"C\")\n",
    "    #plot_mat(uhf, scale_factor=0.4, title=\"U_h, upper layer capsules w/o squash\")\n",
    "    plot_mat(uhs, scale_factor=0.4, title=\"squash(U_h)\")\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 2))\n",
    "    axes[0].bar(range(10), c.mean(axis=0))\n",
    "    axes[0].set_title(\"C\")\n",
    "    axes[3].bar(range(10), np.linalg.norm(uhs, axis=1))\n",
    "    axes[3].set_title(\"sqash(U_h)\")\n",
    "    axes[2].bar(range(10), np.linalg.norm(uhf, axis=1))\n",
    "    axes[2].set_title(\"U_h without Squash\")\n",
    "    axes[1].bar(range(ul.shape[0]), np.linalg.norm(ul, axis=1))\n",
    "    axes[1].set_title(\"U_l\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d9633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
