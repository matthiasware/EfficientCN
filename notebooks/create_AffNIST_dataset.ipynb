{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dotted-dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2381122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dotted_dict import DottedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b49a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DottedDict({\n",
    "    'mnist_train': {},\n",
    "    'mnist_valid': {},\n",
    "    'affnist_train': {},\n",
    "    'affnist_valid': {}\n",
    "})\n",
    "config.p_data_root_mnist = \"./../data\"\n",
    "config.p_data_affnist = \"./../data/affnist\"\n",
    "\n",
    "config.img_height = 40\n",
    "config.img_width = 40\n",
    "\n",
    "# MNIST TRAIN CONFIG\n",
    "config.mnist_train.samples_per_sample = 1\n",
    "config.mnist_train.strip_zeros = False\n",
    "config.mnist_train.file_name = \"mnist_train.pt\"\n",
    "\n",
    "# MNIST VALID CONFIG\n",
    "config.mnist_valid.samples_per_sample = 1\n",
    "config.mnist_valid.strip_zeros = False\n",
    "config.mnist_valid.file_name = \"mnist_valid.pt\"\n",
    "\n",
    "# AFFNIST TRAIN CONFIG\n",
    "config.rotate_degrees = (-20, 20)\n",
    "config.sheer_degrees = (-40, 40)\n",
    "config.scale = (0.8, 1.2)\n",
    "\n",
    "config.affnist_train.samples_per_sample = 1\n",
    "config.affnist_train.file_name = \"affnist_train.pt\"\n",
    "\n",
    "# AFFNIST VALID CONFIG\n",
    "config.affnist_valid.samples_per_sample = 1\n",
    "config.affnist_valid.file_name = \"affnist_valid.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7645c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pprint = pp.pprint \n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd7ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(config.p_data_affnist).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e661d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_idcs_1d(T):\n",
    "    assert len(T.shape) == 1\n",
    "    for idx_from in range(len(T)):\n",
    "        if T[idx_from] > 0:\n",
    "            break\n",
    "    for idx_to in range(len(T) -1, 0, -1):\n",
    "        if T[idx_to] > 0:\n",
    "            idx_to += 1\n",
    "            break\n",
    "    return idx_from, idx_to\n",
    "\n",
    "def strip_tensor_2d(T):\n",
    "    assert len(T.shape) == 2\n",
    "    col_from, col_to = get_content_idcs_1d(T.sum(axis=0))\n",
    "    row_from, row_to = get_content_idcs_1d(T.sum(axis=1))\n",
    "    return T[row_from:row_to, col_from:col_to]\n",
    "\n",
    "def randomly_place(A, B=None, h_B=None, w_B=None):\n",
    "    \"\"\"\n",
    "        Randly place A into B\n",
    "        with a margin of 1\n",
    "    \"\"\"\n",
    "    assert len(A.shape) == 2\n",
    "    if B is not None:\n",
    "        assert len(B.shape) == 2\n",
    "        h_b, w_B = B.shape\n",
    "    else:\n",
    "        assert h_B is not None\n",
    "        assert w_B is not None\n",
    "        B = torch.zeros((h_B, w_B), dtype=A.dtype)\n",
    "        \n",
    "    h_A, w_A = A.shape\n",
    "    #\n",
    "    row_from = np.random.randint(low=0, high=h_B - h_A + 1)\n",
    "    row_to = row_from + h_A\n",
    "\n",
    "    col_from = np.random.randint(low=0, high=w_B - w_A + 1)\n",
    "    col_to = col_from + w_A\n",
    "    B[row_from:row_to, col_from:col_to] = A\n",
    "    return B\n",
    "\n",
    "def create_padded_mnist_tensors(train, strip, height, width, n_samples, p_root):\n",
    "    ds = datasets.MNIST(root=p_root, train=train, download=True, transform=None)\n",
    "    data, targets = ds.data, ds.targets\n",
    "\n",
    "    all_imgs = []\n",
    "    all_targets = []\n",
    "    for idx, img in enumerate(data):\n",
    "        if strip:\n",
    "            img = strip_tensor_2d(img)\n",
    "        all_imgs += torch.stack([randomly_place(img, h_B=height, w_B=width) for _ in range(n_samples)])\n",
    "    all_imgs = torch.stack(all_imgs)\n",
    "    all_targets = targets.repeat_interleave(n_samples)\n",
    "    return all_imgs, all_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b669632e",
   "metadata": {},
   "source": [
    "# MNIST Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc93a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = create_padded_mnist_tensors(\n",
    "    train=True,\n",
    "    strip=config.mnist_train.strip_zeros,\n",
    "    height=config.img_height,\n",
    "    width=config.img_width,\n",
    "    n_samples=config.mnist_train.samples_per_sample,\n",
    "    p_root=config.p_data_root_mnist\n",
    ")\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ea224",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 8\n",
    "grid = torchvision.utils.make_grid(imgs[:n_vis].unsqueeze(1), nrow=config.mnist_train.samples_per_sample)\n",
    "plt.figure(figsize=(2 * 2, n_vis * 2))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb4dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:n_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d0145",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mnist_train = Path(config.p_data_affnist) / config.mnist_train.file_name\n",
    "\n",
    "# save stuff\n",
    "torch.save([imgs, targets], p_mnist_train)\n",
    "\n",
    "# try load\n",
    "imgs, targets = torch.load(p_mnist_train)\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7a815d",
   "metadata": {},
   "source": [
    "# MNIST Valid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = create_padded_mnist_tensors(\n",
    "    train=False,\n",
    "    strip=config.mnist_valid.strip_zeros,\n",
    "    height=config.img_height,\n",
    "    width=config.img_width,\n",
    "    n_samples=config.mnist_valid.samples_per_sample,\n",
    "    p_root=config.p_data_root_mnist\n",
    ")\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe563a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 8\n",
    "grid = torchvision.utils.make_grid(imgs[:n_vis].unsqueeze(1), nrow=config.mnist_train.samples_per_sample)\n",
    "plt.figure(figsize=(2 * 2, n_vis * 2))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ffa431",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:n_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3c2e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mnist_valid = Path(config.p_data_affnist) / config.mnist_valid.file_name\n",
    "\n",
    "# save stuff\n",
    "torch.save([imgs, targets], p_mnist_valid)\n",
    "\n",
    "# try load\n",
    "imgs, targets = torch.load(p_mnist_valid)\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100c7155",
   "metadata": {},
   "source": [
    "# AffNIST Train Data \n",
    "\n",
    "The AffNIST dataset is created by padding the orignal 28x28 MNIST images with 6 px to 40x40 and then randomly affine transform them via:\n",
    "- rotation within 20 degrees\n",
    "- sheering withing 45 degrees\n",
    "- scaling from 0.8 to 1.2 in both vertical and horizonal directions\n",
    "- translations within 8 pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a656f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_affnist_tensors(train, height, width, n_samples, p_root, transforms):\n",
    "    ds = datasets.MNIST(root=p_root, train=train, download=True, transform=None)\n",
    "    data, targets = ds.data, ds.targets\n",
    "    \n",
    "    # padding\n",
    "    pad = (height - 28) // 2\n",
    "    assert 2*pad + 28 == height\n",
    "    assert height == width\n",
    "    \n",
    "    all_imgs = []\n",
    "    all_targets = []\n",
    "    for idx, img in enumerate(data):\n",
    "        for _ in range(n_samples):\n",
    "            # pad img to 40x40\n",
    "            img_aff = F.pad(input=img, pad=(pad, pad, pad, pad), mode='constant', value=0)\n",
    "\n",
    "            # rotation, scaling, sheering\n",
    "            img_aff = transforms(img_aff.unsqueeze(0)).squeeze()\n",
    "            \n",
    "            # strip img\n",
    "            img_aff = strip_tensor_2d(img_aff)\n",
    "    \n",
    "            # translate\n",
    "            img_aff = randomly_place(img_aff, h_B=height, w_B=width)\n",
    "            \n",
    "            all_imgs.append(img_aff)\n",
    "    all_imgs = torch.stack(all_imgs)\n",
    "    all_targets = targets.repeat_interleave(n_samples)\n",
    "    return all_imgs, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f1fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36782862",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.RandomAffine(\n",
    "    degrees=config.rotate_degrees,\n",
    "    translate=None,  # we do that later manually\n",
    "    shear=config.sheer_degrees,\n",
    "    scale=config.scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fc5ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = create_affnist_tensors(\n",
    "    train=True,\n",
    "    height=config.img_height,\n",
    "    width=config.img_width,\n",
    "    n_samples=config.affnist_train.samples_per_sample,\n",
    "    p_root=config.p_data_root_mnist,\n",
    "    transforms=transforms\n",
    ")\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2207ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 16\n",
    "grid = torchvision.utils.make_grid(imgs[:n_vis].unsqueeze(1), nrow=config.mnist_train.samples_per_sample)\n",
    "plt.figure(figsize=(2 * 2, n_vis * 2))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9902ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets[:n_vis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741eabae",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_affnist_train = Path(config.p_data_affnist) / config.affnist_train.file_name\n",
    "\n",
    "# save stuff\n",
    "torch.save([imgs, targets], p_affnist_train)\n",
    "\n",
    "# try load\n",
    "imgs, targets = torch.load(p_affnist_train)\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510b1ec3",
   "metadata": {},
   "source": [
    "# AffNIST Valid Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.RandomAffine(\n",
    "    degrees=config.rotate_degrees,\n",
    "    translate=None,  # we do that later manually\n",
    "    shear=config.sheer_degrees,\n",
    "    scale=config.scale\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd098584",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs, targets = create_affnist_tensors(\n",
    "    train=False,\n",
    "    height=config.img_height,\n",
    "    width=config.img_width,\n",
    "    n_samples=config.affnist_valid.samples_per_sample,\n",
    "    p_root=config.p_data_root_mnist,\n",
    "    transforms=transforms\n",
    ")\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8b595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 16\n",
    "grid = torchvision.utils.make_grid(imgs[:n_vis].unsqueeze(1), nrow=config.mnist_train.samples_per_sample)\n",
    "plt.figure(figsize=(2 * 2, n_vis * 2))\n",
    "plt.imshow(grid.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ef989",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_affnist_valid = Path(config.p_data_affnist) / config.affnist_valid.file_name\n",
    "\n",
    "# save stuff\n",
    "torch.save([imgs, targets], p_affnist_valid)\n",
    "\n",
    "# try load\n",
    "imgs, targets = torch.load(p_affnist_valid)\n",
    "print(imgs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d18e1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
