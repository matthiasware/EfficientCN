{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07aa17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "#\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"./data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9449851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ds_train.data[0], cmap='gray')\n",
    "plt.title('%i' % ds_train.targets[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50988be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                          batch_size=16, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9a9dfd",
   "metadata": {},
   "source": [
    "# Baseline CNN for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c90ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5277cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cdf256",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e005f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (x, y_true) in enumerate(dl_train):\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y_true)\n",
    "\n",
    "        # clear gradients for this training step   \n",
    "        optimizer.zero_grad()           \n",
    "            \n",
    "        # backpropagation, compute gradients \n",
    "        loss.backward()    \n",
    "        # apply gradients             \n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(\"Epoch[{}/{}] - step {} loss: {:.4f}\".format(epoch, num_epochs, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y_true in dl_valid:\n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.max(y_pred, 1)[1]\n",
    "        correct += (y_pred == y_true).sum().item()\n",
    "        total += y_true.shape[0]\n",
    "    acc = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(total - correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c175ff9",
   "metadata": {},
   "source": [
    "# Eff-Caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb078de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimaryCaps(nn.Module):\n",
    "    \"\"\"\n",
    "        Create a primary capsule layer with the methodology described in 'Efficient-CapsNet: Capsule Network with Self-Attention Routing'. \n",
    "        Properties of each capsule s_n are exatracted using a 2D depthwise convolution.\n",
    "\n",
    "        ...\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        F: int depthwise conv number of features\n",
    "        K: int depthwise conv kernel dimension \n",
    "        N: int number of primary capsules\n",
    "        D: int primary capsules dimension (number of properties)\n",
    "        s: int depthwise conv strides\n",
    "    \"\"\"\n",
    "    def __init__(self, F, K, N, D, s=1):\n",
    "        super().__init__()\n",
    "        self.F = F\n",
    "        self.K = K\n",
    "        self.N = N\n",
    "        self.D = D\n",
    "        self.s = s\n",
    "        #\n",
    "        self.dw_conv2d = nn.Conv2d(F, F, kernel_size=K, stride=s, groups=F, padding=\"valid\")\n",
    "        #\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         X in (B,C,H,W) = (B,F,K,K)\n",
    "         -> (B, N, D)\n",
    "        \"\"\"\n",
    "        # (B,C,H,W) -> (B,C,H,W)\n",
    "        x = self.dw_conv2d(x)\n",
    "\n",
    "        # (B,C,H,W) -> (B, N, D)\n",
    "        x = x.view((-1, self.N, self.D))\n",
    "        \n",
    "        #\n",
    "        return x\n",
    "\n",
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=10e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         in:  (b, n, d)\n",
    "         out: (b, n, d)\n",
    "        \"\"\"\n",
    "        xn = torch.norm(x, dim=2, keepdim=True)\n",
    "        return (1 - 1/(torch.exp(xn) + self.eps)) * (x / (xn + self.eps))\n",
    "\n",
    "class FCCaps(nn.Module):\n",
    "    def __init__(self, n_l, n_h, d_l, d_h):\n",
    "        super().__init__()\n",
    "        self.n_l = n_l\n",
    "        self.d_l = d_l\n",
    "        self.n_h = n_h\n",
    "        self.d_h = d_h\n",
    "        #\n",
    "        self.W = torch.nn.Parameter(torch.rand(n_l, n_h, d_l, d_h), requires_grad=True)\n",
    "        self.B = torch.nn.Parameter(torch.rand(n_l, n_h), requires_grad=True)\n",
    "        self.squash = Squash()\n",
    "\n",
    "    def forward(self, U_l):\n",
    "        \"\"\"\n",
    "        einsum convenventions:\n",
    "          n_l = i | h\n",
    "          d_l = j\n",
    "          n_h = k\n",
    "          d_h = l\n",
    "        \n",
    "        Data tensors:\n",
    "            IN:  U_l\n",
    "            OUT: U_h\n",
    "            DIMS: \n",
    "                U_l (n_l, d_l)\n",
    "                U_h (n_h, d_h)\n",
    "                W   (n_l, n_h, d_l, d_h)\n",
    "                B   (n_l, n_h)\n",
    "                A   (n_l, n_l, n_h)\n",
    "                C   (n_l, n_h)\n",
    "        \"\"\"\n",
    "        U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, self.W)\n",
    "        A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "        A = A / torch.sqrt(torch.Tensor([d_l]))\n",
    "        A_sum = torch.einsum(\"...hij->...hj\",A)\n",
    "        C = torch.softmax(A_sum,dim=-1)\n",
    "        CB = C + self.B\n",
    "        U_h = torch.einsum('...ikl,...ik->...kl', U_hat, CB)\n",
    "        return self.squash(U_h)\n",
    "\n",
    "\n",
    "class EfficientCapsNets(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def call(self, x):\n",
    "        pass\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d90430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Part\n",
    "# add he normal initializer\n",
    "cn = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=(5, 5), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.Conv2d(32, 64, kernel_size=(3, 3), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 64, kernel_size=(3, 3), padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.Conv2d(64, 128, kernel_size=(3, 3), stride=2, padding=\"valid\"),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.BatchNorm2d(128),\n",
    ")\n",
    "x_h = cn(x)\n",
    "print(x_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e90da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_l = 16\n",
    "d_l = 8\n",
    "#\n",
    "n_h = 10\n",
    "d_h = 16\n",
    "#\n",
    "pc = PrimaryCaps(F=128, K=9, N=n_l, D=d_l)\n",
    "#\n",
    "U_0 = pc(x_h)\n",
    "print(U_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04871754",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn = FCCaps(n_l, n_h, d_l, d_h)\n",
    "#\n",
    "U_1 = fcn(U_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d276c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_flat = torch.flatten(U_1, start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ab909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    nn.Linear(16*10, 512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(512, 1024),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(1024, 28*28),\n",
    "    nn.Sigmoid(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd30330",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_rec = generator(U_flat)\n",
    "x_rec = x_rec.view((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5723cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_view = x_rec.reshape((-1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c690881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_view[5].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape, x_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.mse_loss(x, x_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3b0fb",
   "metadata": {},
   "source": [
    "#### squash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc52b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=10e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "         in:  (b, n, d)\n",
    "         out: (b, n, d)\n",
    "        \"\"\"\n",
    "        xn = torch.norm(x, dim=2, keepdim=True)\n",
    "        return (1 - 1/(torch.exp(xn) + self.eps)) * (x / (xn + self.eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec41092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, eps=10e-21):\n",
    "    x_norm = torch.norm(x, dim=2, keepdim=True)\n",
    "    return (1 - 1/(torch.exp(x_norm) + eps)) * (x / (x_norm + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1590bbfe",
   "metadata": {},
   "source": [
    "#### margin loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(u, y_true, lbd=0.5, m_plus=0.9, m_minus=0.1):\n",
    "    \"\"\"\n",
    "    U      (b,n,d) output of capsnet\n",
    "    y_true (b, n)  label vector, catergorical representation\n",
    "    \"\"\"\n",
    "    u_norm = torch.norm(u, dim=2)\n",
    "    term_left  = F.relu(m_plus - u_norm)\n",
    "    term_right = F.relu(u_norm - m_minus)\n",
    "    #\n",
    "    loss = y_true * term_left + lbd * (1.0 - y_true) * term_right\n",
    "    loss = loss.sum(dim=1).mean()\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8777b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbd = 0.5\n",
    "m_plus = 0.9\n",
    "m_minus = 1 - m_plus\n",
    "#\n",
    "b = 2\n",
    "n = 3\n",
    "d = 4\n",
    "#\n",
    "y_true = torch.Tensor([\n",
    "    [1., 0., 0.],\n",
    "    [0., 1., 0.]\n",
    "])\n",
    "U_l = torch.rand(b,n,d)\n",
    "U_l = Squash()(U_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169c860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_loss(U_l, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48f6700",
   "metadata": {},
   "source": [
    "### masked reconstruction loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aaa5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_masking(u):\n",
    "    \"\"\"\n",
    "     u (b, n, d)\n",
    "     normalise over dimension d\n",
    "     keep largest vector in dimension n\n",
    "     mask out everything else\n",
    "    \"\"\"\n",
    "    _, n_classes, _ = u.shape\n",
    "    u_norm = torch.norm(u,dim=2)\n",
    "    mask = F.one_hot(torch.argmax(u_norm,1), num_classes=n_classes)\n",
    "    return torch.einsum('bnd,bn->bnd',u, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a42d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
