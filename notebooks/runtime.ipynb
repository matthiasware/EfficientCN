{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cProfile\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets.multimnist import MultiMNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate multimnist...\n",
      "torch.Size([10, 28, 28])\n",
      "torch.Size([10, 28, 28])\n",
      "generation done\n",
      "         131121 function calls (128521 primitive calls) in 3.967 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "       24    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(prod)\n",
      "       20    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(where)\n",
      "        1    0.006    0.006    3.967    3.967 <string>:1(<module>)\n",
      "      200    0.002    0.000    0.078    0.000 Image.py:2158(save)\n",
      "      600    0.001    0.000    0.001    0.000 Image.py:2651(_check_size)\n",
      "      200    0.001    0.000    0.003    0.000 Image.py:2669(new)\n",
      "      200    0.001    0.000    0.006    0.000 Image.py:2708(frombytes)\n",
      "      200    0.000    0.000    0.007    0.000 Image.py:2746(frombuffer)\n",
      "      200    0.003    0.000    0.017    0.000 Image.py:2799(fromarray)\n",
      "      200    0.000    0.000    0.000    0.000 Image.py:341(preinit)\n",
      "      200    0.001    0.000    0.001    0.000 Image.py:413(_getdecoder)\n",
      "      200    0.001    0.000    0.001    0.000 Image.py:436(_getencoder)\n",
      "      400    0.000    0.000    0.000    0.000 Image.py:524(__init__)\n",
      "      800    0.000    0.000    0.000    0.000 Image.py:556(size)\n",
      "      200    0.001    0.000    0.001    0.000 Image.py:560(_new)\n",
      "      200    0.000    0.000    0.001    0.000 Image.py:622(_ensure_mutable)\n",
      "      200    0.001    0.000    0.002    0.000 Image.py:788(frombytes)\n",
      "      400    0.001    0.000    0.001    0.000 Image.py:814(load)\n",
      "      200    0.003    0.000    0.037    0.000 ImageFile.py:478(_save)\n",
      "      200    0.000    0.000    0.000    0.000 ImageFile.py:79(_tilesort)\n",
      "      600    0.002    0.000    0.004    0.000 PngImagePlugin.py:1025(putchunk)\n",
      "      200    0.000    0.000    0.000    0.000 PngImagePlugin.py:1039(__init__)\n",
      "      200    0.000    0.000    0.002    0.000 PngImagePlugin.py:1043(write)\n",
      "      200    0.003    0.000    0.051    0.000 PngImagePlugin.py:1191(_save)\n",
      "     1200    0.001    0.000    0.001    0.000 PngImagePlugin.py:137(_crc32)\n",
      "      400    0.000    0.000    0.000    0.000 _VF.py:25(__getattr__)\n",
      "      200    0.000    0.000    0.000    0.000 __init__.py:271(is_tensor)\n",
      "     2800    0.001    0.000    0.001    0.000 __init__.py:291(is_storage)\n",
      "     1600    0.001    0.000    0.001    0.000 _binary.py:101(o32be)\n",
      "      400    0.000    0.000    0.000    0.000 _jit_internal.py:957(is_scripting)\n",
      "      400    0.000    0.000    0.001    0.000 _namedtensor_internals.py:10(check_serializing_named_tensor)\n",
      "      400    0.001    0.000    0.011    0.000 _tensor.py:131(__reduce_ex__)\n",
      "      400    0.007    0.000    0.010    0.000 _tensor.py:152(_reduce_ex_internal)\n",
      "        2    0.000    0.000    0.001    0.000 _tensor.py:632(__iter__)\n",
      "       20    0.000    0.000    0.000    0.000 _tensor.py:674(__array__)\n",
      "      200    0.001    0.000    0.004    0.000 _utils.py:130(_rebuild_tensor)\n",
      "      200    0.000    0.000    0.004    0.000 _utils.py:136(_rebuild_tensor_v2)\n",
      "      200    0.000    0.000    0.000    0.000 _utils.py:158(_validate_loaded_sparse_tensors)\n",
      "     1200    0.000    0.000    0.001    0.000 abc.py:117(__instancecheck__)\n",
      "       24    0.000    0.000    0.000    0.000 fromnumeric.py:2928(_prod_dispatcher)\n",
      "       24    0.000    0.000    0.001    0.000 fromnumeric.py:2933(prod)\n",
      "       24    0.000    0.000    0.001    0.000 fromnumeric.py:69(_wrapreduction)\n",
      "       24    0.000    0.000    0.000    0.000 fromnumeric.py:70(<dictcomp>)\n",
      "      400    0.002    0.000    0.010    0.000 functional.py:4111(_pad)\n",
      "      400    0.001    0.000    0.018    0.000 functional.py:430(pad)\n",
      "      400    0.000    0.000    0.000    0.000 functional_tensor.py:10(_is_tensor_a_torch_image)\n",
      "      400    0.000    0.000    0.000    0.000 functional_tensor.py:14(_assert_image_tensor)\n",
      "      400    0.003    0.000    0.017    0.000 functional_tensor.py:416(pad)\n",
      "      216    0.000    0.000    0.001    0.000 genericpath.py:121(_splitext)\n",
      "        5    0.000    0.000    2.928    0.586 genericpath.py:16(exists)\n",
      "       16    0.000    0.000    0.025    0.002 genericpath.py:27(isfile)\n",
      "      400    0.001    0.000    0.001    0.000 grad_mode.py:119(__init__)\n",
      "      400    0.001    0.000    0.001    0.000 grad_mode.py:124(__enter__)\n",
      "      400    0.001    0.000    0.001    0.000 grad_mode.py:128(__exit__)\n",
      "      800    0.001    0.000    0.001    0.000 grad_mode.py:213(__init__)\n",
      "  400/200    0.002    0.000    0.117    0.001 grad_mode.py:25(decorate_context)\n",
      "       12    0.000    0.000    0.000    0.000 hex_codec.py:13(hex_encode)\n",
      "      400    0.000    0.000    0.000    0.000 hooks.py:54(warn_if_has_hooks)\n",
      "       11    0.000    0.000    0.000    0.000 iostream.py:206(schedule)\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:418(_is_master_process)\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:437(_schedule_flush)\n",
      "        8    0.000    0.000    0.000    0.000 iostream.py:500(write)\n",
      "       11    0.000    0.000    0.000    0.000 iostream.py:96(_event_pipe)\n",
      "        2    0.000    0.000    0.086    0.043 mnist.py:110(_load_data)\n",
      "       20    0.000    0.000    0.000    0.000 mnist.py:144(raw_folder)\n",
      "        2    0.000    0.000    0.000    0.000 mnist.py:148(processed_folder)\n",
      "        4    0.000    0.000    0.026    0.007 mnist.py:156(_check_exists)\n",
      "       20    0.000    0.000    0.026    0.001 mnist.py:157(<genexpr>)\n",
      "        2    0.000    0.000    0.020    0.010 mnist.py:162(download)\n",
      "       12    0.000    0.000    0.000    0.000 mnist.py:467(get_int)\n",
      "        4    0.000    0.000    0.084    0.021 mnist.py:481(read_sn3_pascalvincent_tensor)\n",
      "        4    0.000    0.000    0.000    0.000 mnist.py:495(<listcomp>)\n",
      "        2    0.000    0.000    0.014    0.007 mnist.py:501(read_label_file)\n",
      "        2    0.002    0.001    0.072    0.036 mnist.py:508(read_image_file)\n",
      "        2    0.000    0.000    3.039    1.519 mnist.py:70(__init__)\n",
      "        2    0.000    0.000    2.926    1.463 mnist.py:95(_check_legacy_exist)\n",
      "      400    0.001    0.000    0.019    0.000 module.py:1096(_call_impl)\n",
      "     5600    0.009    0.000    0.013    0.000 module.py:1180(__setattr__)\n",
      "      400    0.002    0.000    0.013    0.000 module.py:250(__init__)\n",
      "       20    0.000    0.000    0.000    0.000 multiarray.py:341(where)\n",
      "      400    0.001    0.000    0.007    0.000 multimnist.py:108(__pad_rand__)\n",
      "        2    0.019    0.009    0.822    0.411 multimnist.py:117(__multimatch__)\n",
      "        2    0.000    0.000    0.004    0.002 multimnist.py:27(mkdir_directories)\n",
      "        1    0.002    0.002    3.962    3.962 multimnist.py:33(__init__)\n",
      "        1    0.000    0.000    0.002    0.002 multimnist.py:86(__check_exists__)\n",
      "        1    0.000    0.000    0.002    0.002 multimnist.py:93(<listcomp>)\n",
      "        1    0.000    0.000    3.861    3.861 multimnist.py:96(generator)\n",
      "      212    0.000    0.000    0.000    0.000 pathlib.py:102(join_parsed_parts)\n",
      "        5    0.000    0.000    0.000    0.000 pathlib.py:1079(__new__)\n",
      "      217    0.000    0.000    0.000    0.000 pathlib.py:1089(_init)\n",
      "        4    0.000    0.000    0.000    0.000 pathlib.py:1227(stat)\n",
      "        4    0.000    0.000    0.003    0.001 pathlib.py:1318(mkdir)\n",
      "        4    0.000    0.000    0.000    0.000 pathlib.py:1434(is_dir)\n",
      "      239    0.000    0.000    0.000    0.000 pathlib.py:303(splitroot)\n",
      "      217    0.001    0.000    0.002    0.000 pathlib.py:64(parse_parts)\n",
      "      217    0.001    0.000    0.003    0.000 pathlib.py:682(_parse_args)\n",
      "        5    0.000    0.000    0.000    0.000 pathlib.py:702(_from_parts)\n",
      "      212    0.000    0.000    0.001    0.000 pathlib.py:715(_from_parsed_parts)\n",
      "      213    0.000    0.000    0.001    0.000 pathlib.py:725(_format_parsed_parts)\n",
      "      212    0.001    0.000    0.004    0.000 pathlib.py:736(_make_child)\n",
      "      240    0.001    0.000    0.001    0.000 pathlib.py:742(__str__)\n",
      "       40    0.000    0.000    0.000    0.000 pathlib.py:752(__fspath__)\n",
      "      212    0.000    0.000    0.004    0.000 pathlib.py:974(__truediv__)\n",
      "      216    0.000    0.000    0.001    0.000 posixpath.py:117(splitext)\n",
      "       16    0.000    0.000    0.000    0.000 posixpath.py:140(basename)\n",
      "       58    0.000    0.000    0.000    0.000 posixpath.py:41(_get_sep)\n",
      "       42    0.000    0.000    0.000    0.000 posixpath.py:71(join)\n",
      "      400    0.000    0.000    0.000    0.000 serialization.py:116(_cpu_tag)\n",
      "      200    0.000    0.000    0.000    0.000 serialization.py:126(_cpu_deserialize)\n",
      "      400    0.001    0.000    0.001    0.000 serialization.py:164(location_tag)\n",
      "      200    0.000    0.000    0.000    0.000 serialization.py:173(default_restore_location)\n",
      "      400    0.000    0.000    0.000    0.000 serialization.py:183(normalize_storage_type)\n",
      "      600    0.001    0.000    0.001    0.000 serialization.py:193(_is_path)\n",
      "      600    0.000    0.000    0.000    0.000 serialization.py:199(__init__)\n",
      "      600    0.000    0.000    0.000    0.000 serialization.py:202(__enter__)\n",
      "      200    0.000    0.000    0.000    0.000 serialization.py:205(__exit__)\n",
      "      200    0.000    0.000    0.001    0.000 serialization.py:218(__init__)\n",
      "      400    0.000    0.000    0.000    0.000 serialization.py:224(__exit__)\n",
      "      600    0.001    0.000    0.003    0.000 serialization.py:228(_open_file_like)\n",
      "      600    0.002    0.000    0.002    0.000 serialization.py:272(_is_compressed_file)\n",
      "      600    0.001    0.000    0.003    0.000 serialization.py:280(_should_read_directly)\n",
      "      400    0.000    0.000    0.000    0.000 serialization.py:296(_check_seekable)\n",
      "      600    0.000    0.000    0.000    0.000 serialization.py:314(_check_dill_version)\n",
      "      400    0.003    0.000    0.081    0.000 serialization.py:333(save)\n",
      "      400    0.006    0.000    0.076    0.000 serialization.py:384(_legacy_save)\n",
      "     2800    0.005    0.000    0.008    0.000 serialization.py:389(persistent_id)\n",
      "      200    0.001    0.000    0.001    0.000 serialization.py:45(_is_zipfile)\n",
      "      200    0.001    0.000    0.043    0.000 serialization.py:502(load)\n",
      "      200    0.002    0.000    0.039    0.000 serialization.py:628(_legacy_load)\n",
      "      200    0.002    0.000    0.002    0.000 serialization.py:727(persistent_load)\n",
      "      400    0.000    0.000    0.000    0.000 serialization.py:803(_maybe_decode_ascii)\n",
      "      200    0.000    0.000    0.000    0.000 serialization.py:815(_get_restore_location)\n",
      "       11    0.000    0.000    0.000    0.000 socket.py:480(send)\n",
      "      200    0.000    0.000    0.000    0.000 storage.py:13(__init__)\n",
      "      200    0.000    0.000    0.044    0.000 storage.py:160(_load_from_bytes)\n",
      "      400    0.001    0.000    0.082    0.000 storage.py:52(__reduce__)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:1059(_wait_for_tstate_lock)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:1113(is_alive)\n",
      "       11    0.000    0.000    0.000    0.000 threading.py:529(is_set)\n",
      "      400    0.002    0.000    0.020    0.000 transforms.py:390(__init__)\n",
      "      400    0.000    0.000    0.018    0.000 transforms.py:409(forward)\n",
      "      400    0.000    0.000    0.000    0.000 typing.py:1353(cast)\n",
      "      400    0.001    0.000    0.001    0.000 typing.py:269(inner)\n",
      "      200    0.002    0.000    0.113    0.001 utils.py:113(save_image)\n",
      "      200    0.001    0.000    0.005    0.000 utils.py:12(make_grid)\n",
      "       16    0.000    0.000    0.025    0.002 utils.py:65(check_integrity)\n",
      "        2    0.000    0.000    0.000    0.000 vision.py:27(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 vision.py:87(__init__)\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method PIL._imaging.fill}\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.raw_decoder}\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method PIL._imaging.zip_encoder}\n",
      "      217    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x5600a7bb6740}\n",
      "     1200    0.001    0.000    0.001    0.000 {built-in method _abc._abc_instancecheck}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method _codecs.encode}\n",
      "   1604/4    0.514    0.000    0.603    0.151 {built-in method _pickle.dump}\n",
      "    802/2    0.045    0.000    0.090    0.045 {built-in method _pickle.load}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISDIR}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _stat.S_ISREG}\n",
      "     1600    0.001    0.000    0.001    0.000 {built-in method _struct.pack}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method binascii.b2a_hex}\n",
      "        4    0.000    0.000    0.026    0.007 {built-in method builtins.all}\n",
      "        1    0.000    0.000    3.967    3.967 {built-in method builtins.exec}\n",
      "     1224    0.001    0.000    0.001    0.000 {built-in method builtins.getattr}\n",
      "     1000    0.000    0.000    0.000    0.000 {built-in method builtins.hasattr}\n",
      "    22714    0.005    0.000    0.006    0.000 {built-in method builtins.isinstance}\n",
      "      400    0.000    0.000    0.000    0.000 {built-in method builtins.issubclass}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "     5230    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "      200    0.000    0.000    0.000    0.000 {built-in method builtins.max}\n",
      "        4    0.000    0.000    0.001    0.000 {built-in method builtins.print}\n",
      "      400    0.001    0.000    0.001    0.000 {built-in method builtins.sorted}\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method cat}\n",
      "      200    0.001    0.000    0.001    0.000 {built-in method clamp}\n",
      "      400    0.007    0.000    0.007    0.000 {built-in method constant_pad_nd}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method from_numpy}\n",
      "      210    0.047    0.000    0.047    0.000 {built-in method io.open}\n",
      "       44    0.002    0.000    0.002    0.000 {built-in method numpy.core._multiarray_umath.implement_array_function}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method numpy.frombuffer}\n",
      "      487    0.000    0.000    0.000    0.000 {built-in method posix.fspath}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method posix.getpid}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method posix.listdir}\n",
      "        4    0.003    0.001    0.003    0.001 {built-in method posix.mkdir}\n",
      "       25    2.953    0.118    2.953    0.118 {built-in method posix.stat}\n",
      "      238    0.000    0.000    0.000    0.000 {built-in method sys.intern}\n",
      "      200    0.002    0.000    0.002    0.000 {built-in method tensor}\n",
      "      402    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      420    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "      402    0.001    0.000    0.001    0.000 {built-in method torch._C._log_api_usage_once}\n",
      "      800    0.000    0.000    0.000    0.000 {built-in method torch._C._set_grad_enabled}\n",
      "     1200    0.000    0.000    0.000    0.000 {built-in method torch._C.is_grad_enabled}\n",
      "     1200    0.001    0.000    0.001    0.000 {built-in method zlib.crc32}\n",
      "        4    0.006    0.001    0.006    0.001 {method '__exit__' of '_io._IOBase' objects}\n",
      "      200    0.030    0.000    0.030    0.000 {method '_set_from_file' of 'torch._C.LongStorageBase' objects}\n",
      "      400    0.049    0.000    0.049    0.000 {method '_write_file' of 'torch._C.LongStorageBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'acquire' of '_thread.lock' objects}\n",
      "      200    0.002    0.000    0.002    0.000 {method 'add_' of 'torch._C._TensorBase' objects}\n",
      "       11    0.000    0.000    0.000    0.000 {method 'append' of 'collections.deque' objects}\n",
      "     1656    0.000    0.000    0.000    0.000 {method 'append' of 'list' objects}\n",
      "        4    0.027    0.007    0.027    0.007 {method 'astype' of 'numpy.ndarray' objects}\n",
      "       20    0.012    0.001    0.012    0.001 {method 'choice' of 'numpy.random.mtrand.RandomState' objects}\n",
      "      200    0.001    0.000    0.001    0.000 {method 'clamp_' of 'torch._C._TensorBase' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'cleanup' of 'ImagingEncoder' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'clear' of 'list' objects}\n",
      "      200    0.003    0.000    0.003    0.000 {method 'close' of '_io.BufferedRandom' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedReader' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'close' of '_io.BufferedWriter' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'copy' of 'dict' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'decode' of 'ImagingDecoder' objects}\n",
      "     1002    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "      400    0.004    0.000    0.012    0.000 {method 'dump' of '_pickle.Pickler' objects}\n",
      "      200    0.030    0.000    0.030    0.000 {method 'encode' of 'ImagingEncoder' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'endswith' of 'str' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'fileno' of '_io._IOBase' objects}\n",
      "      200    0.002    0.000    0.002    0.000 {method 'float' of 'torch._C._TensorBase' objects}\n",
      "      200    0.008    0.000    0.008    0.000 {method 'flush' of '_io.BufferedRandom' objects}\n",
      "      800    0.000    0.000    0.000    0.000 {method 'flush' of '_io.BytesIO' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'format' of 'str' objects}\n",
      "    19600    0.002    0.000    0.002    0.000 {method 'get' of 'dict' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'getvalue' of '_io.BytesIO' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'has_names' of 'torch._C._TensorBase' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'join' of 'bytes' objects}\n",
      "      213    0.000    0.000    0.000    0.000 {method 'join' of 'str' objects}\n",
      "      800    0.000    0.000    0.000    0.000 {method 'keys' of 'dict' objects}\n",
      "      200    0.001    0.000    0.003    0.000 {method 'load' of '_pickle.Unpickler' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'long' of 'torch._C._TensorBase' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'lower' of 'str' objects}\n",
      "        5    0.000    0.000    0.000    0.000 {method 'lstrip' of 'str' objects}\n",
      "      200    0.003    0.000    0.003    0.000 {method 'mul' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'ndimension' of 'torch._C._TensorBase' objects}\n",
      "      220    0.001    0.000    0.001    0.000 {method 'numpy' of 'torch._C._TensorBase' objects}\n",
      "      200    0.001    0.000    0.001    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'pixel_access' of 'ImagingCore' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'pop' of 'dict' objects}\n",
      "      800    0.006    0.000    0.006    0.000 {method 'randint' of 'numpy.random.mtrand.RandomState' objects}\n",
      "        4    0.040    0.010    0.040    0.010 {method 'read' of '_io.BufferedReader' objects}\n",
      "      800    0.000    0.000    0.000    0.000 {method 'read' of '_io.BytesIO' objects}\n",
      "       24    0.000    0.000    0.000    0.000 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      217    0.000    0.000    0.000    0.000 {method 'reverse' of 'list' objects}\n",
      "      448    0.000    0.000    0.000    0.000 {method 'rfind' of 'str' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'seek' of '_io.BytesIO' objects}\n",
      "      200    0.001    0.000    0.001    0.000 {method 'set_' of 'torch._C._TensorBase' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingDecoder' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'setimage' of 'ImagingEncoder' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C.LongStorageBase' objects}\n",
      "     1002    0.001    0.000    0.001    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "      200    0.000    0.000    0.000    0.000 {method 'sort' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'split' of 'str' objects}\n",
      "      600    0.002    0.000    0.002    0.000 {method 'squeeze' of 'torch._C._TensorBase' objects}\n",
      "       64    0.000    0.000    0.000    0.000 {method 'startswith' of 'str' objects}\n",
      "      400    0.001    0.000    0.001    0.000 {method 'storage' of 'torch._C._TensorBase' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'storage_offset' of 'torch._C._TensorBase' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'stride' of 'torch._C._TensorBase' objects}\n",
      "      600    0.000    0.000    0.000    0.000 {method 'tell' of '_io.BytesIO' objects}\n",
      "      200    0.002    0.000    0.002    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "      200    0.006    0.000    0.006    0.000 {method 'tobytes' of 'numpy.ndarray' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'unbind' of 'torch._C._TensorBase' objects}\n",
      "      800    0.003    0.000    0.003    0.000 {method 'unsqueeze' of 'torch._C._TensorBase' objects}\n",
      "      400    0.000    0.000    0.000    0.000 {method 'upper' of 'str' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'view' of 'torch._C._TensorBase' objects}\n",
      "     2000    0.000    0.000    0.000    0.000 {method 'write' of '_io.BufferedRandom' objects}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "root='/mnt/data/datasets/multimnist_test'\n",
    "cProfile.run('MultiMNist(root=root,train=True, generate=True, g_samples=[10,10])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00145\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "a = np.arange(0,1000,1)\n",
    "\n",
    "for i in a:\n",
    "    np.square(a[i])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"{:.5f}\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generate multimnist...\n",
      "torch.Size([600, 28, 28])\n",
      "torch.Size([600, 28, 28])\n",
      "generation done\n",
      "133.44664\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "MultiMNist(root='/mnt/data/datasets/multimnist_test',train=True, generate=True, g_samples=[10,10])\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"{:.5f}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "samples 1200 gen 10 time 133.44664 s => 89.923 Img/ sec => 0.01112 s/Img -> Time Full Dataset 9 days\n",
    "    -> that wrong...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133.44664478302002\n",
      "0.011120553731918335\n",
      "89.92357971616009\n",
      "778438.7612342834\n",
      "9.00970788465606\n"
     ]
    }
   ],
   "source": [
    "a = end - start\n",
    "samplesize = 12000\n",
    "b = a / samplesize \n",
    "c = 1/ b\n",
    "d = (b * 70000000)\n",
    "e = d / (60*60*24)\n",
    "\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "188faa17072d374bec02d17fca5e544867bade69f71230dfd1a560a6ca303930"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('EffCN': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
