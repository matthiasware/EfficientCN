{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c42d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bd11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beeb573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from tqdm import tqdm\n",
    "#\n",
    "\n",
    "from misc.plot_utils import plot_mat, imshow\n",
    "from effcn.layers import FCCaps, FCCapsWOBias, Squash\n",
    "from misc.utils import count_parameters\n",
    "from effcn.functions import margin_loss\n",
    "from datasets import AffNIST\n",
    "#\n",
    "from perceiver_pytorch import Perceiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(ppt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9808953",
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54f86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.RandomAffine(degrees=(-8, 8),\n",
    "                   shear=(-15, 15),\n",
    "                   scale=(0.9, 1.1)\n",
    "                  ),\n",
    "    T.Normalize((0.0641,), (0.2257))\n",
    "])\n",
    "transform_valid = T.Normalize((0.0641,), (0.2257))\n",
    "\n",
    "p_data = '/home/matthias/projects/EfficientCN/data'\n",
    "\n",
    "ds_mnist_train = AffNIST(p_root=p_data, split=\"mnist_train\", download=True, transform=transform_train, target_transform=None)\n",
    "ds_mnist_valid = AffNIST(p_root=p_data, split=\"mnist_valid\", download=True, transform=transform_valid, target_transform=None)\n",
    "ds_affnist_valid = AffNIST(p_root=p_data, split=\"affnist_valid\", download=True, transform=transform_valid, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae53463",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 512\n",
    "dl_mnist_train = torch.utils.data.DataLoader(\n",
    "    ds_mnist_train, \n",
    "    batch_size=bs, \n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=4)\n",
    "dl_mnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_mnist_valid, \n",
    "    batch_size=bs, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=4)\n",
    "dl_affnist_valid= torch.utils.data.DataLoader(\n",
    "    ds_affnist_valid, \n",
    "    batch_size=bs, \n",
    "    shuffle=True, \n",
    "    pin_memory=True,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1129f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(dl_mnist_train))\n",
    "x_vis_train = x[:32]\n",
    "\n",
    "x, _ = next(iter(dl_mnist_valid))\n",
    "x_vis_mnist_valid = x[:32]\n",
    "\n",
    "x, _ = next(iter(dl_affnist_valid))\n",
    "x_vis_affnist_valid = x[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(torchvision.utils.make_grid(x_vis_train).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_mnist_valid).permute(1,2,0))\n",
    "plt.show()\n",
    "#\n",
    "plt.imshow(torchvision.utils.make_grid(x_vis_affnist_valid).permute(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b39dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Perceiver(\n",
    "    input_channels = 1,          # number of channels for each token of the input\n",
    "    input_axis = 2,              # number of axis for input data (2 for images, 3 for video)\n",
    "    num_freq_bands = 2,          # number of freq bands, with original value (2 * K + 1)\n",
    "    max_freq = 10.,              # maximum frequency, hyperparameter depending on how fine the data is\n",
    "    depth = 3,                   # depth of net. The shape of the final attention mechanism will be:\n",
    "                                 #   depth * (cross attention -> self_per_cross_attn * self attention)\n",
    "    num_latents = 32,            # number of latents, or induced set points, or centroids. different papers giving it different names\n",
    "    latent_dim = 64,             # latent dimension\n",
    "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
    "    latent_heads = 2,            # number of heads for latent self attention, 8\n",
    "    cross_dim_head = 16,          # number of dimensions per cross attention head\n",
    "    latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
    "    num_classes = 10,           # output number of classes\n",
    "    attn_dropout = 0.,\n",
    "    ff_dropout = 0.,\n",
    "    weight_tie_layers = False,   # whether to weight tie layers (optional, as indicated in the diagram)\n",
    "    fourier_encode_data = True,  # whether to auto-fourier encode the data, using the input_axis given. defaults to True, but can be turned off if you are fourier encoding the data yourself\n",
    "    self_per_cross_attn = 2      # number of self attention blocks per cross attention\n",
    ")\n",
    "model = model.to(device)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(torch.rand(1, 40, 40, 1).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay=2e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66572460",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27eb805",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_epochs = 51\n",
    "#\n",
    "for epoch_idx in range(num_epochs):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_mnist_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x,y_true in pbar:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        logits = model.forward(x.permute(0,2,3,1))\n",
    "        loss = criterion(logits, y_true)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        y_pred = torch.argmax(logits, dim=1)\n",
    "        acc = (y_true == y_pred).sum() / y_true.shape[0]\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    #\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    if epoch_idx % 5 != 0:\n",
    "        continue\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_mnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(x.permute(0,2,3,1))\n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   mnist acc_valid: {:.3f}\".format(total_correct / total))\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true in dl_affnist_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            logits = model.forward(x.permute(0,2,3,1))\n",
    "            y_pred = torch.argmax(logits, dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   affnist acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980eb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
