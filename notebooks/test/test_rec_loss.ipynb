{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9811bbff-b44b-48b4-81a3-6291f1ea66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82520918-aebd-4642-ab96-a9026e8f90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f4b662-4b8e-4fdc-8e66-8d1a8701979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "#local import\n",
    "from smallnorb.smallnorb import SmallNORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6745097f-1a8f-434e-8fef-abb0c17b03d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask operation described in 'Dynamic routinig between capsules'.\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    call(inputs, double_mask)\n",
    "        mask a capsule layer\n",
    "        set double_mask for multimnist dataset\n",
    "    \"\"\"\n",
    "    def call(self, inputs, double_mask=None, **kwargs):\n",
    "        if type(inputs) is list:\n",
    "            if double_mask:\n",
    "                inputs, mask1, mask2 = inputs\n",
    "            else:\n",
    "                inputs, mask = inputs\n",
    "        else:  \n",
    "            x = tf.sqrt(tf.reduce_sum(tf.square(inputs), -1))        # 2 norm ?\n",
    "            if double_mask:\n",
    "                mask1 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,0],num_classes=x.get_shape().as_list()[1])\n",
    "                mask2 = tf.keras.backend.one_hot(tf.argsort(x,direction='DESCENDING',axis=-1)[...,1],num_classes=x.get_shape().as_list()[1])\n",
    "            else:\n",
    "                mask = tf.keras.backend.one_hot(indices=tf.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        if double_mask:\n",
    "            masked1 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask1, -1))\n",
    "            masked2 = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask2, -1))\n",
    "            return masked1, masked2\n",
    "        else:\n",
    "            masked = tf.keras.backend.batch_flatten(inputs * tf.expand_dims(mask, -1))\n",
    "            return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  \n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # generation step\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8918c94-688f-4909-8b6b-2562a9d2c673",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_max_norm(u):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "        u (b, n d) ... capsules\n",
    "    OUT:\n",
    "        masked(u)  (b, n, d) where:\n",
    "        - normalise over dimension d of u\n",
    "        - keep largest vector in dimension n\n",
    "        - mask out everything else\n",
    "    \"\"\"\n",
    "    _, n_classes, _ = u.shape\n",
    "    print(n_classes)\n",
    "    u_norm = torch.norm(u, dim=2)\n",
    "    print(u_norm)\n",
    "    mask = F.one_hot(torch.argmax(u_norm, 1), num_classes=n_classes)\n",
    "    print(mask)\n",
    "    return torch.einsum('bnd,bn->bnd', u, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1da76aa-88ac-480e-9ddd-239eb0630b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "u = torch.rand((1,5,16))\n",
    "u.size()\n",
    "u_mask = masking_max_norm(u)\n",
    "u_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d340a5-80b3-4ca6-82c7-2ba5894c348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.one_hot(torch.tensor(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d790c-c2c7-4651-a993-bfc241264d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SmallNORB(root = 'data/SmallNORB',train=False,download=True,mode=\"stereo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13a016-50aa-4f61-9c25-c08d5d8f47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(A[0][0])\n",
    "b = A[3][2]\n",
    "print(b, F.one_hot(b,num_classes=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc152251-5751-468f-bc9e-fa8ba1e7f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masking_y_true(u, y_true):\n",
    "    \"\"\"\n",
    "    IN:\n",
    "        u (b, n d) ... capsules\n",
    "        y_true (b,)  ... classification value (skalar)\n",
    "    OUT:\n",
    "        masked(u)  (b, n, d) where:\n",
    "        - normalise over dimension d of u\n",
    "        - keep vector in dimension n with y_true\n",
    "        - mask out everything else\n",
    "    \"\"\"\n",
    "    _, n_classes, _ = u.shape\n",
    "    print(n_classes)\n",
    "    u_norm = torch.norm(u, dim=2)\n",
    "    print(u_norm)\n",
    "    mask = F.one_hot(y_true, num_classes=n_classes)\n",
    "    print(mask)\n",
    "    return torch.einsum('bnd,bn->bnd', u, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1e8b2b-1dbe-4cf7-a997-83cd9c8991c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6)\n",
    "batch_size = 3\n",
    "u = torch.rand((batch_size,5,16))\n",
    "y_true = torch.randint(high = 5, size=(batch_size,))\n",
    "print(y_true.size())\n",
    "print(y_true)\n",
    "print(u.size())\n",
    "u_mask = masking_y_true(u, y_true)\n",
    "u_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b32724d-2213-4d46-9a53-00b43f8214d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SmallNORB(root='data/SmallNORB',train=True, download=True,transform=T.ToTensor(), mode=\"left\")\n",
    "ds_valid = SmallNORB(root='data/SmallNORB',train=False, download=True,transform=T.ToTensor(),  mode=\"left\")\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                       batch_size=3, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                       batch_size=3, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bfa6e-221d-40e7-92af-5fe0b621f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cac548-83cb-439f-ad24-85543b1ef278",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98adfb79-fee3-4940-b0b5-6ad43c8dad96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y = next(iter(dl_train))\n",
    "torch.manual_seed(6)\n",
    "batch_size = 3\n",
    "u = torch.rand((batch_size,5,16))\n",
    "y_true = y\n",
    "print(y_true.size())\n",
    "print(y_true)\n",
    "print(u.size())\n",
    "u_mask = masking_y_true(u, y_true)\n",
    "u_mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8b87a-bb39-48ce-b0e8-cb22f96429ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
