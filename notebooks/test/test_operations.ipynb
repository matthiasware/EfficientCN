{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3ae572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bffd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4214634",
   "metadata": {},
   "source": [
    "# Self Attention Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2503cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_l = 3\n",
    "n_h = 2\n",
    "d_l = 4\n",
    "d_h = 5\n",
    "b = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d957f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_np = np.random.random((n_l, n_h, d_l, d_h))\n",
    "B_np = np.random.random((n_l, n_h))\n",
    "U_l_np = np.random.random((b, n_l, d_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(W_np)\n",
    "print(B_np)\n",
    "print(U_l_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb307a",
   "metadata": {},
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98532345",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = torch.from_numpy(W_np)\n",
    "B = torch.from_numpy(B_np)\n",
    "U_l = torch.from_numpy(U_l_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a6296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "einsum convenventions:\n",
    "  n_l = i | h\n",
    "  d_l = j\n",
    "  n_h = k\n",
    "  d_h = l\n",
    "\"\"\"\n",
    "U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, W)\n",
    "\n",
    "# A (n_l, n_l, n_h)\n",
    "A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "A = A / torch.sqrt(torch.Tensor([d_l]))\n",
    "A_sum = torch.einsum(\"...hij->...hj\",A)\n",
    "C = torch.softmax(A_sum,dim=-1)\n",
    "CB = C + B\n",
    "U_h = torch.einsum('...ikl,...ik->...kl', U_hat, CB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6fd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCCaps(nn.Module):\n",
    "    def __init__(self, n_l, n_h, d_l, d_h):\n",
    "        super().__init__()\n",
    "        self.n_l = n_l\n",
    "        self.d_l = d_l\n",
    "        self.n_h = n_h\n",
    "        self.d_h = d_h\n",
    "        #\n",
    "        self.W = torch.nn.Parameter(torch.rand(n_l, n_h, d_l, d_h))\n",
    "        self.B = torch.nn.Parameter(torch.rand(n_l, n_h))\n",
    "    def forward(self, U_l):\n",
    "        \"\"\"\n",
    "        einsum convenventions:\n",
    "          n_l = i | h\n",
    "          d_l = j\n",
    "          n_h = k\n",
    "          d_h = l\n",
    "        \n",
    "        Data tensors:\n",
    "            U_l (n_l, d_l)\n",
    "            U_h (n_h, d_h)\n",
    "            W   (n_l, n_h, d_l, d_h)\n",
    "            B   (n_l, n_h)\n",
    "            A   (n_l, n_l, n_h)\n",
    "            C   (n_l, n_h)\n",
    "        \"\"\"\n",
    "        U_hat = torch.einsum('...ij,ikjl->...ikl', U_l, W)\n",
    "        \n",
    "        # A (n_l, n_l, n_h)\n",
    "        A = torch.einsum(\"...ikl, ...hkl -> ...hik\", U_hat, U_hat)\n",
    "        \n",
    "        A = A / torch.sqrt(torch.Tensor([d_l]))\n",
    "        A_sum = torch.einsum(\"...hij->...hj\",A)\n",
    "        C = torch.softmax(A_sum,dim=-1)\n",
    "        CB = C + B\n",
    "        U_h = torch.einsum('...ikl,...ik->...kl', U_hat, CB)\n",
    "        return U_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCCaps(n_l, n_h, d_l, d_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942dd3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_h = model(U_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a379597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6023628f",
   "metadata": {},
   "outputs": [],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8fc42",
   "metadata": {},
   "source": [
    "#### Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " code from paper\n",
    " should give same results ;)\n",
    "\"\"\"\n",
    "W = tf.convert_to_tensor(W_np)\n",
    "B = tf.convert_to_tensor(B_np)\n",
    "U_l = tf.convert_to_tensor(U_l_np)\n",
    "#\n",
    "# (n_l, n_h, d_l, d_h) - > (n_h, n_l, d_l, d_h)\n",
    "W = tf.transpose(W, (1,0,2,3))\n",
    "\n",
    "# (n_l, n_h) -> (n_h, n_l)\n",
    "B = tf.transpose(B, (1, 0))\n",
    "B = tf.expand_dims(B, axis=-1)\n",
    "#\n",
    "u = tf.einsum('...ji,kjiz->...kjz',U_l,W)\n",
    "c = tf.einsum('...ij,...kj->...i', u, u)[...,None]\n",
    "c = c/tf.sqrt(tf.cast(d_l, tf.float64))\n",
    "c = tf.nn.softmax(c, axis=1)\n",
    "cb = c + B\n",
    "s = tf.reduce_sum(tf.multiply(u, cb),axis=-2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c939d644",
   "metadata": {},
   "source": [
    "# Squashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf5644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
