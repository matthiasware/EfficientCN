{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bcaee15c-383d-400e-a5eb-61c52046bf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "153d3ba9-11ea-4aae-b7c9-d505b1862b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "657b813b-5b01-4fa3-98f1-138099728413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as T\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# local imports\n",
    "from effcn.models_mnist import BaselineCNN\n",
    "from misc.utils import count_parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3a0d9-ac8a-4c63-9ab9-f9701b384ab3",
   "metadata": {},
   "source": [
    "#### Test capsulwise activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e7295c32-a216-4918-b4df-9bf16315afcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand([1,1,28,28])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fd4416f0-4ea2-43e9-a397-16643e0ad8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv =  nn.Conv2d(1, 32, kernel_size=(5, 5), padding=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c12dd761-d12d-4da7-b67e-66983858221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 24, 24])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = conv(a)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b63025a6-69ea-44bc-9df3-15672e9bf482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 5, 5])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "06d9cc56-bad1-4817-b14f-08712a40208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_func(x, eps=10e-21):\n",
    "    \"\"\"\n",
    "        IN:\n",
    "            x (b, n, d)\n",
    "        OUT:\n",
    "            squash(x) (b, n, d)\n",
    "    \"\"\"\n",
    "    x_norm = torch.norm(x, dim=2, keepdim=True)\n",
    "    return (1 - 1 / (torch.exp(x_norm) + eps)) * (x / (x_norm + eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "07f47ff5-c961-44de-aed9-d56229817c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4229, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = squash_func(x)\n",
    "s.shape\n",
    "s.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "253dc7dc-b6c0-460e-be26-c9149cadfb79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 576, 32])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = x.view(x.shape[0],x.shape[1],-1)\n",
    "v = v.permute(0,2,1)\n",
    "s = squash_func(v)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "aa02a03c-c6ad-4342-9d02-0f41479ef490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 576, 1])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_norm = torch.norm(v, dim=2, keepdim=True)\n",
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "c70ec734-0b10-40bf-8f52-386a18f0c0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 576, 32])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps=10e-21\n",
    "k = (1 - 1 / (torch.exp(x_norm) + eps)) * (v / (x_norm + eps))\n",
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "bc0d112e-2516-4f9c-a092-0e59dd67feb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.3995, grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "40d6187a-6dbb-43df-b216-c18ac3ff0f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 24, 24])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = k.permute(0,2,1)\n",
    "t = t.view(x.shape)\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079683b1-4355-45bd-a0d3-fdfcd259b295",
   "metadata": {},
   "source": [
    "#### Ref Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "65323011-69e9-4e1e-8b3c-fd15f77e2a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "50b1ecc0-397d-4fb7-bba0-86592c804f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineCNN(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "70f8d49d-724c-49f9-8d6b-e60e0eb6df61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28938"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "839a61fd-ab92-41b1-b936-18a08ee11a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash_conv_func(v, eps=10e-21):\n",
    "    \"\"\"\n",
    "        IN:\n",
    "            x (b, c, h, w)\n",
    "        OUT:\n",
    "            squash(x) (b, c, h, w)\n",
    "    \"\"\"\n",
    "    #shap to capsule squashing for tests\n",
    "    x = v.view(v.shape[0],v.shape[1],-1)\n",
    "    x = x.permute(0,2,1)\n",
    "    \n",
    "    x_norm = torch.norm(x, dim=2, keepdim=True)\n",
    "    k = (1 - 1 / (torch.exp(x_norm) + eps)) * (x / (x_norm + eps))\n",
    "    \n",
    "    #reshape to comv\n",
    "    t = k.permute(0,2,1)\n",
    "    t = t.view(v.shape)\n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6a45e8cd-351c-4837-803a-e777b40ab5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Squash(nn.Module):\n",
    "    def __init__(self, eps=1e-21):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, v):\n",
    "        \"\"\"\n",
    "            IN:\n",
    "                x (b, c, h, w)\n",
    "            OUT:\n",
    "                squash(x) (b, c, h, w)\n",
    "        \"\"\"\n",
    "        #shap to capsule squashing for tests\n",
    "        x = v.view(v.shape[0],v.shape[1],-1)\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        x_norm = torch.norm(x, dim=2, keepdim=True)\n",
    "        k = (1 - 1 / (torch.exp(x_norm) + eps)) * (x / (x_norm + eps))\n",
    "\n",
    "        #reshape to comv\n",
    "        t = k.permute(0,2,1)\n",
    "        t = t.view(v.shape)\n",
    "\n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "23ea6a8c-0729-4601-8c90-ccfaaa6c4f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 24, 24])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on normal conv\n",
    "a = torch.rand([1,1,28,28])\n",
    "conv =  nn.Conv2d(1, 32, kernel_size=(5, 5), padding=\"valid\")\n",
    "#conv =  nn.Conv2d(1, 32, kernel_size=(28, 28), groups=1, padding=\"valid\")\n",
    "x = conv(a)\n",
    "squa = Squash()\n",
    "s = squa(x)\n",
    "\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e7dfa852-d299-446f-943b-0bc69177c5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "06e4e2ba-c8fc-455a-9603-99f6be461ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 1, 1])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test on deepwise conv conv\n",
    "a = torch.rand([1,1,28,28])\n",
    "conv =  nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(5, 5), padding=\"valid\"),\n",
    "            nn.Conv2d(32, 32, kernel_size=(24, 24), groups=32, padding=\"valid\")\n",
    "        )\n",
    "x = conv(a)\n",
    "squa = Squash()\n",
    "s = squa(x)\n",
    "\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "11f3352a-a329-4288-878d-d4cebeb3d3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19296"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "e8c38dab-2a2f-4674-bd93-c75153b1eb81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295776"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "19296\n",
    "295776"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1ccc32-9164-4d5c-9b5c-01f2e790322a",
   "metadata": {},
   "source": [
    "#### Test on Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "8afd4662-6e80-4e4b-bfa1-afaaa751685d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquashCNN(nn.Module):\n",
    "    \"\"\"\n",
    "        Baseline CNN Model for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SquashCNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=16,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),\n",
    "            Squash(),\n",
    "            #nn.MaxPool2d(kernel_size=2),\n",
    "            #nn.AvgPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),\n",
    "            Squash(),\n",
    "            #nn.MaxPool2d(2),\n",
    "            #nn.AvgPool2d(kernel_size=2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        #self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        self.out = nn.Linear(32 * 28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "6d06161e-a050-475c-be20-fd9a78e210b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264138"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SquashCNN()\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "54cb8a0c-1e62-4af9-b8a8-6cb224c86562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1f44c402-f032-46cb-bbd4-76f1acd700a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = datasets.MNIST(root='../../data', train=False, download=True, transform=T.ToTensor())\n",
    "ds_valid = datasets.MNIST(root=\"../../data\", train=False, download=True, transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a009b0a1-a2aa-4774-ba84-b6ab0e2b3dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                          batch_size=256, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "af6d525a-5f22-4864-a201-8d38034db9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 162.42 MiB already allocated; 0 bytes free; 188.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1868/3035393746.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSquashCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\EffCN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    897\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 899\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EffCN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EffCN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\EffCN\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 897\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 162.42 MiB already allocated; 0 bytes free; 188.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "model = SquashCNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "87d156af-6fe3-49ff-8ec5-5e515d9c14c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "568657df-a44f-433f-8d1c-ee9c15207f9c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 162.37 MiB already allocated; 0 bytes free; 188.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1868/2492608466.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 2.00 GiB total capacity; 162.37 MiB already allocated; 0 bytes free; 188.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for idx, (x, y_true) in enumerate(dl_train):\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y_true)         \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if idx % 1000 == 0:\n",
    "            print(\"Epoch[{}/{}] - step {} loss: {:.4f}\".format(epoch, num_epochs, idx, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a459a-ba88-4536-a300-3549f9b3a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y_true in dl_valid:\n",
    "        x = x.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        y_pred = model(x)\n",
    "        y_pred = torch.max(y_pred, 1)[1]\n",
    "        correct += (y_pred == y_true).sum().item()\n",
    "        total += y_true.shape[0]\n",
    "    acc = correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6469e-c7ef-4665-b97c-23d20f611753",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(total - correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1c6b7a-7ec0-41aa-af53-960381f65efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch[19/20] - step 0 loss: 0.0036\n",
    "\n",
    "1.0\n",
    "0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
