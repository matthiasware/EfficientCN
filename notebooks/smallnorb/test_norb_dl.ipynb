{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc53e2a2-fd0a-4bd1-b68e-f371886dcd59",
   "metadata": {},
   "source": [
    "#### Test norb dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5d0c67-4f43-4bd7-b270-2750b0839372",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3152fb51-f75f-404c-8f23-a5261e5e0ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04fa0f0c-69a5-40e7-91cc-ddfedcab1d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#local import\n",
    "from smallnorb.smallnorb import SmallNORB\n",
    "from smallnorb.jitter import ColorJitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9582cafb-3d5a-4731-86bb-5a92d81aef42",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22730630-c3ae-4bcf-8160-f042dde18815",
   "metadata": {},
   "outputs": [],
   "source": [
    "SmallNORB(root = 'data/SmallNORB',train=False,download=True,transform=transforms.ToTensor(),mode=\"stereo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c27c4002-594e-498a-a7fb-3bac59fa55aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = SmallNORB(root = 'data/SmallNORB', mode=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d6abb-1740-49f3-b0e7-33b47ea88811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c923d108-b838-4510-b5d3-3901accad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = A[0][0]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1e5def-0ca6-4795-b7e5-c62182720ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(A[0][0])\n",
    "print(a.shape)\n",
    "imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d0fd1-9663-4d53-93a5-f6b3e93b363f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(A[0][1])\n",
    "print(a.shape)\n",
    "imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21d5a0b-0ab2-4726-85a2-e6d4b1d7085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = SmallNORB(root='data/SmallNORB',train=False, transform=transforms.PILToTensor(), mode=\"stereo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf9f60b-aef8-4cf2-baf1-76a07105ca15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a5eb3f-1d4e-4632-8734-5cea9978a14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B[0][0]\n",
    "print(b.size())\n",
    "c = B[0][1]\n",
    "print(c.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4d5c6-4dea-4245-8baf-f2ece46cfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = B[0][0][0][:][:]\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91058645-6142-415a-9947-cca1f823efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B[0][2]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c18dd-6157-4156-b07f-3b81dbce84a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B[0][2]\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c7cbd-a09b-4e2d-b03a-3e52547cdca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = B[0][0][0][:][:]\n",
    "img = Image.fromarray(x.numpy(), mode='L')\n",
    "imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45cba4-f8b2-4301-af97-cb91465d4283",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = B[0][1][0][:][:]\n",
    "img = Image.fromarray(y.numpy(), mode='L')\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebe1c1a-45a6-403b-97e7-c025b9ba97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x-y\n",
    "img = Image.fromarray(z.numpy(), mode='L')\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657a8274-d2dd-47b1-946b-3bbffde45edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C = SmallNORB(root='data/SmallNORB',train=False, transform=transforms.Resize(64), mode=\"nopil\")\n",
    "C = SmallNORB(root='data/SmallNORB',train=False,transform=transforms.Resize(64),  mode=\"nopil\")\n",
    "\n",
    "#\n",
    "#2 channel img tensor\n",
    "C[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637cf92-6291-4717-90e4-ffb23d60be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7318018-9f73-4f99-93d1-b84baf0be6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 channel img tensor\n",
    "C[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb4876-85d7-48b4-905c-bbf2c9597835",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class\n",
    "C[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126b925-67cb-409a-8d9d-74173356cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info\n",
    "C[0][2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46149163-dcaf-421f-ace8-d076dc3653fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558]),\n",
    "    T.Resize(64),\n",
    "    #T.RandomCrop(48),\n",
    "    T.CenterCrop(48),\n",
    "    ColorJitter(brightness= [0.,2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "    #T.ToTensor()\n",
    "])\n",
    "transform_valid = T.Compose([\n",
    "    #T.Resize(64),\n",
    "    #T.RandomCrop(48),\n",
    "    #T.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#C = SmallNORB(root='data/SmallNORB',train=False, transform=transforms.Resize(64), mode=\"nopil\")\n",
    "D = SmallNORB(root='data/SmallNORB',train=True,transform=transform_train,  mode=\"nopil\")\n",
    "\n",
    "#Ugly preprocessing after generation, because jitter can only handle 1 or 3 channel\n",
    "#Jitter = T.ColorJitter(brightness=[0., 2.], contrast=[0.5,1.5], saturation=0, hue=0)\n",
    "#D[:][0][:,:1] = Jitter(D[:][0][:,:1])\n",
    "#D[:][0][:,1:2] = Jitter(D[:][0][:,1:2])\n",
    "#\n",
    "#2 channel img tensor\n",
    "print(D[:][0][:,:1].size())\n",
    "print(D[:][0][:,1:2].size())\n",
    "print(D[0][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d5a57-4e9f-4141-b3bc-a4b034937889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02605b4-de35-443a-ab57-b217c1060c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = D[:][0]\n",
    "h = D[:][0]\n",
    "print(d.size())\n",
    "print(d.max())\n",
    "print(d.mean())\n",
    "print(d.min())\n",
    "e = d[:,0]\n",
    "print(e.size())\n",
    "f = d[:,1]\n",
    "print(f.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e98d1d-d847-4341-a063-38a672a002d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#e = e.type(torch.float)\n",
    "print(e.size())\n",
    "print(\"c1 mea: \", e.mean())\n",
    "print(\"c1 std: \", e.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f79ca-4151-474b-b48e-0951e8c843f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = f.float()\n",
    "print(f.size())\n",
    "print(\"c2 mea: \", f.mean())\n",
    "print(\"c2 std: \", f.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac7e9fa-b880-40f8-8a4d-4804c953dee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = h[6,1]\n",
    "print(t.size())\n",
    "print(t.max())\n",
    "print(t.mean())\n",
    "print(t.min())\n",
    "img = transforms.ToPILImage()(t)\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d57df7-120a-4077-a9fe-1aacc0055d30",
   "metadata": {},
   "source": [
    "train\n",
    "c1 mea:  tensor(191.7811)\n",
    "c1 std:  tensor(45.2232)\n",
    "\n",
    "c2 mea:  tensor(193.0594)\n",
    "c2 std:  tensor(44.2558)\n",
    "\n",
    "T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558])\n",
    "\n",
    "\n",
    "valid\n",
    "\n",
    "c1 mea:  tensor(191.0684)\n",
    "c1 std:  tensor(45.4354)\n",
    "\n",
    "c2 mea:  tensor(192.0952)\n",
    "c2 std:  tensor(44.3388)\n",
    "\n",
    "T.Normalize(mean=[191.0684,192.0952],std=[45.4354, 44.3388])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4b889a30-70b7-41c4-9c2a-bce0055fc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    #T.Normalize(mean=[167.8820,166.8084],std=[14.5266, 13.8093]),\n",
    "    #T.Normalize(mean=[191.0684,192.0952],std=[45.4354, 44.3388]),\n",
    "    #T.Resize(64),\n",
    "    #T.RandomCrop(48),\n",
    "    #T.transforms.ColorJitter(brightness=[0., 2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "\n",
    "])\n",
    "transform_valid = T.Compose([\n",
    "    T.Resize(64),\n",
    "    T.RandomCrop(48),\n",
    "])\n",
    "\n",
    "\n",
    "#C = SmallNORB(root='data/SmallNORB',train=False, transform=transforms.Resize(64), mode=\"nopil\")\n",
    "E = SmallNORB(root='data/SmallNORB',train=True,transform=transform_train,  mode=\"nopil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac56282-d979-4936-9069-81ceabe343ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = E[0][0]\n",
    "img = transforms.ToPILImage()(h[0])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0e362-7b94-400b-bb75-0e6e65d1bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#2 channel img tensor\n",
    "x = E[0][0]\n",
    "print(x.size())\n",
    "print(x.max())\n",
    "print(x.min())\n",
    "print(x)\n",
    "print(x[0].size())\n",
    "x = (x - x.mean()) / x.std()\n",
    "print(x.size())\n",
    "print(x.max())\n",
    "print(x.min())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e7f91-41c7-4a7d-9f87-ca208608502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transforms.ToPILImage()(x[0])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77fc6d-00f0-413a-b8d5-3fda527956fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = (x + x.min()) / (x.max() - x.min())\n",
    "img = transforms.ToPILImage()(k[1])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d427e5-acce-4e52-8913-3d3573873701",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = E[1][0]\n",
    "img = transforms.ToPILImage()(g[0])\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e584114b-22ab-45e8-ba46-b2a176c0118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ColorJitter(brightness= (0.,2.), contrast=[0.5,1.5], saturation=0, hue=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42a9e5a0-b576-421b-8fe7-c94ca78a37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7407aaf3-acd2-4cf9-8061-d3afc3ed924c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439f11c-0425-4014-ab50-2e30e4cb6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "a(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e7aab834-40bc-412c-8afb-690be72c7d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = SmallNORB(root='data/SmallNORB',train=True,transform=None,  mode=\"pseudo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb251c-8382-4d3d-8880-d9e557c729d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43f0b5f-0d3a-46e4-98ad-e8a09d687fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "H[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49905eba-514a-4aac-9653-45389e7bdf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = T.ToPILImage()(H[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0c77a-5844-44f5-be08-a7c223aa1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d125d-ca6a-493a-8d83-d4a625e1a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "H[0][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dc81cb1-27ec-4e2d-8282-315d9523f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = T.ToTensor()(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfbdcfa-2e21-4ea7-b49c-91e5df748274",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0879b584-5f0e-465a-af09-7fdf777228c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([       \n",
    "    T.ColorJitter(brightness= [0.,0.5], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "    T.Resize(64),\n",
    "    T.RandomCrop(48),\n",
    "    T.Normalize(mean=[191.7811/255,193.0594/255,0],std=[45.2232/255, 44.2558/255,1]),\n",
    "    #T.Normalize(mean=[127.5/255, 127.5/255, 127.5/255],std=[127.5/255, 127.5/255, 127.5/255]),\n",
    "\n",
    "])\n",
    "\n",
    "K = SmallNORB(root=\"data/SmallNORB\",transform=transform, mode=\"pseudo\")\n",
    "#B = SmallNORB(root='data/SmallNORB',train=False, transform=transforms.PILToTensor(), mode=\"stereo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc8550-8c63-45b6-8815-67f7319c45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "K[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5beb6c0-4f53-410b-9b3e-061ee8f959a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = torch.utils.data.DataLoader(K, \n",
    "                                       batch_size=16, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d835376-6b6e-49c7-acf9-d0bcd974dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "print(x[:64,:1,:,:].size())\n",
    "print(x[:64,1:2,:,:].size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6160fbe-d219-4abc-b4b7-85c24725b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "\n",
    "# stereo channel 1\n",
    "img = torchvision.utils.make_grid((x[:64,:1,:,:]-x.min())/(x.max()-x.min()), nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# stereo channel 2\n",
    "img = torchvision.utils.make_grid((x[:64,1:2,:,:]-x.min())/(x.max()-x.min()), nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99624bba-fb6e-4649-95b9-a2c91a3e3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0,:1,:,:].max()-x[0,:1,:,:].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfc16ec-a73d-4871-9ec3-e34e835f00a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scal = lambda x: (x-x.min())/(x.max()-x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fbeec-bacf-4b99-b4e6-46f1ef256bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(a)\n",
    "print(scal(a))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
