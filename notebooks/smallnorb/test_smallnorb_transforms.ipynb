{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8697c8f8-581f-4503-be73-c0f6c0364681",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7f9810-7457-490f-b50a-918c84975cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "bf17f5ab-0509-413a-b923-f1382c0c8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from smallnorb.smallnorb import SmallNORB\n",
    "from smallnorb.jitter import ColorJitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58ece45e-5081-4b70-a2e9-2c5fd7a6d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SmallNORB(root='data/SmallNORB',train=True, download=True,  mode=\"nopil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c35787-a083-44ec-bb87-42965add42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0:1][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "df9f1862-7747-4808-aff5-403c6a5517d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = ds_train[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0b1ed509-bb21-44f3-9dc8-91e40335b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numpy = img_torch.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795fe39d-9dcf-4cb0-b394-57cdde7d6c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a404a7d-cbab-4b2c-918e-28c1a31e7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_torch.max())\n",
    "print(img_torch.min())\n",
    "print(img_torch.mean())\n",
    "print(img_numpy.max())\n",
    "print(img_numpy.min())\n",
    "print(img_numpy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecaf3f-e3d7-4a38-9e8f-e0dbbc7b18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_torch[...,0,:,:].mean())\n",
    "print(img_torch[...,0,:,:].std())\n",
    "print(img_torch[...,1,:,:].mean())\n",
    "print(img_torch[...,1,:,:].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f21b644c-7a47-4ebf-85ce-f5ac766fa25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558]),\n",
    "    #T.Normalize(mean=[127.5, 127.5],std=[127.5, 127.5]),\n",
    "    #T.Resize(64),\n",
    "    #T.RandomCrop(48),\n",
    "    #ColorJitter(brightness= [0.,2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "])\n",
    "transform_valid = T.Compose([\n",
    "    #T.Normalize(mean=[191.0684,192.0952],std=[45.4354, 44.3388]),\n",
    "    T.Normalize(mean=[127.5, 127.5],std=[127.5, 127.5]),\n",
    "    T.Resize(64),\n",
    "    T.CenterCrop(48),\n",
    "])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e006a21c-76a0-46b1-810f-80730fbff389",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform used in torch\n",
    "transform_train = T.Compose([T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558])])\n",
    "\n",
    "img_torch_trans = transform_train(img_torch)\n",
    "print(img_torch_trans.max())\n",
    "print(img_torch_trans.min())\n",
    "print(img_torch_trans.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27d7c44c-e364-41a8-a5d8-c3ab16e5a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig standadizer\n",
    "def standardize(x):\n",
    "    x[...,0] = (x[...,0] - x[...,0].mean()) / x[...,0].std()\n",
    "    x[...,1] = (x[...,1] - x[...,1].mean()) / x[...,1].std()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e5e218f6-904a-4ad5-8a2b-33a6d2b86098",
   "metadata": {},
   "outputs": [],
   "source": [
    "#orig standadizer shape of torch tensor\n",
    "def standardizer(x):\n",
    "    x[...,0,:,:] = (x[...,0,:,:] - x[...,0,:,:].mean()) / x[...,0,:,:].std()\n",
    "    x[...,1,:,:] = (x[...,1,:,:] - x[...,1,:,:].mean()) / x[...,1,:,:].std()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4c65c8d9-86dc-499a-b061-4c7bab607f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numpy_std_ten = standardizer(img_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7f4c65-b0af-42ff-8d0a-f77cf3e67f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_numpy_std_ten.max())\n",
    "print(img_numpy_std_ten.min())\n",
    "print(img_numpy_std_ten.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbdb132-d316-4a94-bb96-883fcb0f96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape array to tensprflow\n",
    "img_numpy_shape_tf = np.einsum('...ijk -> ...jki', img_numpy)\n",
    "img_numpy_shape_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25fd71f-b8fa-4371-aa8b-54e4cf0da640",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numpy_std_tf = standardize(img_numpy_shape_tf)\n",
    "print(img_numpy_std_tf.max())\n",
    "print(img_numpy_std_tf.min())\n",
    "print(img_numpy_std_tf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620eb3d9-def5-4ed1-b529-6a9f3badefb5",
   "metadata": {},
   "source": [
    "#### Rescaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0afc05f4-5946-40ad-99a7-bb4ae54cc59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(x):\n",
    "    with tf.device(\"/cpu:0\"):\n",
    "        x = tf.image.resize(x , [64, 64])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc665a2a-6c1a-4cea-902f-1e71caec2837",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling\n",
    "img_numpy_res_tf = rescale(img_numpy_std_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e874c-a4e7-49de-9a57-fd2e92c3c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_numpy_res_tf.shape)\n",
    "print(img_numpy_res_tf.numpy().max())\n",
    "print(img_numpy_res_tf.numpy().min())\n",
    "print(img_numpy_res_tf.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb8dee-a03b-44bb-860c-9a38f2a3c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = ds_train[:][0]\n",
    "#Transform used in torch\n",
    "transform_train = T.Compose([\n",
    "    T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558]),\n",
    "    T.Resize([64,64]),\n",
    "    #T.RandomCrop(48),\n",
    "    #ColorJitter(brightness= [0.,2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "])\n",
    "\n",
    "print(img_torch.size())\n",
    "print(img_torch.max())\n",
    "print(img_torch.min())\n",
    "print(img_torch.mean())\n",
    "\n",
    "img_torch_trans = transform_train(img_torch)\n",
    "print(img_torch_trans.size())\n",
    "print(img_torch_trans.max())\n",
    "print(img_torch_trans.min())\n",
    "print(img_torch_trans.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac710ed9-b184-4a23-b2de-5cbb4e2c61e4",
   "metadata": {},
   "source": [
    "### random patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "096b3281-bc69-44be-958e-ff1225637a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "def random_patches(x):\n",
    "    #return tf.image.random_crop(x, [48, 48, 2])\n",
    "    return tf.image.central_crop(x, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3a6cd-acb3-4068-8087-266a9c1e3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patches\n",
    "tf.random.set_seed(0)\n",
    "img_numpy_pat_tf = random_patches(img_numpy_res_tf[0])\n",
    "\n",
    "print(img_numpy_pat_tf.shape)\n",
    "print(img_numpy_pat_tf.numpy().max())\n",
    "print(img_numpy_pat_tf.numpy().min())\n",
    "print(img_numpy_pat_tf.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59516f69-e3cd-456f-a448-44d92f3c2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = ds_train[:][0]\n",
    "torch.manual_seed(0)\n",
    "#Transform used in torch\n",
    "transform_train = T.Compose([\n",
    "    T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558]),\n",
    "    T.Resize([64,64]),\n",
    "    #T.RandomCrop(48),\n",
    "    #ColorJitter(brightness= [0.,2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "])\n",
    "\n",
    "print(\"#\" * 50)\n",
    "print(img_torch.size())\n",
    "print(img_torch.max())\n",
    "print(img_torch.min())\n",
    "print(img_torch.mean())\n",
    "\n",
    "img_torch_trans = transform_train(img_torch)\n",
    "print(\"#\" * 50)\n",
    "print(img_torch_trans.size())\n",
    "print(img_torch_trans.max())\n",
    "print(img_torch_trans.min())\n",
    "print(img_torch_trans.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9556d7e-29ef-4461-bf4d-944b6e924fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "img_torch_pat = T.RandomCrop([48,48])(img_torch_trans[0])\n",
    "#img_torch_pat = T.CenterCrop([48,48])(img_torch_trans[0])\n",
    "print(\"#\" * 50)\n",
    "print(img_torch_pat.size())\n",
    "print(img_torch_pat.max())\n",
    "print(img_torch_pat.min())\n",
    "print(img_torch_pat.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2ba0b-a498-4840-9111-07744ad6b10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = img_numpy_pat_tf.numpy().max()  - img_torch_pat.numpy().max()\n",
    "b = img_numpy_pat_tf.numpy().min()  - img_torch_pat.numpy().min()\n",
    "c = img_numpy_pat_tf.numpy().mean() - img_torch_pat.numpy().mean()\n",
    "d = np.einsum(\"jik -> kji\", img_numpy_pat_tf.numpy()) - img_torch_pat.numpy()\n",
    "\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ebf01-4795-463f-85f0-6178aa4bdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "print(tf.random.uniform([1]))\n",
    "torch.manual_seed(0)\n",
    "print(torch.rand([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb68143d-a471-4b6a-95c4-7f2b2f94dd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img_torch_pat.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a4479-ed7d-4ba7-b351-484ce25fdd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(np.einsum(\"jik -> kji\", img_numpy_pat_tf.numpy())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c0078-d6f9-46a1-871d-3ed0f5126e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d[0].max()-d[0].min())\n",
    "imshow(d[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e787a8-135f-4bed-8071-d4c9c1a41901",
   "metadata": {},
   "source": [
    "###\n",
    "ohne random besteht kein unterschied zwischen crop funcs. \n",
    "mit random wird nicht der selbe seed genutzt.\n",
    "aber max und min nahezu gleich. sollte passen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e96299-51ec-4106-a72e-0df959612d25",
   "metadata": {},
   "source": [
    "### Random brigthness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab67821a-e24c-4960-a822-941af09f6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = ds_train[:][0]\n",
    "#Transform used in torch\n",
    "transform_train = T.Compose([\n",
    "    T.Normalize(mean=[191.7811,193.0594],std=[45.2232, 44.2558]),\n",
    "    T.Resize([64,64]),\n",
    "    #T.RandomCrop(48),\n",
    "    #ColorJitter(brightness= [0.,2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "])\n",
    "\n",
    "print(\"#\" * 50)\n",
    "print(img_torch.size())\n",
    "print(img_torch.max())\n",
    "print(img_torch.min())\n",
    "print(img_torch.mean())\n",
    "\n",
    "img_torch_trans = transform_train(img_torch)\n",
    "print(\"#\" * 50)\n",
    "print(img_torch_trans.size())\n",
    "print(img_torch_trans.max())\n",
    "print(img_torch_trans.min())\n",
    "print(img_torch_trans.mean())\n",
    "\n",
    "\n",
    "#img_torch_pat = T.RandomCrop([48,48])(img_torch_trans[0])\n",
    "img_torch_pat = T.CenterCrop([48,48])(img_torch_trans[0])\n",
    "print(\"#\" * 50)\n",
    "print(img_torch_pat.size())\n",
    "print(img_torch_pat.max())\n",
    "print(img_torch_pat.min())\n",
    "print(img_torch_pat.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "52dc5d9e-55bf-4447-8d25-56a032c072c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_brightness(x):\n",
    "    tf.random.set_seed(0)\n",
    "    #return tf.image.random_brightness(x, max_delta=2.0)\n",
    "    return tf.image.adjust_brightness(x, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387a33d-b941-443b-bb20-a9e9ad86fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_numpy_bri_tf = random_brightness(img_numpy_pat_tf)\n",
    "\n",
    "print(img_numpy_bri_tf.shape)\n",
    "print(img_numpy_bri_tf.numpy().max())\n",
    "print(img_numpy_bri_tf.numpy().min())\n",
    "print(img_numpy_bri_tf.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1750c7f-170a-4909-badd-208f36736d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.manual_seed(0)\n",
    "#img_torch_bri = T.ColorJitter(brightness= [-0.2,0.2])(img_torch_pat[0])#, contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "img_torch_bri = T.functional.adjust_brightness(img_torch_pat[0]-img_torch_pat[0].min(),brightness_factor=2)\n",
    "#-img_torch_pat[0].min()\n",
    "print(img_torch_bri.size())\n",
    "print(img_torch_bri.max())\n",
    "print(img_torch_bri.min())\n",
    "print(img_torch_bri.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2598c-0ebc-49f8-91f4-bd05ddadaa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img_torch_bri.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4283db7-9b46-4927-98d4-63441c8a9360",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "#img_torch_bri = T.ColorJitter(brightness= [-0.2,0.2])(img_torch_pat[0])#, contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "#img_torch_bri = T.functional.adjust_brightness(img_torch_pat[0]-img_torch_pat[0].min(),brightness_factor=2)\n",
    "#-img_torch_pat[0].min()\n",
    "p = torch.rand([1])\n",
    "pp = ((p-0.5)*2) *2\n",
    "print(p, pp)\n",
    "img_torch_bri = img_torch_pat[0] * pp\n",
    "print(img_torch_bri.size())\n",
    "print(img_torch_bri.max())\n",
    "print(img_torch_bri.min())\n",
    "print(img_torch_bri.mean())\n",
    "imshow(img_torch_bri.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db70937c-de96-434f-9793-451baffef923",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_torch = ds_train[:][0]\n",
    "#Transform used in torch\n",
    "img_torch = img_torch[0,:1]\n",
    "print(img_torch.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c266ea25-33a6-4b6e-bb4f-345225e94666",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    T.Lambda(lambda x: x/255),\n",
    "    \n",
    "    ColorJitter(brightness=1., contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "    T.Lambda(lambda x: x*255),\n",
    "    T.Normalize(mean=[191.7811],std=[45.2232]),\n",
    "    T.Resize([64]),\n",
    "    T.RandomCrop(48),\n",
    "])\n",
    "\n",
    "print(\"#\" * 50)\n",
    "print(img_torch.size())\n",
    "print(img_torch.max())\n",
    "print(img_torch.min())\n",
    "print(img_torch.mean())\n",
    "\n",
    "img_torch_trans = transform_train(img_torch)\n",
    "print(\"#\" * 50)\n",
    "print(img_torch_trans.size())\n",
    "print(img_torch_trans.max())\n",
    "print(img_torch_trans.min())\n",
    "print(img_torch_trans.mean())\n",
    "\n",
    "imshow(img_torch_trans[0,:,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "cf1e6669-cf79-4de9-9479-debed599f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10883f7-9667-4825-a611-9cfb65530092",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = T.Compose([\n",
    "    #T.Lambda(lambda x: x/255.),\n",
    "    #ColorJitter(brightness=1., contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "    #T.Lambda(lambda x: x*255.),\n",
    "    T.Normalize(mean=[191.7811/255,193.0594/255],std=[45.2232/255, 44.2558/255]),\n",
    "    T.Resize([64]),\n",
    "    T.RandomCrop(48),\n",
    "])\n",
    "\n",
    "\n",
    "train = SmallNORB(root='data/SmallNORB',train=True,transform=None, download=True,  mode=\"stereo\")\n",
    "\n",
    "print(train[0][:2])\n",
    "\n",
    "dl_train = torch.utils.data.DataLoader(train, \n",
    "                                       batch_size=16, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1726864c-4882-4358-9893-f0555d39f322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "x[:64,:1,:,:].size()\n",
    "x[:64,1:2,:,:].size()\n",
    "p = x[0,:1,:,:]\n",
    "print(p.size())\n",
    "print(p.max())\n",
    "print(p.min())\n",
    "print(p.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafbf5a-0588-4be6-b997-4be84cc12625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "# stereo channel 1\n",
    "img = torchvision.utils.make_grid(x[:64,:1,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# stereo channel 2\n",
    "img = torchvision.utils.make_grid(x[:64,1:2,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
