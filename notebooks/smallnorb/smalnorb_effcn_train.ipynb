{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d5b1871-0c26-450d-8f01-0649a1461351",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127643b3-40ea-42d7-bd9d-814c589ec45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ebb1f8-9d5d-4ede-935f-3f819679887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# third party libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# default libraries\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# local imports\n",
    "from effcn.models import SmallNorbEcnBackbone, SmallNorbEcnDecoder, SmallNorbEffCapsNet, SmallNorbEffCapsNetYMask\n",
    "from effcn.layers import PrimaryCaps, FCCaps\n",
    "from effcn.functions import margin_loss, max_norm_masking, masking_max_norm, masking_y_true\n",
    "from smallnorb.smallnorb import SmallNORB\n",
    "from effcn.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956dc049-d030-4712-917e-930bbd188218",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  using params from paper\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 150\n",
    "LEARNING_RATE = 5e-4 * 2**0\n",
    "SCHEDULER_GAMMA = 0.97\n",
    "REC_LOSS_WEIGHT = 0.392\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e41e47f5-3813-4723-9ef4-97253d0dd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "DEVICE = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c989b-18d9-481a-b5f8-b3c2a3f7b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "564374a6-f8b0-4f4d-a08c-45921c9aec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    transform_train = T.Compose([\n",
    "        T.Resize(64),\n",
    "        T.RandomCrop(48),\n",
    "        T.transforms.ColorJitter(brightness=[0., 2.], contrast=[0.5,1.5], saturation=0, hue=0),\n",
    "        T.ToTensor()\n",
    "    ])\n",
    "    transform_valid = T.Compose([\n",
    "        T.Resize(64),\n",
    "        T.RandomCrop(48),\n",
    "        T.transforms.ColorJitter(brightness=0, contrast=0, saturation=0, hue=0),\n",
    "        T.ToTensor()\n",
    "    ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050dc50-1ac2-49fa-bbda-a6dc3c483f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = SmallNORB(root='data/SmallNORB',train=True, download=True, transform=transform_train, mode=\"nopil\")\n",
    "ds_valid = SmallNORB(root='data/SmallNORB',train=False, download=True, transform=transform_valid, mode=\"nopil\")\n",
    "\n",
    "\n",
    "#\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, \n",
    "                                       batch_size=16, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)\n",
    "dl_valid = torch.utils.data.DataLoader(ds_valid, \n",
    "                                       batch_size=16, \n",
    "                                       shuffle=True, \n",
    "                                       num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bb849-ab0c-4d45-89aa-293ba7508d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85dbada-0cf0-4a45-9b2e-b408bc754a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_valid[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed7391-5a69-4ac6-a1de-74d96fb33841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "x[:64,:1,:,:].size()\n",
    "x[:64,1:2,:,:].size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba884cd4-d152-40ee-ac45-b5f6f726eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot train imgs\n",
    "x, y, z = next(iter(dl_train))\n",
    "\n",
    "# stereo channel 1\n",
    "img = torchvision.utils.make_grid(x[:64,:1,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# stereo channel 2\n",
    "img = torchvision.utils.make_grid(x[:64,1:2,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# plot valid imgs\n",
    "x, y, z = next(iter(dl_valid))\n",
    "\n",
    "# stereo channel 1\n",
    "img = torchvision.utils.make_grid(x[:64,:1,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# stereo channel 2\n",
    "img = torchvision.utils.make_grid(x[:64,1:2,:,:], nrow=8)\n",
    "img = img.permute((1,2,0))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdf535-9dc0-4afa-8e93-d23977d20b90",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f426f36b-ffde-43f0-b487-5e74f9e63782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallNorbEffCapsNet()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8af4e10-0337-4298-bf1b-bb6bb02ab037",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "064840b1-7e96-4f2f-81d4-14f05763c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training statistics\n",
    "stats = {\n",
    "    'acc_train': [],\n",
    "    'acc_valid': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b698ace-0d76-4093-9c8a-8affd2a9ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stuff\n",
    "print(\"#\" * 100)\n",
    "print(\"#params:            {:,}\".format(count_parameters(model)))\n",
    "print(\"Using device:       {}\".format(DEVICE))\n",
    "print(\"Learning rate:      {}\".format(LEARNING_RATE))\n",
    "print(\"Batch size:         {}\".format(BATCH_SIZE))\n",
    "#print(\"Writing results to: {}\".format(p_run))\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826738a-f81f-4409-8af9-017fa8a95b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_loss = 0\n",
    "epoch_correct = 0\n",
    "\n",
    "num_epochs = 1\n",
    "#\n",
    "for epoch_idx in range(1, num_epochs +1):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x, y_true, _ in pbar:\n",
    "        x = x.to(DEVICE)\n",
    "        y_true = y_true.to(DEVICE)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # way faster than optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        \n",
    "        u_h, x_rec = model.forward(x)\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=5)\n",
    "        loss_margin = margin_loss(u_h, y_one_hot)\n",
    "        loss_rec = torch.nn.functional.mse_loss(x, x_rec)\n",
    "        loss_rec = REC_LOSS_WEIGHT * loss_rec\n",
    "        \n",
    "        #Total Loss\n",
    "        loss = loss_margin + loss_rec\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # validate batch\n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "        \n",
    "        correct = (y_true == y_pred).sum()\n",
    "        acc = correct / y_true.shape[0]\n",
    "        \n",
    "        epoch_correct += correct.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'mar': loss_margin.item(),\n",
    "                 'rec': loss_rec.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "        break\n",
    "    break\n",
    "    \n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true, _ in dl_valid:\n",
    "        x = x.to(DEVICE)\n",
    "        y_true = y_true.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #u_l = model.primcaps(model.backbone(x))\n",
    "            #u_h = model.fcncaps(u_l)\n",
    "            u_h, x_rec = model.forward(x)            \n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401223e-2a1b-4bc7-8520-70e3063c5d4f",
   "metadata": {},
   "source": [
    "### loss rec argmax & y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5d581d-7f24-42ea-bc5a-f9ff1db3ba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallNorbEffCapsNetYMask()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e391939-3836-4f99-bc07-b6d2fcd3f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 5e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9120aaa-f29a-47b7-b9d4-8e683bf116ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print stuff\n",
    "print(\"#\" * 100)\n",
    "print(\"#params:            {:,}\".format(count_parameters(model)))\n",
    "print(\"Using device:       {}\".format(DEVICE))\n",
    "print(\"Learning rate:      {}\".format(LEARNING_RATE))\n",
    "print(\"Batch size:         {}\".format(BATCH_SIZE))\n",
    "#print(\"Writing results to: {}\".format(p_run))\n",
    "print(\"#\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8451e517-e4c9-418c-9d64-693f28c1ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 1\n",
    "#\n",
    "for epoch_idx in range(1, num_epochs +1):\n",
    "    # ####################\n",
    "    # TRAIN\n",
    "    # ####################\n",
    "    model.train()\n",
    "    epoch_correct = 0\n",
    "    epoch_total = 0\n",
    "    desc = \"Train [{:3}/{:3}]:\".format(epoch_idx, num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format=desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    \n",
    "    for x, y_true, _ in pbar:\n",
    "        x = x.to(DEVICE)\n",
    "        y_true = y_true.to(DEVICE)\n",
    "\n",
    "        #optimizer.zero_grad()\n",
    "\n",
    "        # way faster than optimizer.zero_grad()\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        \n",
    "        u_h, x_rec_max, x_rec_y = model.forward(x, y_true)\n",
    "        \n",
    "        print(\"x_rec_max: \", x_rec_max.size())\n",
    "        print(\"x_rec_y: \", x_rec_y.size())\n",
    "        \n",
    "        # LOSS\n",
    "        y_one_hot = F.one_hot(y_true, num_classes=5)\n",
    "        loss_margin = margin_loss(u_h, y_one_hot)\n",
    "        loss_rec = torch.nn.functional.mse_loss(x, x_rec_y)\n",
    "        loss_rec = REC_LOSS_WEIGHT * loss_rec\n",
    "        \n",
    "        #Total Loss\n",
    "        loss = loss_margin + loss_rec\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # validate batch\n",
    "        y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "        print(y_pred)\n",
    "        print(y_true)\n",
    "        print(y_true - y_pred)\n",
    "        \n",
    "        correct = (y_true == y_pred).sum()\n",
    "        acc = correct / y_true.shape[0]\n",
    "        \n",
    "        epoch_correct += correct.item()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        pbar.set_postfix(\n",
    "                {'loss': loss.item(),\n",
    "                 'mar': loss_margin.item(),\n",
    "                 'rec': loss_rec.item(),\n",
    "                 'acc': acc.item()\n",
    "                 }\n",
    "        )\n",
    "        break\n",
    "    break    \n",
    "    \n",
    "    lr_scheduler.step()\n",
    "    # ####################\n",
    "    # VALID\n",
    "    # ####################\n",
    "    model.eval()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for x,y_true, _ in dl_valid:\n",
    "        x = x.to(DEVICE)\n",
    "        y_true = y_true.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            #u_l = model.primcaps(model.backbone(x))\n",
    "            #u_h = model.fcncaps(u_l)\n",
    "            u_h, x_rec_max, x_rec_y  = model.forward(x, y_true)            \n",
    "            \n",
    "            y_pred = torch.argmax(torch.norm(u_h, dim=2), dim=1)\n",
    "            total_correct += (y_true == y_pred).sum()\n",
    "            total += y_true.shape[0]\n",
    "    print(\"   acc_valid: {:.3f}\".format(total_correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
